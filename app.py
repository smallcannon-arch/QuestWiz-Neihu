import streamlit as st
import google.generativeai as genai
import random
from pypdf import PdfReader
from docx import Document
import pandas as pd
import subprocess
import os

# --- 1. æª”æ¡ˆè®€å–å·¥å…· ---
def read_pdf(file):
    pdf_reader = PdfReader(file)
    return "".join([p.extract_text() or "" for p in pdf_reader.pages])

def read_docx(file):
    doc = Document(file)
    return "\n".join([p.text for p in doc.paragraphs])

def read_doc(file):
    with open("temp.doc", "wb") as f: f.write(file.getbuffer())
    try:
        result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
        return result.stdout if result.returncode == 0 else "[è®€å–å¤±æ•—]"
    except: return "[çµ„ä»¶æœªå°±ç·’]"
    finally:
        if os.path.exists("temp.doc"): os.remove("temp.doc")

# --- 2. æ·±åº¦æ•´åˆä¹‹ Gem å‘½é¡Œéµå¾‹ ---
GEM_INSTRUCTIONS = """
ä½ æ˜¯ã€Œåœ‹å°å°ˆæ¥­å®šæœŸè©•é‡å‘½é¡Œ AIã€ï¼Œç²¾é€š 1-6 å¹´ç´šæ•™ææ•™æ³•ã€‚
ä½ å¿…é ˆåš´æ ¼éµå®ˆä»¥ä¸‹è¡Œæ”¿èˆ‡å‘½é¡Œéµå¾‹ï¼š

### æ ¸å¿ƒè¨ˆç®—è¦å‰‡ï¼š
1. **é…åˆ†æ¬Šé‡**ï¼šå–®å…ƒç¸½åˆ† = (è©²å–®å…ƒç¯€æ•¸ / ç¸½ç¯€æ•¸) * 100ã€‚
2. **ç¸½åˆ†ç²¾ç®—**ï¼šè©¦å·ç¸½åˆ†å¿…é ˆã€Œå‰›å¥½ã€ç­‰æ–¼ 100 åˆ†ã€‚è‹¥å› ç›®æ¨™éå¤šå°è‡´æº¢åˆ†ï¼Œè«‹å„ªå…ˆèª¿é™åŸºç¤é¡Œé…åˆ†ã€‚ [cite: 2026-02-13]
3. **é¡Œå‹åˆ†é…**ï¼š
   - ğŸŸ¢ æ¨¡å¼ A (é©ä¸­)ï¼š60% é¸æ“‡ / 40% é–±è®€å…¶å®ƒã€‚
   - ğŸ”´ æ¨¡å¼ B (å›°é›£)ï¼š30% é¸æ“‡ / 70% é–±è®€å…¶å®ƒã€‚
   - ğŸŒŸ æ¨¡å¼ C (ç´ é¤Š)ï¼š20% é¸æ“‡ / 80% é–±è®€å…¶å®ƒ (å¼·åŒ–æƒ…å¢ƒ)ã€‚

### è¼¸å‡ºè¦ç¯„ï¼š
1. **åŸæ–‡æå–**ï¼šå­¸ç¿’ç›®æ¨™å¿…é ˆåŸæ–‡æ¡è‡ªæ•™æã€‚ [cite: 2026-02-13]
2. **é¡Œè™Ÿå°æ‡‰**ï¼šå¯©æ ¸è¡¨ä¸­çš„ã€Œå°æ‡‰é¡Œè™Ÿã€å¿…é ˆèˆ‡å¾ŒçºŒè©¦é¡Œå®Œå…¨ä¸€è‡´ã€‚ [cite: 2026-02-13]
3. **å“è³ªå®ˆé–€å“¡**ï¼šåš´ç¦ã€Œä»¥ä¸Šçš†æ˜¯/çš†éã€ã€‚æ ¼æ•¸æ§åˆ¶åœ¨ 34-45 æ ¼ã€‚ [cite: 2026-02-13]

### Phase 1 æ ¼å¼ (å…§æ¹–æ ¡å…§ç‰ˆ)ï¼š
è«‹ç‚ºæ¯å€‹å–®å…ƒç”¢å‡ºè¡¨æ ¼ï¼š
#### **[ç¬¬ X å–®å…ƒ ï¼ åç¨±]**
| å­¸ç¿’ç›®æ¨™ (åŸæ–‡) | æˆèª²ç¯€æ•¸ | å°æ‡‰é¡Œè™Ÿ | é¸æ“‡é¡Œ (ä½”åˆ†) | é–±è®€/å…¶å®ƒ (ä½”åˆ†) |
| :--- | :---: | :---: | :---: | :---: |
"""

# --- 3. ç¶²é ä»‹é¢é…ç½® ---
st.set_page_config(page_title="QuestWiz å…§æ¹–åœ‹å°ç‰ˆ", layout="wide")
st.title("ğŸ« QuestWiz è©¦é¡Œè¡Œæ”¿è‡ªå‹•åŒ–ç³»çµ±")

with st.sidebar:
    st.header("ğŸ”‘ ç³»çµ±è¨­å®š")
    st.markdown("[ğŸ‘‰ ç”³è«‹é‡‘é‘°](https://aistudio.google.com/app/apikey)")
    api_input = st.text_area("è²¼ä¸Š API Key (å¤šçµ„è«‹ç”¨é€—è™Ÿæˆ–æ›è¡Œéš”é–‹)", height=100)
    
    st.divider()
    auto_mode = st.checkbox("ğŸš€ ä¸€éµå…¨è‡ªå‹•æ¨¡å¼ (è·³éç¢ºèªå¯©æ ¸è¡¨)", value=False)
    st.info("ğŸ’¡ æ ¸å¿ƒï¼šå·²è¼‰å…¥ã€Œç›®æ¨™ä¸€å°ä¸€å°æ‡‰ã€å‘½é¡Œé‚è¼¯")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- æµç¨‹è™•ç† ---
if not st.session_state.chat_history:
    with st.container(border=True):
        col1, col2, col3 = st.columns(3)
        with col1: grade = st.selectbox("å¹´ç´š", ["ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"], index=4)
        with col2: subject = st.selectbox("ç§‘ç›®", ["è‡ªç„¶ç§‘å­¸", "åœ‹èª", "æ•¸å­¸", "ç¤¾æœƒ", "è‹±èª"], index=0)
        with col3: mode = st.selectbox("å‘½é¡Œæ¨¡å¼", ["ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­", "ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£", "ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š"], index=0)
        
        uploaded_files = st.file_uploader("ä¸Šå‚³æ•™æ", type=["pdf", "docx", "doc", "csv"], accept_multiple_files=True)
        start_btn = st.button("ğŸš€ é–‹å§‹åŸ·è¡Œå‘½é¡Œä»»å‹™", type="primary", use_container_width=True)

    if start_btn and api_input and uploaded_files:
        # API Key éš¨æ©Ÿè¼ªæ›¿é‚è¼¯
        api_keys = [k.strip() for k in api_input.replace('\n', ',').split(',') if k.strip()]
        selected_key = random.choice(api_keys)
        
        all_content = ""
        for f in uploaded_files:
            ext = f.name.split('.')[-1].lower()
            if ext == 'pdf': all_content += read_pdf(f)
            elif ext == 'docx': all_content += read_docx(f)
            elif ext == 'doc': all_content += read_doc(f)
            elif ext == 'csv': all_content += pd.read_csv(f, encoding_errors='ignore').to_string()
        
        try:
            genai.configure(api_key=selected_key)
            # è‡ªå‹•é€£ç·šè¨ºæ–·
            available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            target = "models/gemini-2.5-flash" if "models/gemini-2.5-flash" in available else available[0]
            
            model = genai.GenerativeModel(model_name=target, system_instruction=GEM_INSTRUCTIONS, generation_config={"temperature": 0.0})
            chat = model.start_chat(history=[])
            
            prompt = f"å¹´ç´šï¼š{grade}\nç§‘ç›®ï¼š{subject}\næ¨¡å¼ï¼š{mode}\nå…§å®¹ï¼š\n{all_content}\n"
            prompt += "--- è«‹ç›´æ¥ç”¢å‡ºå®Œæ•´è©¦å·ã€‚" if auto_mode else "--- è«‹å…ˆç”¢å‡ºã€è©¦é¡Œå¯©æ ¸è¡¨ã€‘ã€‚"

            with st.spinner("âš¡ æ­£åœ¨åˆ†ææ•™æä¸¦ç²¾ç®—é…åˆ†..."):
                response = chat.send_message(prompt)
                st.session_state.chat_session = chat
                st.session_state.chat_history.append({"role": "model", "content": response.text})
                st.rerun()
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—ï¼š{e}")
else:
    for msg in st.session_state.chat_history:
        with st.chat_message("ai" if msg["role"] == "model" else "user"):
            st.markdown(msg["content"])
    
    if prompt := st.chat_input("è¼¸å…¥ã€é–‹å§‹å‡ºé¡Œã€æˆ–ä¿®æ”¹æŒ‡ä»¤..."):
        res = st.session_state.chat_session.send_message(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        st.session_state.chat_history.append({"role": "model", "content": res.text})
        st.rerun()

    if st.button("ğŸ”„ é‡æ–°è¨­å®š (ä¸‹ä¸€ä½è€å¸«ä½¿ç”¨)"):
        st.session_state.chat_history = []
        st.session_state.chat_session = None
        st.rerun()
