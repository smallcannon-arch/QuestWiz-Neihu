import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from docx import Document
import pandas as pd
import subprocess
import os

# --- 1. æª”æ¡ˆè®€å–å·¥å…· ---
def read_pdf(file):
    pdf_reader = PdfReader(file)
    return "".join([p.extract_text() or "" for p in pdf_reader.pages])

def read_docx(file):
    doc = Document(file)
    return "\n".join([p.text for p in doc.paragraphs])

def read_doc(file):
    """è®€å–èˆŠç‰ˆ docï¼Œéœ€é…åˆ packages.txt å®‰è£ antiword"""
    with open("temp.doc", "wb") as f: f.write(file.getbuffer())
    try:
        result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
        return result.stdout if result.returncode == 0 else "[è®€å–å¤±æ•—]"
    except: return "[çµ„ä»¶æœªå°±ç·’]"
    finally:
        if os.path.exists("temp.doc"): os.remove("temp.doc")

# --- 2. æ·±åº¦å°é½Šåœ–ç‰‡æ ¼å¼èˆ‡æ•™ææå–çš„æŒ‡ä»¤ ---
GEM_INSTRUCTIONS = """
ä½ æ˜¯ã€Œåœ‹å°å°ˆæ¥­å®šæœŸè©•é‡å‘½é¡Œ AIã€ã€‚
ä½ çš„ä»»å‹™æ˜¯å¾æ•™æä¸­ã€ŒåŸæ–‡æå–ã€å­¸ç¿’ç›®æ¨™ï¼Œä¸¦åš´æ ¼ä¾ç…§ã€å…§æ¹–åœ‹å°æ ¡å…§ Excel æ ¼å¼ã€‘ç”¢å‡ºå¯©æ ¸è¡¨ã€‚

### æ ¸å¿ƒåŸå‰‡ï¼š
1. **åŸæ–‡æå–**ï¼šå­¸ç¿’ç›®æ¨™å¿…é ˆç›´æ¥æ¡è‡ªä½¿ç”¨è€…æä¾›çš„æ•™æå…§å®¹ï¼Œä¸å¾—è‡ªè¡Œç·¨é€ æˆ–ç°¡åŒ–ã€‚
2. **æ ¼å¼å°é½Š**ï¼šè¼¸å‡ºçµæ§‹éœ€ç¬¦åˆæä¾›çš„ Excel æˆªåœ–ã€‚

### Phase 1ï¼šã€è©¦é¡Œå¯©æ ¸è¡¨ã€‘æ ¼å¼ (å°é½Šåœ–ç‰‡)ï¼š
è«‹ç‚ºã€Œæ¯å€‹å–®å…ƒã€ç”¢å‡ºä¸€å€‹ç¨ç«‹çš„ Markdown è¡¨æ ¼ï¼š

#### **[ç¬¬ X å–®å…ƒ ï¼ å–®å…ƒåç¨±]**
| å­¸ç¿’ç›®æ¨™ (ç”±æ•™æåŸæ–‡æå–) | æˆèª²ç¯€æ•¸ | é¸æ“‡é¡Œ (ä½”åˆ†%) | é–±è®€/å…¶å®ƒ (ä½”åˆ†%) |
| :--- | :---: | :---: | :---: |
| 1. [æ•™æç›®æ¨™åŸæ–‡ 1] | [ç¯€æ•¸] | [é…åˆ†]% | [é…åˆ†]% |
| 2. [æ•™æç›®æ¨™åŸæ–‡ 2] | | | |
| 3. [æ•™æç›®æ¨™åŸæ–‡ 3] | | | |

---
**åŸºæœ¬æª¢æŸ¥æ¬„ä½ï¼š**
* **å‘½é¡Œæ¨¡å¼**ï¼š{mode} | **ç§‘ç›®**ï¼š{subject}
* **è©¦å·ç¸½åˆ†**ï¼š100 åˆ† | **ç¸½æ ¼æ•¸**ï¼š34-45 æ ¼
* **åœ–è¡¨æ¸…å–®**ï¼šè«‹åˆ—å‡º [Image of...] æ¨™ç±¤ã€‚
"""

# --- 3. ç¶²é ä»‹é¢é…ç½® ---
st.set_page_config(page_title="QuestWiz å…§æ¹–åœ‹å°å°ˆå±¬ç‰ˆ", layout="wide")
st.title("ğŸ« QuestWiz è©¦é¡Œè¡Œæ”¿è‡ªå‹•åŒ–ç³»çµ±")

with st.sidebar:
    st.header("ğŸ”‘ ç³»çµ±è¨­å®š")
    st.markdown("[ğŸ‘‰ ç”³è«‹é‡‘é‘°](https://aistudio.google.com/app/apikey)")
    api_key = st.text_input("è²¼ä¸Šæ‚¨çš„ API Key", type="password")
    st.divider()
    st.info("ğŸ’¡ æ ¼å¼å„ªåŒ–ï¼šå·²å°é½Šæ ¡å…§ Excel å¯©æ ¸è¡¨è¦ç¯„")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- ç¬¬ä¸€éšæ®µï¼šåˆ†æ ---
if not st.session_state.chat_history:
    with st.container(border=True):
        col1, col2, col3 = st.columns(3)
        with col1:
            grade = st.selectbox("å¹´ç´š", ["ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"], index=4)
        with col2:
            subject = st.selectbox("ç§‘ç›®", ["è‡ªç„¶ç§‘å­¸", "åœ‹èª", "æ•¸å­¸", "ç¤¾æœƒ", "è‹±èª"], index=0)
        with col3:
            mode = st.selectbox("å‘½é¡Œæ¨¡å¼", ["ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­", "ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£", "ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š"], index=0)
        
        uploaded_files = st.file_uploader("ä¸Šå‚³æ•™æ (æ”¯æ´æ–°èˆŠ Word/PDF/CSV)", type=["pdf", "docx", "doc", "csv"], accept_multiple_files=True)
        start_btn = st.button("ğŸš€ ç”¢å‡ºã€å…§æ¹–æ ¼å¼ã€‘è©¦é¡Œå¯©æ ¸è¡¨", type="primary", use_container_width=True)

    if start_btn and api_key and uploaded_files:
        all_content = ""
        for f in uploaded_files:
            ext = f.name.split('.')[-1].lower()
            if ext == 'pdf': all_content += read_pdf(f)
            elif ext == 'docx': all_content += read_docx(f)
            elif ext == 'doc': all_content += read_doc(f)
            elif ext == 'csv': all_content += pd.read_csv(f, encoding_errors='ignore').to_string()
        
        try:
            genai.configure(api_key=api_key)
            # è‡ªå‹•é€£ç·šè¨ºæ–·
            available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            target = "models/gemini-2.5-flash" if "models/gemini-2.5-flash" in available else available[0]
            
            # å°‡æ¨¡å¼èˆ‡ç§‘ç›®å‹•æ…‹å¸¶å…¥æŒ‡ä»¤
            current_instr = GEM_INSTRUCTIONS.format(mode=mode, subject=subject, grade=grade)
            
            model = genai.GenerativeModel(model_name=target, system_instruction=current_instr, generation_config={"temperature": 0.0})
            chat = model.start_chat(history=[])
            
            with st.spinner("âš¡ æ­£åœ¨åˆ†ææ•™æç›®æ¨™ä¸¦è¦åŠƒæ ¼å¼..."):
                response = chat.send_message(f"æ•™æå…§å®¹å¦‚ä¸‹ï¼š\n{all_content}")
                st.session_state.chat_session = chat
                st.session_state.chat_history.append({"role": "model", "content": response.text})
                st.rerun()
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—ï¼š{e}")
else:
    # é¡¯ç¤ºæ­·å²ç´€éŒ„èˆ‡å¾ŒçºŒæŒ‡ä»¤
    for msg in st.session_state.chat_history:
        with st.chat_message("ai" if msg["role"] == "model" else "user"):
            st.markdown(msg["content"])
    
    if prompt := st.chat_input("ç¢ºèªå¯©æ ¸è¡¨å¾Œï¼Œè«‹è¼¸å…¥ã€é–‹å§‹å‡ºé¡Œã€..."):
        res = st.session_state.chat_session.send_message(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        st.session_state.chat_history.append({"role": "model", "content": res.text})
        st.rerun()

    if st.button("ğŸ”„ é‡æ–°è¨­å®š"):
        st.session_state.chat_history = []
        st.session_state.chat_session = None
        st.rerun()
