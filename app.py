import streamlit as st
import google.generativeai as genai
import io
import pandas as pd
import math
import tempfile
import os
import time

# å˜—è©¦åŒ¯å…¥ Python æ–‡æª”è™•ç†å¥—ä»¶ (é˜²å‘†)
try:
    from docx import Document
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False

try:
    from pptx import Presentation
    HAS_PPTX = True
except ImportError:
    HAS_PPTX = False

# --- 1. è‡ªå‹•æœå°‹å¯ç”¨æ¨¡å‹ (ä¿®å¾© 404 çš„é—œéµ) ---
def get_valid_model_name(api_key):
    """
    è‡ªå‹•è©¢å• Google å¸³è™Ÿæœ‰å“ªäº›æ¨¡å‹å¯ç”¨ï¼Œé¿å…å¯«æ­»åç¨±å°è‡´ 404 éŒ¯èª¤ã€‚
    """
    try:
        genai.configure(api_key=api_key)
        # åˆ—å‡ºæ‰€æœ‰æ”¯æ´ç”Ÿæˆå…§å®¹çš„æ¨¡å‹
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        if not models:
            return "models/gemini-1.5-flash" # å¦‚æœçœŸçš„æŠ“ä¸åˆ°ï¼Œåªå¥½ç›²çŒœä¸€å€‹
            
        # å„ªå…ˆé †åº 1: Gemini 1.5 Flash (æœ€å¿«æœ€çœ)
        for m in models:
            if 'flash' in m.lower() and '1.5' in m.lower(): return m
            
        # å„ªå…ˆé †åº 2: Gemini 1.5 Pro (æœ€å¼·)
        for m in models:
            if 'pro' in m.lower() and '1.5' in m.lower(): return m
            
        # å„ªå…ˆé †åº 3: ä»»ä½• Flash
        for m in models:
            if 'flash' in m.lower(): return m
            
        # æœ€å¾Œæ‰‹æ®µ: åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹
        return models[0]
        
    except Exception as e:
        # å¦‚æœé€£åˆ—è¡¨éƒ½åˆ—ä¸å‡ºä¾†ï¼Œé€šå¸¸æ˜¯ API Key éŒ¯äº†ï¼Œä½†æˆ‘å€‘é‚„æ˜¯å›å‚³ä¸€å€‹é è¨­å€¼
        return "models/gemini-1.5-flash"

# --- 2. æ ¸å¿ƒé‚è¼¯ï¼šæª”æ¡ˆè™•ç† (æš´åŠ›è®€å–ç‰ˆ) ---
def process_file_for_ai(uploaded_file, api_key):
    genai.configure(api_key=api_key)
    filename = uploaded_file.name.lower()
    
    # === ç­–ç•¥ A: PDF ç›´è®€æ¨¡å¼ (è¦–è¦ºåˆ†æ) ===
    if filename.endswith(".pdf"):
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        try:
            st.toast(f"æ­£åœ¨å°‡ {uploaded_file.name} å‚³é€è‡³ AI è¦–è¦ºä¸­æ¨...", icon="ğŸ‘ï¸")
            gemini_file = genai.upload_file(path=tmp_path, mime_type="application/pdf")
            
            while gemini_file.state.name == "PROCESSING":
                time.sleep(1)
                gemini_file = genai.get_file(gemini_file.name)
            
            if gemini_file.state.name == "FAILED":
                return "error", "Google AI ç„¡æ³•è®€å–æ­¤ PDF (å¯èƒ½æ˜¯åŠ å¯†æˆ–æå£)ã€‚"
            
            return "file_mode", gemini_file
            
        except Exception as e:
            return "error", str(e)
        finally:
            if os.path.exists(tmp_path): os.remove(tmp_path)

    # === ç­–ç•¥ B: Word/PPT çµæ§‹åŒ–æ–‡å­—æ¨¡å¼ ===
    else:
        st.toast(f"æ­£åœ¨è§£æ {uploaded_file.name} æ–‡å­—çµæ§‹...", icon="ğŸ“")
        text_content = ""
        header = f"\n\n=== æª”æ¡ˆï¼š{uploaded_file.name} ===\n"

        try:
            if filename.endswith('.docx'):
                if HAS_DOCX:
                    doc = Document(uploaded_file)
                    paragraphs = []
                    for p in doc.paragraphs:
                        text = p.text.strip()
                        if text:
                            # å¼·åˆ¶åŠ ç¬¦è™Ÿï¼Œè®“ AI çŸ¥é“é€™æ˜¯åˆ—è¡¨
                            prefix = "â— " if len(text) < 80 else ""
                            paragraphs.append(f"{prefix}{text}")
                    text_content = "\n".join(paragraphs)
                else:
                    return "error", "ç³»çµ±ç¼ºå°‘ python-docx å¥—ä»¶ï¼Œç„¡æ³•è®€å– Word æª”ã€‚"
            
            elif filename.endswith('.pptx'):
                if HAS_PPTX:
                    prs = Presentation(uploaded_file)
                    for slide_idx, slide in enumerate(prs.slides):
                        slide_text = []
                        for shape in slide.shapes:
                            if hasattr(shape, "text") and shape.text.strip():
                                slide_text.append(f"â— {shape.text}")
                        if slide_text:
                            text_content += f"\n[Slide {slide_idx+1}]\n" + "\n".join(slide_text) + "\n"
                else:
                    return "error", "ç³»çµ±ç¼ºå°‘ python-pptx å¥—ä»¶ï¼Œç„¡æ³•è®€å– PPT æª”ã€‚"
            
            elif filename.endswith('.txt'):
                text_content = str(uploaded_file.read(), "utf-8")
            
            else:
                return "error", "ä¸æ”¯æ´çš„æ ¼å¼ã€‚è«‹ä¸Šå‚³ PDF (æœ€ä½³), DOCX, PPTX æˆ– TXTã€‚"

            return "text_mode", header + text_content

        except Exception as e:
            return "error", f"è®€å–å¤±æ•—: {str(e)}"

# --- 3. ç®—åˆ†æ ¸å¿ƒ (ç¸½åˆ† 100 é–å®š) ---
def calculate_scores(df):
    if df is None or df.empty: return df
    if 'é è¨ˆé…åˆ†' not in df.columns: df['é è¨ˆé…åˆ†'] = 0.0

    try:
        if 'æˆèª²ç¯€æ•¸' in df.columns: df.rename(columns={'æˆèª²ç¯€æ•¸': 'å–®å…ƒç¸½ç¯€æ•¸'}, inplace=True)
        
        # å¼·åˆ¶è½‰æ•¸å€¼
        df['å–®å…ƒç¸½ç¯€æ•¸'] = pd.to_numeric(df['å–®å…ƒç¸½ç¯€æ•¸'], errors='coerce').fillna(1)
        
        # æ¼”ç®—æ³•ï¼šå–®å…ƒæ™‚æ•¸åˆ†é…
        unit_counts = df['å–®å…ƒåç¨±'].value_counts()
        
        def get_objective_weight(row):
            unit = row['å–®å…ƒåç¨±']
            total_hours = row['å–®å…ƒç¸½ç¯€æ•¸']
            count = unit_counts.get(unit, 1)
            if count == 0: count = 1
            return total_hours / count

        df['ç›®æ¨™æ¬Šé‡(æ™‚æ•¸)'] = df.apply(get_objective_weight, axis=1)

        # ç¸½æ™‚æ•¸
        unique_units = df[['å–®å…ƒåç¨±', 'å–®å…ƒç¸½ç¯€æ•¸']].drop_duplicates()
        total_course_hours = unique_units['å–®å…ƒç¸½ç¯€æ•¸'].sum()
        if total_course_hours == 0: total_course_hours = 1

        # é…åˆ†
        df['åŸå§‹é…åˆ†'] = (df['ç›®æ¨™æ¬Šé‡(æ™‚æ•¸)'] / total_course_hours) * 100
        df['é è¨ˆé…åˆ†'] = df['åŸå§‹é…åˆ†'].apply(lambda x: round(x, 1))

        # 100åˆ†æ ¡æ­£
        current_sum = df['é è¨ˆé…åˆ†'].sum()
        diff = 100 - current_sum
        if abs(diff) > 0.01:
            df.iloc[-1, df.columns.get_loc('é è¨ˆé…åˆ†')] += diff

        return df
    except Exception as e:
        st.error(f"ç®—åˆ†é‚è¼¯éŒ¯èª¤: {e}")
        return df

# --- 4. Excel ä¸‹è¼‰å™¨ ---
def df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        export_df = df.copy()
        cols = ['å–®å…ƒåç¨±', 'å–®å…ƒç¸½ç¯€æ•¸', 'å­¸ç¿’ç›®æ¨™', 'ç›®æ¨™æ¬Šé‡(æ™‚æ•¸)', 'é è¨ˆé…åˆ†']
        final_cols = [c for c in cols if c in export_df.columns]
        export_df = export_df[final_cols]
        if 'ç›®æ¨™æ¬Šé‡(æ™‚æ•¸)' in export_df.columns:
            export_df.rename(columns={'ç›®æ¨™æ¬Šé‡(æ™‚æ•¸)': 'æ­¤ç›®æ¨™ä½”ç”¨ç¯€æ•¸'}, inplace=True)
        
        export_df.to_excel(writer, index=False, sheet_name='å¯©æ ¸è¡¨')
        workbook = writer.book
        worksheet = writer.sheets['å¯©æ ¸è¡¨']
        header_fmt = workbook.add_format({'bold': True, 'align': 'center', 'bg_color': '#DCE6F1', 'border': 1})
        text_fmt = workbook.add_format({'text_wrap': True, 'valign': 'top', 'border': 1})
        num_fmt = workbook.add_format({'num_format': '0.0', 'border': 1, 'align': 'center'})
        
        worksheet.set_column('A:A', 15, text_fmt)
        worksheet.set_column('B:B', 12, num_fmt)
        worksheet.set_column('C:C', 60, text_fmt)
        worksheet.set_column('D:E', 12, num_fmt)
        
        for i, col in enumerate(export_df.columns):
            worksheet.write(0, i, col, header_fmt)
            
    return output.getvalue()

# --- 5. Prompt ---
GEM_EXTRACT_PROMPT = """
ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„æ•™æåˆ†æå¸«ã€‚è«‹é–±è®€æä¾›çš„æ•™æï¼Œæå–ã€Œå–®å…ƒåç¨±ã€ã€ã€Œå­¸ç¿’ç›®æ¨™ã€èˆ‡ã€Œå–®å…ƒç¸½æˆèª²ç¯€æ•¸ã€ã€‚

**ä»»å‹™ 1ï¼šæŠ“å–æˆèª²ç¯€æ•¸ (Teaching Hours)**
- è«‹åœ¨æ–‡ä¸­æœå°‹ä»£è¡¨æ™‚é–“çš„é—œéµå­—ï¼Œå¦‚ã€Œ5ç¯€ã€ã€ã€Œå…­å ‚èª²ã€ã€ã€Œ40åˆ†é˜ x 3ã€ç­‰ã€‚
- å°‡è©²å–®å…ƒçš„**ç¸½ç¯€æ•¸**å¡«å…¥è¡¨æ ¼ã€‚
- è‹¥æ‰¾ä¸åˆ°ï¼Œè«‹æ ¹æ“šå–®å…ƒå…§å®¹ä»½é‡æ¨ä¼° (å¡«å…¥ 1~5 çš„æ•¸å­—)ã€‚

**ä»»å‹™ 2ï¼šæ‹†è§£å­¸ç¿’ç›®æ¨™ (Explode Rows)**
- çœ‹åˆ°ç·¨è™Ÿ (1. 2. 3...) æˆ–åˆ—è¡¨ç¬¦è™Ÿ (â—, -)ï¼Œ**å¿…é ˆå°‡æ¯ä¸€å€‹ç›®æ¨™æ‹†æˆç¨ç«‹çš„ä¸€åˆ— (Row)**ã€‚
- ç¯„ä¾‹ï¼šè‹¥å–®å…ƒæœ‰ 3 å€‹é‡é»ï¼Œè«‹è¼¸å‡º 3 åˆ—ï¼Œé€™ 3 åˆ—çš„ã€Œå–®å…ƒåç¨±ã€èˆ‡ã€Œæˆèª²ç¯€æ•¸ã€éƒ½ç›¸åŒã€‚
- **åš´ç¦åˆä½µ**ã€‚

**è¼¸å‡ºæ ¼å¼ (Markdown è¡¨æ ¼)**
æ¬„ä½ï¼š| å–®å…ƒåç¨± | å­¸ç¿’ç›®æ¨™ | æˆèª²ç¯€æ•¸ |
"""

# --- 6. ä¸»ç¨‹å¼ ---
st.set_page_config(page_title="å…§æ¹–åœ‹å° AI å‘½é¡Œç³»çµ± (Auto-Fix)", layout="wide")

st.markdown("""<div style="background:#1E293B;padding:15px;text-align:center;color:white;border-radius:10px;">
<h2>å…§æ¹–åœ‹å° AI å‘½é¡Œç³»çµ± (Auto-Fix ç‰ˆ)</h2></div>""", unsafe_allow_html=True)

if "extracted_data" not in st.session_state: st.session_state.extracted_data = None
if "step" not in st.session_state: st.session_state.step = 1

with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("Google API Key", type="password")
    
    st.divider()
    if HAS_DOCX: st.caption("âœ… DOCX æ¨¡çµ„æ­£å¸¸")
    else: st.error("âŒ ç¼º python-docx (ç„¡æ³•è®€ Word)")
    
    if st.button("ğŸ”„ é‡ç½®"): 
        st.session_state.extracted_data = None
        st.session_state.step = 1
        st.rerun()

# Step 1: ä¸Šå‚³
if st.session_state.step == 1:
    st.info("ğŸ’¡ æ”¯æ´ PDF (æœ€å¼·ï¼Œå¯è®€æƒææª”)ã€Wordã€PPTã€‚è«‹ç›´æ¥ä¸Šå‚³ï¼ŒAI æœƒæƒ³è¾¦æ³•ç¡¬è®€ã€‚")
    uploaded_files = st.file_uploader("é¸æ“‡æ•™ææª”æ¡ˆ", type=["pdf", "docx", "pptx", "txt"], accept_multiple_files=True)
    
    if st.button("ğŸš€ é–‹å§‹åˆ†æ & è‡ªå‹•é…åˆ†", type="primary", use_container_width=True):
        if api_key and uploaded_files:
            with st.spinner("AI æ­£åœ¨é¸å–æœ€ä½³æ¨¡å‹ä¸¦åˆ†æè³‡æ–™..."):
                all_data = []
                # è‡ªå‹•å–å¾—æœ€ä½³æ¨¡å‹åç¨± (é—œéµä¿®å¾©ï¼)
                model_name = get_valid_model_name(api_key)
                st.toast(f"å·²é€£ç·šè‡³æ¨¡å‹ï¼š{model_name}", icon="ğŸ¤–")
                
                # è™•ç†å¤šå€‹æª”æ¡ˆ
                for file in uploaded_files:
                    try:
                        # 1. æ±ºå®šè®€å–ç­–ç•¥
                        mode, payload = process_file_for_ai(file, api_key)
                        
                        if mode == "error":
                            st.warning(f"è·³éæª”æ¡ˆ {file.name}: {payload}")
                            continue

                        # 2. å‘¼å« Gemini
                        model = genai.GenerativeModel(model_name)
                        
                        if mode == "file_mode":
                            # è¦–è¦ºæ¨¡å¼ (PDF)
                            response = model.generate_content([GEM_EXTRACT_PROMPT, payload])
                        else:
                            # æ–‡å­—æ¨¡å¼ (DOCX/PPTX)
                            response = model.generate_content(GEM_EXTRACT_PROMPT + f"\n\næ•™æå…§å®¹ï¼š\n{payload}")

                        # 3. è§£æå›æ‡‰
                        lines = [l.strip() for l in response.text.split('\n') if "|" in l and "---" not in l]
                        for l in lines:
                            row = [c.strip() for c in l.split('|') if c.strip()]
                            if len(row) >= 3: all_data.append(row[:3])
                            
                    except Exception as e:
                        st.error(f"è™•ç† {file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

                if all_data:
                    # è½‰æˆ DataFrame
                    df = pd.DataFrame(all_data[1:], columns=["å–®å…ƒåç¨±", "å­¸ç¿’ç›®æ¨™", "æˆèª²ç¯€æ•¸"])
                    # æ’é™¤å¯èƒ½çš„æ¨™é¡Œåˆ—
                    if "å–®å…ƒ" in str(df.iloc[0,0]): 
                        df = df.iloc[1:].reset_index(drop=True)
                    
                    df.rename(columns={"æˆèª²ç¯€æ•¸": "å–®å…ƒç¸½ç¯€æ•¸"}, inplace=True)
                    
                    # é€²å…¥ç®—åˆ†
                    df_cal = calculate_scores(df)
                    st.session_state.extracted_data = df_cal
                    st.session_state.step = 2
                    st.rerun()
                else:
                    st.error("AI è®€ä¸åˆ°ä»»ä½•è¡¨æ ¼è³‡æ–™ã€‚è«‹ç¢ºèªæª”æ¡ˆå…§å®¹ã€‚")

# Step 2: çµæœç¢ºèª
elif st.session_state.step == 2:
    st.success("âœ… è³‡æ–™æå–æˆåŠŸï¼é…åˆ†å·²è‡ªå‹•è¨ˆç®—ã€‚")
    st.markdown("è«‹æª¢æŸ¥ **ã€Œå–®å…ƒç¸½ç¯€æ•¸ã€** æ˜¯å¦æ­£ç¢ºã€‚è‹¥ AI æŠ“éŒ¯ (ä¾‹å¦‚æŠ“æˆ 1)ï¼Œè«‹æ‰‹å‹•ä¿®æ”¹ï¼Œé…åˆ†æœƒç«‹åˆ»é‡ç®—ã€‚")
    
    df_curr = st.session_state.extracted_data
    
    # ç·¨è¼¯å™¨
    edited_df = st.data_editor(
        df_curr,
        column_config={
            "å–®å…ƒåç¨±": st.column_config.TextColumn(disabled=True),
            "å­¸ç¿’ç›®æ¨™": st.column_config.TextColumn(width="large"),
            "å–®å…ƒç¸½ç¯€æ•¸": st.column_config.NumberColumn("å–®å…ƒç¸½ç¯€æ•¸", min_value=1, max_value=50, help="ä¿®æ”¹æ­¤è™•ï¼Œé…åˆ†è‡ªå‹•æ›´æ–°"),
            "ç›®æ¨™æ¬Šé‡(æ™‚æ•¸)": st.column_config.NumberColumn("æ­¤ç›®æ¨™ä½”ç”¨", disabled=True, format="%.2f"),
            "é è¨ˆé…åˆ†": st.column_config.NumberColumn("é…åˆ† (%)", disabled=True)
        },
        use_container_width=True,
        num_rows="dynamic"
    )
    
    # å³æ™‚é‡ç®—
    if not edited_df.equals(df_curr):
        st.session_state.extracted_data = calculate_scores(edited_df)
        st.rerun()

    col1, col2 = st.columns(2)
    with col1:
        st.download_button("ğŸ“¥ ä¸‹è¼‰å¯©æ ¸è¡¨ (Excel)", df_to_excel(edited_df), "å¯©æ ¸è¡¨.xlsx", use_container_width=True)
    with col2:
        if st.button("â¬…ï¸ é‡æ–°ä¸Šå‚³", use_container_width=True): 
            st.session_state.step=1
            st.rerun()
