import streamlit as st
import google.generativeai as genai
import io
import pandas as pd
import math
from pypdf import PdfReader
from docx import Document
from pptx import Presentation

# --- 1. æ ¸å¿ƒè¨­å®š (ä¸è®Š) ---
SUBJECT_Q_TYPES = {
    "åœ‹èª": ["åœ‹å­—æ³¨éŸ³", "æ”¹éŒ¯å­—", "å­—è©ç¾©æ¸¬é©—", "èª²æ–‡ç†è§£", "é–±è®€æ¸¬é©—", "æˆèªé‹ç”¨"],
    "æ•¸å­¸": ["é¸æ“‡é¡Œ", "å¡«å……é¡Œ", "è¨ˆç®—é¡Œ", "æ‡‰ç”¨é¡Œ", "ç•«åœ–é¡Œ"],
    "è‡ªç„¶ç§‘å­¸": ["æ˜¯éé¡Œ", "é¸æ“‡é¡Œ", "åšåšçœ‹", "ç§‘å­¸é–±è®€", "å¯¦é©—é¡Œ"],
    "ç¤¾æœƒ": ["æ˜¯éé¡Œ", "é¸æ“‡é¡Œ", "å‹¾é¸é¡Œ", "é€£é€£çœ‹", "ç°¡ç­”é¡Œ", "åœ–è¡¨é¡Œ"],
    "è‹±èª": ["Listen & Check", "Listen & Choose", "Read & Choose", "Look & Write", "Reading Comprehension"],
    "": ["å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "ç°¡ç­”é¡Œ"]
}

# --- 2. æª”æ¡ˆè®€å–å·¥å…· (ä¸è®Š) ---
@st.cache_data
def extract_text_from_files(files):
    text_content = ""
    for file in files:
        try:
            filename = file.name.lower()
            file_header = f"\n\n=== æª”æ¡ˆä¾†æºï¼š{file.name} ===\n"
            extracted_text = ""

            if filename.endswith('.pdf'):
                pdf_reader = PdfReader(file)
                for page in pdf_reader.pages:
                    extracted_text += (page.extract_text() or "") + "\n"
                if len(extracted_text.strip()) < 10:
                    text_content += file_header + "[è­¦ç¤º] æª”æ¡ˆå…§å®¹éå°‘ï¼Œä¼¼ä¹æ˜¯åœ–ç‰‡æƒææª”ã€‚\n"
                else:
                    text_content += file_header + extracted_text

            elif filename.endswith('.docx'):
                doc = Document(file)
                extracted_text = "\n".join([p.text for p in doc.paragraphs])
                text_content += file_header + extracted_text

            elif filename.endswith('.pptx'):
                prs = Presentation(file)
                for slide_idx, slide in enumerate(prs.slides):
                    slide_text = []
                    for shape in slide.shapes:
                        if hasattr(shape, "text") and shape.text.strip():
                            slide_text.append(shape.text)
                    if slide_text:
                        extracted_text += f"[Slide {slide_idx+1}]\n" + "\n".join(slide_text) + "\n"
                text_content += file_header + extracted_text
            
            elif filename.endswith('.txt'):
                text_content += file_header + str(file.read(), "utf-8")
                
        except Exception as e:
            text_content += f"\n[è®€å–éŒ¯èª¤] {str(e)}\n"
    return text_content

# --- 3. é‚è¼¯å¤§æ”¹ï¼šå–®å…ƒæ™‚æ•¸å‡åˆ†æ¼”ç®—æ³• ---
def calculate_scores(df):
    try:
        # 1. ç¢ºä¿æ•¸æ“šæ ¼å¼æ­£ç¢º
        # æˆ‘å€‘è®“ 'å–®å…ƒç¸½ç¯€æ•¸' æˆç‚ºè©²å–®å…ƒçš„ç¸½é‡ï¼Œ'æ¬Šé‡' å‰‡æ˜¯é€™æ¢ç›®æ¨™åˆ†åˆ°çš„æ™‚æ•¸
        if 'å–®å…ƒç¸½ç¯€æ•¸' not in df.columns:
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡ç”Ÿæˆï¼Œå¯èƒ½åªæœ‰ 'æˆèª²ç¯€æ•¸'ï¼Œå…ˆè½‰æ›éä¾†
            df['å–®å…ƒç¸½ç¯€æ•¸'] = pd.to_numeric(df['æˆèª²ç¯€æ•¸'], errors='coerce').fillna(1)
        
        # 2. è¨ˆç®—æ¯å€‹å–®å…ƒæœ‰å¤šå°‘å€‹ç›®æ¨™ (Row count per unit)
        unit_counts = df['å–®å…ƒåç¨±'].value_counts()
        
        # 3. é‡æ–°è¨ˆç®—æ¯ä¸€åˆ—çš„å¯¦éš›ç¯€æ•¸ (æ¬Šé‡)
        # é‚è¼¯ï¼šå¦‚æœä½¿ç”¨è€…å¡«å¯«å–®å…ƒ 4-1 æ˜¯ 5 ç¯€ï¼Œä¸” AI æŠ“å‡º 10 æ¢ç›®æ¨™ï¼Œå‰‡æ¯æ¢è‡ªå‹•åˆ† 0.5 ç¯€
        def distribute_hours(row):
            unit_name = row['å–®å…ƒåç¨±']
            total_unit_hours = row['å–®å…ƒç¸½ç¯€æ•¸']
            count = unit_counts.get(unit_name, 1)
            return total_unit_hours / count

        # å‰µé€ ä¸€å€‹æ–°æ¬„ä½ã€Œç›®æ¨™åˆ†é…ç¯€æ•¸ã€ï¼Œé€™æ‰æ˜¯çœŸæ­£ç”¨ä¾†ç®—åˆ†çš„æ¬Šé‡
        df['ç›®æ¨™åˆ†é…ç¯€æ•¸'] = df.apply(distribute_hours, axis=1)

        # 4. è¨ˆç®—æ•´å¼µè€ƒå·çš„ç¸½æ™‚æ•¸
        # æ³¨æ„ï¼šä¸èƒ½ç›´æ¥ sum(ç›®æ¨™åˆ†é…ç¯€æ•¸)ï¼Œå› ç‚ºæµ®é»æ•¸æœƒæœ‰èª¤å·®ï¼Œæˆ‘å€‘æ”¹ç”¨ sum(å–®å…ƒç¸½ç¯€æ•¸) / count é‚è¼¯åæ¨
        # ä½†æœ€ç°¡å–®çš„æ–¹å¼æ˜¯ï¼šå°‡æ‰€æœ‰å–®å…ƒçš„ç¸½ç¯€æ•¸åŠ ç¸½ (å»é‡è¤‡å¾Œ)
        
        # å»ºç«‹ä¸€å€‹å–®å…ƒå°ç…§è¡¨
        unit_hours_map = df[['å–®å…ƒåç¨±', 'å–®å…ƒç¸½ç¯€æ•¸']].drop_duplicates()
        total_course_hours = unit_hours_map['å–®å…ƒç¸½ç¯€æ•¸'].sum()
        
        if total_course_hours == 0: total_course_hours = 1

        # 5. è¨ˆç®—é…åˆ†
        # å…¬å¼ï¼š(è©²ç›®æ¨™åˆ†åˆ°çš„ç¯€æ•¸ / ç¸½èª²ç¨‹æ™‚æ•¸) * 100
        df['åŸå§‹é…åˆ†'] = (df['ç›®æ¨™åˆ†é…ç¯€æ•¸'] / total_course_hours) * 100
        df['é è¨ˆé…åˆ†'] = df['åŸå§‹é…åˆ†'].apply(lambda x: round(x, 1)) # ä¿ç•™ä¸€ä½å°æ•¸æ¯”è¼ƒå¥½çœ‹

        # 6. å¾®èª¿ç¸½åˆ†è‡³ 100 (é‡å°æ•´æ•¸)
        # é€™è£¡åšä¸€å€‹ç°¡å–®çš„è™•ç†ï¼šæœ€å¾Œä¸€é …è£œå·®é¡ï¼Œç¢ºä¿åŠ èµ·ä¾†æ˜¯ 100
        current_sum = df['é è¨ˆé…åˆ†'].sum()
        diff = 100 - current_sum
        if diff != 0:
            df.iloc[-1, df.columns.get_loc('é è¨ˆé…åˆ†')] += diff

        return df
    except Exception as e:
        st.error(f"é…åˆ†è¨ˆç®—éŒ¯èª¤: {e}")
        return df

# --- 4. Excel ä¸‹è¼‰ (æ”¯æ´å°æ•¸é»é¡¯ç¤º) ---
def df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        # æº–å‚™åŒ¯å‡ºè³‡æ–™ï¼Œç§»é™¤è¨ˆç®—ç”¨çš„æš«å­˜æ¬„ä½
        export_df = df.copy()
        # ç‚ºäº†è®“è€å¸«çœ‹æ‡‚ï¼Œæˆ‘å€‘æŠŠã€Œå–®å…ƒç¸½ç¯€æ•¸ã€æ”¾åœ¨å‰é¢
        cols = ['å–®å…ƒåç¨±', 'å–®å…ƒç¸½ç¯€æ•¸', 'å­¸ç¿’ç›®æ¨™', 'ç›®æ¨™åˆ†é…ç¯€æ•¸', 'é è¨ˆé…åˆ†']
        export_df = export_df[cols]
        export_df.rename(columns={'ç›®æ¨™åˆ†é…ç¯€æ•¸': 'æ­¤ç›®æ¨™ä½”ç”¨ç¯€æ•¸'}, inplace=True)
        
        export_df.to_excel(writer, index=False, sheet_name='å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨')
        workbook = writer.book
        worksheet = writer.sheets['å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨']
        
        header_fmt = workbook.add_format({'bold': True, 'align': 'center', 'bg_color': '#DCE6F1', 'border': 1})
        cell_fmt = workbook.add_format({'text_wrap': True, 'valign': 'top', 'border': 1})
        num_fmt = workbook.add_format({'num_format': '0.0', 'border': 1, 'align': 'center'}) # æ”¯æ´å°æ•¸é»
        
        worksheet.set_column('A:A', 15, cell_fmt) 
        worksheet.set_column('B:B', 10, num_fmt) 
        worksheet.set_column('C:C', 60, cell_fmt) 
        worksheet.set_column('D:D', 12, num_fmt)
        worksheet.set_column('E:E', 12, num_fmt)
        
        for col_num, value in enumerate(export_df.columns.values):
            worksheet.write(0, col_num, value, header_fmt)
            
    return output.getvalue()

# --- 5. æ¨¡å‹é¸æ“‡ (ä¸è®Š) ---
def get_available_flash_model(api_key):
    try:
        genai.configure(api_key=api_key)
        valid_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        for m in valid_models:
             if 'flash' in m.lower(): return m
        return "models/gemini-1.5-flash"
    except: return "models/gemini-1.5-flash"

# --- 6. Prompt å¤§æ”¹ï¼šå¼·åˆ¶é€æ¢åˆ—å‡º + æŠ“å–®å…ƒç¸½æ™‚æ•¸ ---
GEM_EXTRACT_PROMPT = """
ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„æ•™æåˆ†æå¸«ã€‚è«‹åˆ†æä»¥ä¸‹æ•™æï¼Œæå–ã€Œå–®å…ƒåç¨±ã€ã€ã€Œå­¸ç¿’ç›®æ¨™ã€èˆ‡ã€Œå–®å…ƒç¸½æˆèª²ç¯€æ•¸ã€ã€‚

**è¼¸å‡ºè¦å‰‡ (è«‹åš´æ ¼åŸ·è¡Œ)ï¼š**
1. **æ ¼å¼**ï¼šåƒ…è¼¸å‡º Markdown è¡¨æ ¼ï¼Œæ¬„ä½ï¼š| å–®å…ƒåç¨± | å­¸ç¿’ç›®æ¨™ | æˆèª²ç¯€æ•¸ |
2. **å­¸ç¿’ç›®æ¨™æ‹†è§£ (æœ€é‡è¦)**ï¼š
   - ä»”ç´°é–±è®€æ•™æä¸­çš„æ¢åˆ—å¼é‡é» (å¦‚ 1., 2., 3... æˆ– A, B, C)ã€‚
   - **æ¯ä¸€æ¢é‡é»å¿…é ˆç¨ç«‹æ‹†æˆ Excel çš„ä¸€åˆ— (Row)**ã€‚
   - **åš´ç¦åˆä½µ**ï¼šå¦‚æœæœ‰ 10 é»ï¼Œè¡¨æ ¼å°±è¦æœ‰ 10 åˆ—ã€‚
   - ç¯„ä¾‹ï¼šå¦‚æœå–®å…ƒ 4-1 æœ‰ 10 é»ï¼Œè«‹è¼¸å‡º 10 åˆ—ã€Œå–®å…ƒ 4-1ã€ï¼Œæ¯åˆ—å°æ‡‰ä¸€é»ç›®æ¨™ã€‚
3. **æˆèª²ç¯€æ•¸ (å–®å…ƒç¸½é‡)**ï¼š
   - è«‹æ‰¾å‡ºè©²ã€Œå–®å…ƒã€å»ºè­°çš„ç¸½ç¯€æ•¸ (ä¾‹å¦‚å–®å…ƒ 4-1 å»ºè­° 5 ç¯€)ã€‚
   - **è«‹åœ¨è©²å–®å…ƒçš„æ¯ä¸€åˆ—éƒ½å¡«å…¥é€™å€‹ã€Œç¸½ç¯€æ•¸ã€** (ä¸ç”¨ä½ å»å¹³åˆ†ï¼Œå¾ŒçºŒç¨‹å¼æœƒç®—)ã€‚
   - å¦‚æœæ‰¾ä¸åˆ°å»ºè­°ç¯€æ•¸ï¼Œè«‹ä¾å…§å®¹ä»½é‡æ¨ä¼° (ä¾‹å¦‚å…§å®¹å¾ˆå¤šçš„å–®å…ƒå¡« 5ï¼Œå°‘çš„å¡« 2)ã€‚

æ•™æå…§å®¹ï¼š
{content}
"""

# --- 7. ä¸»ç¨‹å¼ ---
st.set_page_config(page_title="å…§æ¹–åœ‹å°å‡ºé¡Œç³»çµ± (Pro)", layout="wide")

st.markdown("""<div style="background:#1E293B;padding:15px;text-align:center;color:white;border-radius:10px;">
<h2>å…§æ¹–åœ‹å° AI å‘½é¡Œç³»çµ± (ç´°ç›®æ‹†è§£ç‰ˆ)</h2></div>""", unsafe_allow_html=True)

if "extracted_data" not in st.session_state: st.session_state.extracted_data = None
if "step" not in st.session_state: st.session_state.step = 1

with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("API Key", type="password")
    if st.button("é‡ç½®"): 
        st.session_state.extracted_data = None
        st.session_state.step = 1
        st.rerun()

if st.session_state.step == 1:
    uploaded_files = st.file_uploader("ä¸Šå‚³æ•™æ", type=["pdf","docx","pptx","txt"], accept_multiple_files=True)
    if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
        if api_key and uploaded_files:
            with st.spinner("AI æ­£åœ¨é€æ¢æ‹†è§£å­¸ç¿’ç›®æ¨™..."):
                try:
                    text = extract_text_from_files(uploaded_files)
                    model_name = get_available_flash_model(api_key)
                    model = genai.GenerativeModel(model_name)
                    res = model.generate_content(GEM_EXTRACT_PROMPT.format(content=text[:40000]))
                    
                    # è§£æ
                    lines = [l.strip() for l in res.text.split('\n') if "|" in l and "---" not in l]
                    data = []
                    for l in lines:
                        row = [c.strip() for c in l.split('|') if c.strip()]
                        if len(row) >= 3: data.append(row[:3])
                    
                    if data:
                        df = pd.DataFrame(data[1:], columns=["å–®å…ƒåç¨±", "å­¸ç¿’ç›®æ¨™", "æˆèª²ç¯€æ•¸"])
                        # é€™è£¡æŠŠ 'æˆèª²ç¯€æ•¸' æ”¹åç‚º 'å–®å…ƒç¸½ç¯€æ•¸' ä»¥ç¬¦åˆæ–°é‚è¼¯
                        df.rename(columns={"æˆèª²ç¯€æ•¸": "å–®å…ƒç¸½ç¯€æ•¸"}, inplace=True)
                        
                        df_cal = calculate_scores(df)
                        st.session_state.extracted_data = df_cal
                        st.session_state.step = 2
                        st.rerun()
                except Exception as e: st.error(str(e))

elif st.session_state.step == 2:
    st.info("ğŸ’¡ é‚è¼¯æ›´æ–°ï¼šè«‹ä¿®æ”¹ã€Œå–®å…ƒç¸½ç¯€æ•¸ã€ã€‚ç³»çµ±æœƒè‡ªå‹•å°‡è©²å–®å…ƒçš„ç¯€æ•¸ï¼Œå¹³å‡åˆ†é…çµ¦åº•ä¸‹çš„æ‰€æœ‰å­¸ç¿’ç›®æ¨™ã€‚")
    
    df_curr = st.session_state.extracted_data
    
    # ç·¨è¼¯å™¨ï¼šè®“è€å¸«æ”¹å–®å…ƒç¸½ç¯€æ•¸
    edited_df = st.data_editor(
        df_curr,
        column_config={
            "å–®å…ƒåç¨±": st.column_config.TextColumn(disabled=True),
            "å­¸ç¿’ç›®æ¨™": st.column_config.TextColumn(width="large"),
            "å–®å…ƒç¸½ç¯€æ•¸": st.column_config.NumberColumn("å–®å…ƒç¸½ç¯€æ•¸", help="ä¾‹å¦‚ 4-1 ç¸½å…± 5 ç¯€ï¼Œè«‹åœ¨æ­¤è¼¸å…¥ 5 (æ¯ä¸€åˆ—éƒ½å¡« 5)"),
            "ç›®æ¨™åˆ†é…ç¯€æ•¸": st.column_config.NumberColumn("æ­¤ç›®æ¨™ä½”ç”¨ (ç¯€)", disabled=True, format="%.2f", help="è‡ªå‹•è¨ˆç®—ï¼šç¸½ç¯€æ•¸ / ç›®æ¨™æ•¸é‡"),
            "é è¨ˆé…åˆ†": st.column_config.NumberColumn("é è¨ˆé…åˆ† (%)", disabled=True)
        },
        use_container_width=True,
        num_rows="dynamic"
    )
    
    # å³æ™‚é‡ç®—
    if not edited_df.equals(df_curr):
        st.session_state.extracted_data = calculate_scores(edited_df)
        st.rerun()

    st.download_button("ä¸‹è¼‰ Excel", df_to_excel(edited_df), "ç´°ç›®å¯©æ ¸è¡¨.xlsx")
    if st.button("é‡æ–°ä¸Šå‚³"): st.session_state.step=1; st.rerun()
