import streamlit as st
import google.generativeai as genai
import io
import pandas as pd
import math
from pypdf import PdfReader
from docx import Document
from pptx import Presentation

# --- 1. æ ¸å¿ƒè¨­å®š ---
SUBJECT_Q_TYPES = {
    "åœ‹èª": ["åœ‹å­—æ³¨éŸ³", "æ”¹éŒ¯å­—", "å­—è©ç¾©æ¸¬é©—", "èª²æ–‡ç†è§£", "é–±è®€æ¸¬é©—", "æˆèªé‹ç”¨"],
    "æ•¸å­¸": ["é¸æ“‡é¡Œ", "å¡«å……é¡Œ", "è¨ˆç®—é¡Œ", "æ‡‰ç”¨é¡Œ", "ç•«åœ–é¡Œ"],
    "è‡ªç„¶ç§‘å­¸": ["æ˜¯éé¡Œ", "é¸æ“‡é¡Œ", "åšåšçœ‹", "ç§‘å­¸é–±è®€", "å¯¦é©—é¡Œ"],
    "ç¤¾æœƒ": ["æ˜¯éé¡Œ", "é¸æ“‡é¡Œ", "å‹¾é¸é¡Œ", "é€£é€£çœ‹", "ç°¡ç­”é¡Œ", "åœ–è¡¨é¡Œ"],
    "è‹±èª": ["Listen & Check", "Listen & Choose", "Read & Choose", "Look & Write", "Reading Comprehension"],
    "": ["å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "ç°¡ç­”é¡Œ"]
}

# --- 2. æª”æ¡ˆè®€å–å·¥å…· ---
@st.cache_data
def extract_text_from_files(files):
    text_content = ""
    for file in files:
        try:
            filename = file.name.lower()
            file_header = f"\n\n=== æª”æ¡ˆä¾†æºï¼š{file.name} ===\n"
            extracted_text = ""

            if filename.endswith('.pdf'):
                pdf_reader = PdfReader(file)
                for page in pdf_reader.pages:
                    extracted_text += (page.extract_text() or "") + "\n"
                if len(extracted_text.strip()) < 10:
                    text_content += file_header + "[è­¦ç¤º] æª”æ¡ˆå…§å®¹éå°‘ï¼Œä¼¼ä¹æ˜¯åœ–ç‰‡æƒææª”ã€‚\n"
                else:
                    text_content += file_header + extracted_text

            elif filename.endswith('.docx'):
                doc = Document(file)
                extracted_text = "\n".join([p.text for p in doc.paragraphs])
                text_content += file_header + extracted_text

            elif filename.endswith('.pptx'):
                try:
                    prs = Presentation(file)
                    for slide_idx, slide in enumerate(prs.slides):
                        slide_text = []
                        for shape in slide.shapes:
                            if hasattr(shape, "text") and shape.text.strip():
                                slide_text.append(shape.text)
                        if slide_text:
                            extracted_text += f"[Slide {slide_idx+1}]\n" + "\n".join(slide_text) + "\n"
                    text_content += file_header + extracted_text
                except:
                    text_content += file_header + "[PPTX è®€å–éŒ¯èª¤] è«‹ç¢ºèªæª”æ¡ˆæœªåŠ å¯†ã€‚\n"
            
            elif filename.endswith('.txt'):
                text_content += file_header + str(file.read(), "utf-8")
                
        except Exception as e:
            text_content += f"\n[è®€å–éŒ¯èª¤] {str(e)}\n"
    return text_content

# --- 3. é‚è¼¯ä¿®å¾©ï¼šé˜²å‘†ç®—åˆ†ç³»çµ± ---
def calculate_scores(df):
    # åˆå§‹åŒ–æ¬„ä½ï¼Œé˜²æ­¢è¨ˆç®—å¤±æ•—æ™‚å°è‡´å¾ŒçºŒ KeyError
    if 'ç›®æ¨™åˆ†é…ç¯€æ•¸' not in df.columns: df['ç›®æ¨™åˆ†é…ç¯€æ•¸'] = 0.0
    if 'é è¨ˆé…åˆ†' not in df.columns: df['é è¨ˆé…åˆ†'] = 0.0

    try:
        # 1. çµ±ä¸€æ¬„ä½åç¨± (é˜²å‘†)
        if 'æˆèª²ç¯€æ•¸' in df.columns:
            df.rename(columns={'æˆèª²ç¯€æ•¸': 'å–®å…ƒç¸½ç¯€æ•¸'}, inplace=True)
        
        # 2. å¼·åˆ¶è½‰æ•¸å€¼ (é—œéµä¿®å¾©ï¼)
        # ç„¡è«– AI å¯«äº†ä»€éº¼æ–‡å­— (å¦‚ "æœªæä¾›...")ï¼Œä¸€å¾‹å¼·åˆ¶è½‰ç‚ºæ•¸å­—ï¼Œè½‰ä¸éçš„è®Šæˆ NaNï¼Œå†è£œæˆ 1
        df['å–®å…ƒç¸½ç¯€æ•¸'] = pd.to_numeric(df['å–®å…ƒç¸½ç¯€æ•¸'], errors='coerce').fillna(1)
        
        # 3. è¨ˆç®—æ¯å€‹å–®å…ƒçš„ç›®æ¨™æ•¸é‡
        unit_counts = df['å–®å…ƒåç¨±'].value_counts()
        
        # 4. åˆ†é…ç¯€æ•¸
        def distribute_hours(row):
            unit_name = row['å–®å…ƒåç¨±']
            total_unit_hours = row['å–®å…ƒç¸½ç¯€æ•¸']
            count = unit_counts.get(unit_name, 1)
            return total_unit_hours / count

        df['ç›®æ¨™åˆ†é…ç¯€æ•¸'] = df.apply(distribute_hours, axis=1)

        # 5. è¨ˆç®—ç¸½æ™‚æ•¸èˆ‡é…åˆ†
        unit_hours_map = df[['å–®å…ƒåç¨±', 'å–®å…ƒç¸½ç¯€æ•¸']].drop_duplicates()
        total_course_hours = unit_hours_map['å–®å…ƒç¸½ç¯€æ•¸'].sum()
        if total_course_hours == 0: total_course_hours = 1

        df['åŸå§‹é…åˆ†'] = (df['ç›®æ¨™åˆ†é…ç¯€æ•¸'] / total_course_hours) * 100
        df['é è¨ˆé…åˆ†'] = df['åŸå§‹é…åˆ†'].apply(lambda x: round(x, 1))

        # 6. å¾®èª¿ç¸½åˆ†è‡³ 100
        current_sum = df['é è¨ˆé…åˆ†'].sum()
        diff = 100 - current_sum
        if abs(diff) > 0.01: # åªæœ‰èª¤å·®å¤§æ–¼ 0.01 æ‰ä¿®æ­£
            df.iloc[-1, df.columns.get_loc('é è¨ˆé…åˆ†')] += diff

        return df
    except Exception as e:
        # å¦‚æœçœŸçš„ç™¼ç”ŸéŒ¯èª¤ï¼Œå°å‡ºéŒ¯èª¤ä½†ä¸è®“ç¨‹å¼å´©æ½°
        st.error(f"âš ï¸ é…åˆ†è¨ˆç®—ç™¼ç”Ÿä¾‹å¤–ç‹€æ³ (å·²è‡ªå‹•ç•¥é): {e}")
        return df

# --- 4. Excel ä¸‹è¼‰ (ä¿®å¾© KeyError) ---
def df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        export_df = df.copy()
        
        # å®šç¾©æœŸæœ›çš„æ¬„ä½é †åº
        desired_cols = ['å–®å…ƒåç¨±', 'å–®å…ƒç¸½ç¯€æ•¸', 'å­¸ç¿’ç›®æ¨™', 'ç›®æ¨™åˆ†é…ç¯€æ•¸', 'é è¨ˆé…åˆ†']
        
        # é—œéµä¿®å¾©ï¼šåªé¸æ“‡å­˜åœ¨çš„æ¬„ä½ï¼Œé¿å… KeyError
        final_cols = [c for c in desired_cols if c in export_df.columns]
        export_df = export_df[final_cols]
        
        if 'ç›®æ¨™åˆ†é…ç¯€æ•¸' in export_df.columns:
            export_df.rename(columns={'ç›®æ¨™åˆ†é…ç¯€æ•¸': 'æ­¤ç›®æ¨™ä½”ç”¨ç¯€æ•¸'}, inplace=True)
        
        export_df.to_excel(writer, index=False, sheet_name='å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨')
        workbook = writer.book
        worksheet = writer.sheets['å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨']
        
        header_fmt = workbook.add_format({'bold': True, 'align': 'center', 'bg_color': '#DCE6F1', 'border': 1})
        cell_fmt = workbook.add_format({'text_wrap': True, 'valign': 'top', 'border': 1})
        num_fmt = workbook.add_format({'num_format': '0.0', 'border': 1, 'align': 'center'})
        
        # å®‰å…¨è¨­å®šæ¬„å¯¬
        worksheet.set_column('A:A', 15, cell_fmt) 
        worksheet.set_column('B:B', 10, num_fmt) 
        worksheet.set_column('C:C', 60, cell_fmt) 
        worksheet.set_column('D:D', 12, num_fmt)
        worksheet.set_column('E:E', 12, num_fmt)
        
        for col_num, value in enumerate(export_df.columns.values):
            worksheet.write(0, col_num, value, header_fmt)
            
    return output.getvalue()

# --- 5. æ¨¡å‹é¸æ“‡ ---
def get_available_flash_model(api_key):
    try:
        genai.configure(api_key=api_key)
        valid_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        for m in valid_models:
             if 'flash' in m.lower(): return m
        return "models/gemini-1.5-flash"
    except: return "models/gemini-1.5-flash"

# --- 6. Prompt èª¿æ•´ (æ›´ç©©å®šçš„è¼¸å‡º) ---
GEM_EXTRACT_PROMPT = """
ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„æ•™æåˆ†æå¸«ã€‚è«‹åˆ†æä»¥ä¸‹æ•™æï¼Œæå–ã€Œå–®å…ƒåç¨±ã€ã€ã€Œå­¸ç¿’ç›®æ¨™ã€èˆ‡ã€Œå–®å…ƒç¸½æˆèª²ç¯€æ•¸ã€ã€‚

**è¼¸å‡ºè¦å‰‡ (åš´æ ¼åŸ·è¡Œ)ï¼š**
1. **æ ¼å¼**ï¼šåƒ…è¼¸å‡º Markdown è¡¨æ ¼ï¼Œæ¬„ä½ï¼š| å–®å…ƒåç¨± | å­¸ç¿’ç›®æ¨™ | æˆèª²ç¯€æ•¸ |
2. **å­¸ç¿’ç›®æ¨™æ‹†è§£**ï¼š
   - æ¯ä¸€æ¢é‡é»å¿…é ˆç¨ç«‹æ‹†æˆ Excel çš„ä¸€åˆ— (Row)ã€‚
   - **åš´ç¦åˆä½µ**ã€‚
3. **æˆèª²ç¯€æ•¸ (æ•¸å­—)**ï¼š
   - è©²æ¬„ä½**å¿…é ˆå¡«å…¥ç´”æ•¸å­—** (ä¾‹å¦‚ 5, 4, 2)ã€‚
   - å¦‚æœæ•™ææ²’å¯«ç¯€æ•¸ï¼Œ**è«‹ç›´æ¥å¡«å…¥ "1"**ï¼Œä¸è¦å¯«æ–‡å­—èªªæ˜ (å¦‚ "æœªæä¾›...")ã€‚
   - è©²å–®å…ƒçš„æ¯ä¸€åˆ—éƒ½å¡«å…¥ç›¸åŒçš„ç¸½ç¯€æ•¸ã€‚

æ•™æå…§å®¹ï¼š
{content}
"""

# --- 7. ä¸»ç¨‹å¼ ---
st.set_page_config(page_title="å…§æ¹–åœ‹å°å‡ºé¡Œç³»çµ± (Pro)", layout="wide")

st.markdown("""<div style="background:#1E293B;padding:15px;text-align:center;color:white;border-radius:10px;">
<h2>å…§æ¹–åœ‹å° AI å‘½é¡Œç³»çµ± (ç´°ç›®æ‹†è§£ç‰ˆ)</h2></div>""", unsafe_allow_html=True)

if "extracted_data" not in st.session_state: st.session_state.extracted_data = None
if "step" not in st.session_state: st.session_state.step = 1

with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("API Key", type="password")
    if st.button("é‡ç½®"): 
        st.session_state.extracted_data = None
        st.session_state.step = 1
        st.rerun()
    
    st.divider()
    with st.expander("ğŸ› ï¸ è½‰æª”å·¥å…·ç®±"):
        st.markdown("[Word è½‰æª”](https://cloudconvert.com/doc-to-docx)")
        st.markdown("[PPT è½‰æª”](https://cloudconvert.com/ppt-to-pptx)")
        st.markdown("[PDF è½‰æ–‡å­— (OCR)](https://www.ilovepdf.com/zh-tw/pdf_to_word)")

if st.session_state.step == 1:
    uploaded_files = st.file_uploader("ä¸Šå‚³æ•™æ", type=["pdf","docx","pptx","txt"], accept_multiple_files=True)
    if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
        if api_key and uploaded_files:
            with st.spinner("AI æ­£åœ¨é€æ¢æ‹†è§£å­¸ç¿’ç›®æ¨™..."):
                try:
                    text = extract_text_from_files(uploaded_files)
                    model_name = get_available_flash_model(api_key)
                    model = genai.GenerativeModel(model_name)
                    res = model.generate_content(GEM_EXTRACT_PROMPT.format(content=text[:40000]))
                    
                    lines = [l.strip() for l in res.text.split('\n') if "|" in l and "---" not in l]
                    data = []
                    for l in lines:
                        row = [c.strip() for c in l.split('|') if c.strip()]
                        if len(row) >= 3: data.append(row[:3])
                    
                    if data:
                        df = pd.DataFrame(data[1:], columns=["å–®å…ƒåç¨±", "å­¸ç¿’ç›®æ¨™", "æˆèª²ç¯€æ•¸"])
                        # æ¬„ä½é‡æ–°å‘½å (èˆ‡ calculate_scores å°é½Š)
                        df.rename(columns={"æˆèª²ç¯€æ•¸": "å–®å…ƒç¸½ç¯€æ•¸"}, inplace=True)
                        
                        df_cal = calculate_scores(df)
                        st.session_state.extracted_data = df_cal
                        st.session_state.step = 2
                        st.rerun()
                    else:
                        st.error("AI æœªåµæ¸¬åˆ°è¡¨æ ¼è³‡æ–™ï¼Œè«‹æª¢æŸ¥æ•™æå…§å®¹æ˜¯å¦æ¸…æ™°ã€‚")
                except Exception as e: st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")

elif st.session_state.step == 2:
    st.info("ğŸ’¡ ä¿®æ­£æ¨¡å¼ï¼šè‹¥ AI å¡«å¯«çš„ç¯€æ•¸ç‚º 1 (é è¨­å€¼)ï¼Œè«‹æ‰‹å‹•ä¿®æ”¹ã€Œå–®å…ƒç¸½ç¯€æ•¸ã€ï¼Œé…åˆ†æœƒè‡ªå‹•é‡ç®—ã€‚")
    
    df_curr = st.session_state.extracted_data
    
    # ç·¨è¼¯å™¨
    edited_df = st.data_editor(
        df_curr,
        column_config={
            "å–®å…ƒåç¨±": st.column_config.TextColumn(disabled=True),
            "å­¸ç¿’ç›®æ¨™": st.column_config.TextColumn(width="large"),
            "å–®å…ƒç¸½ç¯€æ•¸": st.column_config.NumberColumn("å–®å…ƒç¸½ç¯€æ•¸", min_value=1, max_value=50, help="ä¿®æ”¹æ­¤æ•¸å­—ï¼Œè©²å–®å…ƒæ‰€æœ‰ç›®æ¨™çš„é…åˆ†æœƒè‡ªå‹•æ›´æ–°"),
            "ç›®æ¨™åˆ†é…ç¯€æ•¸": st.column_config.NumberColumn("æ­¤ç›®æ¨™ä½”ç”¨", disabled=True, format="%.2f"),
            "é è¨ˆé…åˆ†": st.column_config.NumberColumn("é…åˆ† (%)", disabled=True)
        },
        use_container_width=True,
        num_rows="dynamic"
    )
    
    # å³æ™‚é‡ç®—
    if not edited_df.equals(df_curr):
        st.session_state.extracted_data = calculate_scores(edited_df)
        st.rerun()

    st.download_button("ä¸‹è¼‰ Excel", df_to_excel(edited_df), "ç´°ç›®å¯©æ ¸è¡¨.xlsx")
    if st.button("é‡æ–°ä¸Šå‚³"): st.session_state.step=1; st.rerun()
