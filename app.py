import subprocess
import sys
import os
import re

# --- 0. è‡ªå‹•å®‰è£ä¾è³´å¥—ä»¶ (Auto-Install) ---
# é€™æ®µç¨‹å¼ç¢¼æœƒè‡ªå‹•æª¢æŸ¥ä¸¦å®‰è£ç¼ºå°‘çš„å¥—ä»¶ï¼Œé˜²æ­¢åŸ·è¡Œå¤±æ•—
def install_package(package):
    try:
        __import__(package)
    except ImportError:
        print(f"ğŸ“¦ æ­£åœ¨è‡ªå‹•å®‰è£ {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])

# æª¢æŸ¥æ¸…å–®
install_package("xlsxwriter")
install_package("pypdf")
install_package("docx")
install_package("pandas")
install_package("google.generativeai")
install_package("streamlit")

# -------------------------------------------

import streamlit as st
import google.generativeai as genai
import random
import io
import time
from pypdf import PdfReader
from docx import Document
import pandas as pd

# --- 1. å®šç¾©å­¸ç§‘èˆ‡é¡Œå‹æ˜ å°„ ---
SUBJECT_Q_TYPES = {
    "åœ‹èª": ["åœ‹å­—æ³¨éŸ³", "é€ å¥", "å–®é¸é¡Œ", "é–±è®€ç´ é¤Šé¡Œ", "å¥å‹è®Šæ›", "ç°¡ç­”é¡Œ"],
    "æ•¸å­¸": ["æ‡‰ç”¨è¨ˆç®—é¡Œ", "åœ–è¡¨åˆ†æé¡Œ", "å¡«å……é¡Œ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ"],
    "è‡ªç„¶ç§‘å­¸": ["å¯¦é©—åˆ¤è®€é¡Œ", "åœ–è¡¨åˆ†æé¡Œ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "é…åˆé¡Œ"],
    "ç¤¾æœƒ": ["åœ°åœ–åˆ¤è®€é¡Œ", "æƒ…å¢ƒæ¡ˆä¾‹åˆ†æ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ", "é…åˆé¡Œ", "ç°¡ç­”é¡Œ"],
    "è‹±èª": ["è‹±èªæœƒè©±é¸æ“‡", "è©å½™æ­é…", "æ–‡æ„é¸å¡«", "å–®é¸é¡Œ", "é–±è®€ç†è§£"],
    "": ["å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "ç°¡ç­”é¡Œ"]
}

# --- 2. æª”æ¡ˆè®€å–å·¥å…· (å¼·åŒ–ç‰ˆï¼šåˆ†é +æ¸…æ´—) ---
@st.cache_data
def extract_text_from_files(files):
    text_content = ""
    for file in files:
        try:
            file_text = ""
            ext = file.name.split('.')[-1].lower()
            
            if ext == 'pdf':
                pdf_reader = PdfReader(file)
                # åŠ ä¸Šé ç¢¼æ¨™è¨˜ï¼Œå¹«åŠ© AI å€åˆ†å–®å…ƒé‚Šç•Œ
                for i, page in enumerate(pdf_reader.pages):
                    content = page.extract_text() or ""
                    file_text += f"\n--- Page {i+1} ---\n{content}"
            elif ext == 'docx':
                doc = Document(file)
                # ä¿ç•™æ®µè½çµæ§‹
                file_text = "\n".join([p.text for p in doc.paragraphs])
            elif ext == 'doc':
                # å˜—è©¦è™•ç†èˆŠç‰ˆ Wordï¼Œè‹¥å¤±æ•—å‰‡å¿½ç•¥
                try:
                    with open("temp.doc", "wb") as f: f.write(file.getbuffer())
                    result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
                    if result.returncode == 0:
                        file_text = result.stdout
                    if os.path.exists("temp.doc"): os.remove("temp.doc")
                except:
                    file_text = "[èˆŠç‰ˆ .doc è®€å–å¤±æ•—ï¼Œè«‹è½‰å­˜ç‚º .docx]"
            
            # --- æ–‡å­—æ¸…æ´—å€ ---
            # ç§»é™¤é€£çºŒå¤šé¤˜çš„ç©ºè¡Œï¼Œç¯€çœ Token
            file_text = re.sub(r'\n\s*\n', '\n\n', file_text)
            text_content += f"\n\n=== æª”æ¡ˆ: {file.name} ===\n{file_text}"
            
        except Exception as e:
            text_content += f"\n[è®€å–éŒ¯èª¤: {file.name} - {str(e)}]"
            
    return text_content

# --- 3. Excel ä¸‹è¼‰å·¥å…· (å«ï¼šæŠ—æ²¾é» + åˆ†æ•¸è‡ªå‹•æ ¡æ­£ + ç¾åŒ–) ---
def md_to_excel(md_text):
    try:
        # Step 1: é è™•ç† - ä¿®å¾© AI å¯èƒ½çš„æ ¼å¼éŒ¯èª¤
        cleaned_text = md_text.replace("||", "|\n|")
        
        lines = cleaned_text.strip().split('\n')
        table_lines = []
        is_table_started = False
        
        # Step 2: æŠ“å–è¡¨æ ¼å…§å®¹
        for line in lines:
            if ("å–®å…ƒ" in line or "ç›®æ¨™" in line or "é…åˆ†" in line) and "|" in line:
                is_table_started = True
                table_lines.append(line)
                continue
            
            if is_table_started:
                if "---" in line: continue
                if "|" in line:
                    table_lines.append(line)
                
        if not table_lines: return None

        # Step 3: è³‡æ–™è§£æ
        data = []
        for line in table_lines:
            row = [cell.strip() for cell in line.strip('|').split('|')]
            data.append(row)

        if len(data) < 2: return None

        headers = data[0]
        rows = data[1:]
        
        # Step 4: å¼·åŠ›è£œé½Šèˆ‡åˆ‡å‰Š
        max_cols = len(headers)
        cleaned_rows = []
        for r in rows:
            if len(r) == max_cols:
                cleaned_rows.append(r)
            elif len(r) < max_cols:
                cleaned_rows.append(r + [''] * (max_cols - len(r)))
            else:
                cleaned_rows.append(r[:max_cols])

        df = pd.DataFrame(cleaned_rows, columns=headers)
        
        # --- ğŸ”¥ åˆ†æ•¸è‡ªå‹•æ ¡æ­£ (Normalization) ---
        score_col = None
        for col in df.columns:
            if "é…åˆ†" in col:
                score_col = col
                break
        
        if score_col:
            try:
                # æå–æ•¸å­—
                scores = []
                for x in df[score_col]:
                    nums = re.findall(r'\d+', str(x))
                    scores.append(float(nums[0]) if nums else 0.0)
                
                current_total = sum(scores)
                
                # å¦‚æœç¸½åˆ†ä¸æ˜¯ 100ï¼Œä¸”å¤§æ–¼ 0ï¼Œé€²è¡Œæ ¡æ­£
                if current_total > 0 and current_total != 100:
                    st.toast(f"âš–ï¸ ç³»çµ±è‡ªå‹•æ ¡æ­£ï¼šå°‡åŸå§‹ç¸½åˆ† {int(current_total)} åˆ†ä¾æ¯”ä¾‹èª¿æ•´ç‚º 100 åˆ†ã€‚", icon="âœ…")
                    
                    new_scores = [(s / current_total) * 100 for s in scores]
                    rounded_scores = [round(s) for s in new_scores]
                    
                    # è™•ç†å››æ¨äº”å…¥èª¤å·®ï¼Œå°‡å·®é¡è£œåœ¨åˆ†æ•¸æœ€é«˜çš„é‚£é …
                    diff = 100 - sum(rounded_scores)
                    if diff != 0:
                        max_idx = rounded_scores.index(max(rounded_scores))
                        rounded_scores[max_idx] += diff
                    
                    df[score_col] = rounded_scores
            except:
                pass # è‹¥æ ¡æ­£å¤±æ•—å‰‡ç¶­æŒåŸæ¨£
        # ------------------------------------

        # Step 5: ä½¿ç”¨ XlsxWriter å¼•æ“é€²è¡Œç¾åŒ–
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨')
            workbook = writer.book
            worksheet = writer.sheets['å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨']
            
            wrap_format = workbook.add_format({'text_wrap': True, 'valign': 'vcenter'})
            header_format = workbook.add_format({
                'bold': True, 'text_wrap': True, 'valign': 'vcenter', 
                'fg_color': '#D7E4BC', 'border': 1
            })

            # è¨­å®šæ¨™é¡Œåˆ—æ ¼å¼
            for col_num, value in enumerate(df.columns.values):
                worksheet.write(0, col_num, value, header_format)

            # è¨­å®šæ¬„å¯¬
            worksheet.set_column(0, 0, 15, wrap_format) # å–®å…ƒ
            worksheet.set_column(1, 1, 55, wrap_format) # å­¸ç¿’ç›®æ¨™ (æœ€å¯¬)
            worksheet.set_column(2, 2, 20, wrap_format) # é¡Œå‹
            worksheet.set_column(3, 3, 10, wrap_format) # é…åˆ†
                
        return output.getvalue()
    except Exception as e:
        print(f"Excel è½‰æ›å¤±æ•—: {e}")
        return None

# --- 4. æ ¸å¿ƒ Gem å‘½é¡Œéµå¾‹ (Phase 1 å°ˆç”¨) ---
GEM_INSTRUCTIONS_PHASE1 = """
ä½ æ˜¯ã€Œåœ‹å°å°ˆæ¥­å®šæœŸè©•é‡å‘½é¡Œ AIã€ã€‚

### âš ï¸ Phase 1 ä»»å‹™ç›®æ¨™ï¼š
è«‹é–±è®€ä½¿ç”¨è€…æä¾›çš„æ•™æå…§å®¹ï¼Œæ•´ç†å‡ºä¸€ä»½ã€å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨ã€‘ã€‚

### çµ•å°è¦å‰‡ (é•åå°‡å°è‡´ç³»çµ±å´©æ½°)ï¼š
1. **é…åˆ†é‚è¼¯**ï¼šè«‹æ ¹æ“šå„å–®å…ƒå…§å®¹çš„ã€Œç¯‡å¹…é•·åº¦ã€èˆ‡ã€Œé‡è¦æ€§ã€ï¼Œå°‡ç¸½åˆ†åˆ†é…ç‚º **å‰›å¥½ 100 åˆ†**ã€‚
2. **ç¦æ­¢å»¢è©±**ï¼š**åš´ç¦** æ’°å¯«å‰è¨€ (å¦‚ "å¥½çš„ï¼Œé€™æ˜¯æˆ‘æ•´ç†çš„...") æˆ–çµèªã€‚
3. **ç¦æ­¢å‡ºé¡Œ**ï¼šç¾åœ¨é‚„ä¸æ˜¯å‡ºé¡Œéšæ®µï¼Œ**åš´ç¦** ç”¢å‡ºé¡Œç›®ã€‚
4. **æ ¼å¼è¦æ±‚**ï¼š
   - åƒ…è¼¸å‡ºæ¨™æº– Markdown è¡¨æ ¼ã€‚
   - æ¬„ä½å¿…é ˆåŒ…å«ï¼š| å–®å…ƒåç¨± | å­¸ç¿’ç›®æ¨™(åŸæ–‡) | å°æ‡‰é¡Œå‹ | é è¨ˆé…åˆ† |
   - **æ¯ä¸€åˆ—è³‡æ–™å¿…é ˆå¼·åˆ¶æ›è¡Œ**ï¼Œä¸å¯æ¥åœ¨åŒä¸€è¡Œã€‚
"""

# --- 5. æ™ºèƒ½æ¨¡å‹èˆ‡å·¥å…· ---
def get_best_model(api_key, mode="fast"):
    genai.configure(api_key=api_key)
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        if not models: return None, "æ‰¾ä¸åˆ°å¯ç”¨æ¨¡å‹"
        target_model = None
        if mode == "fast":
            for m in models:
                if 'flash' in m.lower(): target_model = m; break
            if not target_model: target_model = models[0]
        elif mode == "smart":
            for m in models:
                if 'pro' in m.lower() and '1.5' in m.lower(): target_model = m; break
            if not target_model: target_model = models[0]
        return target_model, None
    except Exception as e: return None, str(e)

def generate_with_retry(model_or_chat, prompt, stream=True):
    max_retries = 3
    for i in range(max_retries):
        try:
            if hasattr(model_or_chat, 'send_message'):
                return model_or_chat.send_message(prompt, stream=stream)
            else:
                return model_or_chat.generate_content(prompt, stream=stream)
        except Exception as e:
            if "429" in str(e):
                time.sleep((i + 1) * 3)
            else:
                raise e
    raise Exception("é€£ç·šé€¾æ™‚ï¼Œè«‹æª¢æŸ¥ API Key æˆ–ç¶²è·¯ç‹€æ…‹ã€‚")

# --- 6. ä»‹é¢è¨­å®š ---
st.set_page_config(page_title="å…§æ¹–åœ‹å° AI è¼”åŠ©å‡ºé¡Œç³»çµ±", layout="wide")

st.markdown("""
    <style>
    header[data-testid="stHeader"] { display: none !important; visibility: hidden !important; }
    footer { display: none !important; visibility: hidden !important; }
    .stApp { background-color: #0F172A; }
    .block-container { max-width: 1200px; padding-top: 1.5rem !important; padding-bottom: 5rem; }
    .school-header {
        background: linear-gradient(90deg, #1E293B 0%, #334155 100%);
        padding: 25px; border-radius: 18px; text-align: center; margin-bottom: 25px; 
        border: 1px solid #475569;
    }
    .school-name { font-size: 26px; font-weight: 700; color: #F1F5F9; letter-spacing: 3px; }
    .app-title { font-size: 15px; color: #94A3B8; margin-top: 6px; }
    h1, h2, h3, p, span, label, .stMarkdown { color: #E2E8F0 !important; }
    .comfort-box {
        background-color: #1E293B; padding: 15px; border-radius: 10px; 
        margin-bottom: 15px; border-left: 5px solid #3B82F6; 
        font-size: 14px; color: #CBD5E1; line-height: 1.8;
    }
    .comfort-box b { color: #fff; }
    .comfort-box a { color: #60A5FA !important; text-decoration: none; font-weight: bold; }
    [data-testid="stSidebar"] .stMarkdown { margin-bottom: 10px; } 
    .stTextArea textarea { min-height: 80px; }
    .stTextArea { margin-bottom: 15px !important; }
    [data-testid="stSidebar"] .stButton > button { 
        display: block; margin: 15px auto !important; 
        width: 100%; border-radius: 8px; height: 42px;
        background-color: #334155; border: 1px solid #475569; font-size: 15px;
    }
    .custom-footer { 
        position: fixed; left: 0; bottom: 0; width: 100%; 
        background-color: #0F172A; color: #475569; 
        text-align: center; padding: 12px; font-size: 11px; 
        border-top: 1px solid #1E293B; z-index: 100; 
    }
    </style>
    <div class="school-header">
        <div class="school-name">æ–°ç«¹å¸‚é¦™å±±å€å…§æ¹–åœ‹å°</div>
        <div class="app-title">è©•é‡å‘½é¡Œèˆ‡å­¸ç¿’ç›®æ¨™è‡ªå‹•åŒ–ç³»çµ±</div>
    </div>
    """, unsafe_allow_html=True)

if "phase" not in st.session_state: st.session_state.phase = 1 
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "last_prompt_content" not in st.session_state: st.session_state.last_prompt_content = ""

# --- Sidebar ---
with st.sidebar:
    st.markdown("### ğŸš€ ç³»çµ±è¨­å®š")
    api_input = st.text_area("åœ¨æ­¤è¼¸å…¥ API Key", height=80, placeholder="è«‹è²¼ä¸Š Google AI Studio é‡‘é‘°...")
    
    if st.button("ğŸ”„ é‡ç½®ç³»çµ±"):
        st.session_state.phase = 1
        st.session_state.chat_history = []
        st.session_state.last_prompt_content = ""
        st.rerun()

    st.markdown("### ğŸ“š è³‡æºé€£çµ")
    st.markdown("""
    <div class="comfort-box">
        <b>æ•™æä¸‹è¼‰ï¼š</b><br>
        â€¢ <a href="https://webetextbook.knsh.com.tw/" target="_blank">åº·è»’é›»å­æ›¸</a><br>
        â€¢ <a href="https://edisc3.hle.com.tw/" target="_blank">ç¿°æ—è¡Œå‹•å¤§å¸«</a><br>
        â€¢ <a href="https://reader.nani.com.tw/" target="_blank">å—ä¸€ OneBox</a>
    </div>
    """, unsafe_allow_html=True)

# --- Phase 1: åƒæ•¸è¨­å®šèˆ‡æ•™æä¸Šå‚³ ---
if st.session_state.phase == 1:
    with st.container(border=True):
        st.markdown("### ğŸ“ ç¬¬ä¸€éšæ®µï¼šåƒæ•¸è¨­å®šèˆ‡æ•™æä¸Šå‚³")
        
        c1, c2, c3 = st.columns(3)
        with c1: grade = st.selectbox("1. é¸æ“‡å¹´ç´š", ["", "ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"], index=0)
        with c2: subject = st.selectbox("2. é¸æ“‡ç§‘ç›®", ["", "åœ‹èª", "æ•¸å­¸", "è‡ªç„¶ç§‘å­¸", "ç¤¾æœƒ", "è‹±èª"], index=0)
        with c3: mode = st.selectbox("3. å‘½é¡Œæ¨¡å¼", ["ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­", "ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£", "ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š"], index=0)
        
        st.divider()
        st.markdown("**4. å‹¾é¸æ¬²ç”¢å‡ºçš„é¡Œå‹**")
        available_types = SUBJECT_Q_TYPES.get(subject, SUBJECT_Q_TYPES[""])
        cols = st.columns(min(len(available_types), 4))
        selected_types = []
        for i, t in enumerate(available_types):
            if cols[i % len(cols)].checkbox(t, value=True):
                selected_types.append(t)
        
        st.divider()
        uploaded_files = st.file_uploader("5. ä¸Šå‚³æ•™ææª”æ¡ˆ (Word/PDF)", type=["pdf", "docx", "doc"], accept_multiple_files=True)
        
        if st.button("ğŸš€ ç”¢å‡ºå­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨", type="primary", use_container_width=True):
            if not api_input:
                st.error("âŒ å‹•ä½œä¸­æ­¢ï¼šå´é‚Šæ¬„å°šæœªè¼¸å…¥ API Keyã€‚")
            elif not grade or not subject or not uploaded_files or not selected_types:
                st.warning("âš ï¸ å‹•ä½œä¸­æ­¢ï¼šè«‹ç¢ºèªå¹´ç´šã€ç§‘ç›®ã€é¡Œå‹èˆ‡æ•™æå·²å‚™å¦¥ã€‚")
            else:
                with st.spinner("âš¡ æ­£åœ¨æ¥µé€Ÿæƒææ•™æå…§å®¹ï¼Œè«‹ç¨å€™..."):
                    keys = [k.strip() for k in api_input.replace('\n', ',').split(',') if k.strip()]
                    target_key = random.choice(keys)
                    model_name, error_msg = get_best_model(target_key, mode="fast")
                    
                    if error_msg:
                        st.error(f"âŒ API é€£ç·šéŒ¯èª¤ï¼š{error_msg}")
                    else:
                        content = extract_text_from_files(uploaded_files)
                        try:
                            st.toast(f"âš¡ å•Ÿå‹• AI å¼•æ“ ({model_name}) åˆ†æä¸­...", icon="ğŸ¤–")
                            
                            model_fast = genai.GenerativeModel(
                                model_name=model_name,
                                system_instruction=GEM_INSTRUCTIONS_PHASE1, 
                                generation_config={"temperature": 0.0}
                            )
                            
                            chat = model_fast.start_chat(history=[])
                            
                            with st.chat_message("ai"):
                                message_placeholder = st.empty()
                                full_response = ""
                                t_str = "ã€".join(selected_types)
                                
                                prompt_content = f"""
                                ä»»å‹™ï¼šåˆ†æä»¥ä¸‹æ•™æä¸¦ç”¢å‡ºå¯©æ ¸è¡¨ã€‚
                                ã€åƒæ•¸è¨­å®šã€‘å¹´ç´šï¼š{grade}, ç§‘ç›®ï¼š{subject}, å¯ç”¨é¡Œå‹ï¼š{t_str}
                                ã€æ•™æå…§å®¹ã€‘{content}
                                ã€åŸ·è¡Œæ­¥é©Ÿã€‘
                                1. è­˜åˆ¥æ•™æä¸­çš„å–®å…ƒçµæ§‹ã€‚
                                2. æå–å…·é«”çš„å­¸ç¿’ç›®æ¨™ã€‚
                                3. æ ¹æ“šå…§å®¹é•·åº¦ï¼Œè¨ˆç®—è©²å–®å…ƒæ‡‰ä½”ç¸½åˆ† 100 åˆ†ä¸­çš„å¤šå°‘æ¯”ä¾‹ã€‚
                                4. åƒ…è¼¸å‡º Markdown è¡¨æ ¼ã€‚
                                """
                                st.session_state.last_prompt_content = prompt_content
                                response = generate_with_retry(chat, prompt_content, stream=True)
                                
                                for chunk in response:
                                    if chunk.text:
                                        full_response += chunk.text
                                        message_placeholder.markdown(full_response + "â–Œ")
                                message_placeholder.markdown(full_response)
                            
                            # ç°¡å–®é˜²å‘†
                            if "|" in full_response and "å–®å…ƒ" in full_response:
                                st.session_state.chat_history.append({"role": "model", "content": full_response})
                                st.session_state.phase = 2
                                time.sleep(1)
                                st.rerun()
                            else:
                                st.error("âŒ AI ç”¢å‡ºæ ¼å¼ç•°å¸¸ï¼Œæœªåµæ¸¬åˆ°è¡¨æ ¼ï¼Œè«‹é‡è©¦ã€‚")
                                
                        except Exception as e: 
                            st.error(f"é€£ç·šå¤±æ•—ï¼š{e} (è«‹æª¢æŸ¥ API Key æˆ–ç¨å¾Œé‡è©¦)")

# --- Phase 2: ä¸‹è¼‰èˆ‡ç¢ºèª ---
elif st.session_state.phase == 2:
    current_md = st.session_state.chat_history[0]["content"]
    
    with st.container(border=True):
        st.markdown("### ğŸ“¥ ç¬¬äºŒéšæ®µï¼šä¸‹è¼‰å¯©æ ¸è¡¨")
        st.info("è«‹ä¸‹è¼‰ Excel è¡¨æ ¼ï¼Œç¢ºèªé…åˆ†èˆ‡å­¸ç¿’ç›®æ¨™æ˜¯å¦æ­£ç¢ºã€‚ç¢ºèªç„¡èª¤å¾Œè«‹é»æ“Šä¸‹æ–¹æŒ‰éˆ•é€²å…¥å‡ºé¡Œéšæ®µã€‚")
        
        with st.expander("ğŸ‘ï¸ é è¦½ AI ç”¢å‡ºçš„è¡¨æ ¼å…§å®¹", expanded=False):
            st.markdown(current_md)
        
        # Excel è½‰æ› (åŒ…å«è‡ªå‹•é…åˆ†æ ¡æ­£)
        excel_data = md_to_excel(current_md)
        
        c1, c2 = st.columns([1, 1])
        with c1:
            if excel_data:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ Excel å¯©æ ¸è¡¨ (.xlsx)",
                    data=excel_data,
                    file_name=f"å…§æ¹–åœ‹å°_{st.session_state.get('subject', 'ç§‘ç›®')}_å¯©æ ¸è¡¨.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            else:
                st.warning("âš ï¸ è¡¨æ ¼è½‰æ›å¤±æ•—")
        
        with c2:
             if st.button("â¬…ï¸ è¿”å›é‡ä¾† (æ¸…é™¤è³‡æ–™)", use_container_width=True):
                st.session_state.phase = 1
                st.session_state.chat_history = []
                st.rerun()

    st.divider()
    
    if st.button("âœ… å¯©æ ¸ç„¡èª¤ï¼Œé–‹å§‹æ­£å¼å‘½é¡Œ (Phase 3)", type="primary", use_container_width=True):
        st.toast("ğŸš€ é€²å…¥ Phase 3... (åŠŸèƒ½é–‹ç™¼ä¸­)", icon="ğŸš§")
        # æœªä¾†åŠŸèƒ½ï¼š
        # st.session_state.phase = 3
        # st.rerun()

st.markdown('<div class="custom-footer">Â© 2026 æ–°ç«¹å¸‚é¦™å±±å€å…§æ¹–åœ‹å°. All Rights Reserved.</div>', unsafe_allow_html=True)
