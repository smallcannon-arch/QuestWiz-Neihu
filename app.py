import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from docx import Document
import pandas as pd
import subprocess
import os

# --- 1. æª”æ¡ˆè®€å–å·¥å…· ---
def read_pdf(file):
    pdf_reader = PdfReader(file)
    return "".join([p.extract_text() or "" for p in pdf_reader.pages])

def read_docx(file):
    doc = Document(file)
    return "\n".join([p.text for p in doc.paragraphs])

def read_doc(file):
    with open("temp.doc", "wb") as f:
        f.write(file.getbuffer())
    try:
        result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
        return result.stdout if result.returncode == 0 else "[DOC è®€å–éŒ¯èª¤]"
    except: return "[ç³»çµ±æœªå®‰è£ antiword]"
    finally:
        if os.path.exists("temp.doc"): os.remove("temp.doc")

# --- 2. ç¶²é ä»‹é¢ ---
st.set_page_config(page_title="QuestWiz å…§æ¹–åœ‹å°ç‰ˆ", layout="wide")
st.title("ğŸ« QuestWiz è©¦é¡Œè¡Œæ”¿åŠ©æ‰‹ (ç©©å®šç‰ˆ)")

with st.sidebar:
    st.header("ğŸ”‘ ç³»çµ±è¨­å®š")
    st.markdown("[ğŸ‘‰ ç”³è«‹é‡‘é‘°](https://aistudio.google.com/app/apikey)")
    api_key = st.text_input("è²¼ä¸Šæ‚¨çš„ Gemini API Key", type="password")
    st.divider()
    st.info("ğŸ’¡ æç¤ºï¼šæœ¬ç‰ˆå·²å¼·åˆ¶é—œé–‰ AI å‰µé€ åŠ›ï¼Œç¢ºä¿è¨ˆç®—ç²¾æº–ã€‚")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- ç¬¬ä¸€éšæ®µï¼šæª”æ¡ˆä¸Šå‚³ ---
if not st.session_state.chat_history:
    with st.container(border=True):
        grade = st.selectbox("å¹´ç´š", ["ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"], index=4)
        subject = st.selectbox("ç§‘ç›®", ["è‡ªç„¶ç§‘å­¸", "åœ‹èª", "æ•¸å­¸", "ç¤¾æœƒ"], index=0)
        uploaded_files = st.file_uploader("ä¸Šå‚³æ•™æ (PDF/Word/CSV)", type=["pdf", "docx", "doc", "csv"], accept_multiple_files=True)
        start_btn = st.button("ğŸš€ ç”¢å‡ºè©¦é¡Œå¯©æ ¸è¡¨", type="primary", use_container_width=True)

    if start_btn and api_key and uploaded_files:
        all_content = ""
        for f in uploaded_files:
            ext = f.name.split('.')[-1].lower()
            if ext == 'pdf': all_content += read_pdf(f)
            elif ext == 'docx': all_content += read_docx(f)
            elif ext == 'doc': all_content += read_doc(f)
            elif ext == 'csv': all_content += pd.read_csv(f, encoding_errors='ignore').to_string()
        
        try:
            genai.configure(api_key=api_key)
            
            # è¨ºæ–·å¯ç”¨å‹è™Ÿ
            available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            # å„ªå…ˆé †åºï¼š1.5-flash (æœ€ç©©) > 1.5-pro > 2.5
            target = ""
            for m in ["models/gemini-1.5-flash", "models/gemini-1.5-pro", "models/gemini-2.5-flash"]:
                if m in available:
                    target = m
                    break
            if not target: target = available[0]

            # --- é—œéµä¿®æ­£ï¼šåŠ å…¥ generation_config ç¦æ­¢ AI äº‚ç·¨æ•…äº‹ ---
            model = genai.GenerativeModel(
                model_name=target,
                generation_config={"temperature": 0.0} # è¨­ç‚º 0 ä»£è¡¨æœ€åš´è¬¹ï¼Œä¸å…è¨±éš¨æ©Ÿç™¼æ®
            )
            
            chat = model.start_chat(history=[])
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {target} åš´è¬¹è¨ˆç®—ä¸­..."):
                prompt = f"ä½ æ˜¯å…§æ¹–åœ‹å°è¡Œæ”¿åŠ©æ‰‹ã€‚è«‹åš´è¬¹åˆ†æä»¥ä¸‹å…§å®¹ä¸¦ç”¢å‡ºã€è©¦é¡Œå¯©æ ¸è¡¨ã€è¡¨æ ¼ã€‚ç¦æ­¢è¼¸å‡ºèˆ‡æ•™æç„¡é—œçš„æ•…äº‹å…§å®¹ã€‚\nç§‘ç›®ï¼š{subject}\nå…§å®¹ï¼š{all_content}"
                response = chat.send_message(prompt)
                st.session_state.chat_session = chat
                st.session_state.chat_history.append({"role": "model", "content": response.text})
                st.rerun()
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—ï¼š{e}")
else:
    for msg in st.session_state.chat_history:
        with st.chat_message("ai" if msg["role"] == "model" else "user"):
            st.markdown(msg["content"])
    if prompt := st.chat_input("è«‹è¼¸å…¥æŒ‡ä»¤..."):
        res = st.session_state.chat_session.send_message(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        st.session_state.chat_history.append({"role": "model", "content": res.text})
        st.rerun()
