import subprocess
import sys
import os
import re

# --- 0. è‡ªå‹•å®‰è£ä¾è³´å¥—ä»¶ ---
def install_package(package):
    try:
        __import__(package)
    except ImportError:
        print(f"ğŸ“¦ æ­£åœ¨è‡ªå‹•å®‰è£ {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])

install_package("xlsxwriter")
install_package("pypdf")
install_package("docx")
install_package("pandas")
install_package("google.generativeai")
install_package("streamlit")

# -------------------------------------------

import streamlit as st
import google.generativeai as genai
import random
import io
import time
from pypdf import PdfReader
from docx import Document
import pandas as pd

# --- 1. å®šç¾©å­¸ç§‘èˆ‡é¡Œå‹æ˜ å°„ ---
SUBJECT_Q_TYPES = {
    "åœ‹èª": ["åœ‹å­—æ³¨éŸ³", "é€ å¥", "å–®é¸é¡Œ", "é–±è®€ç´ é¤Šé¡Œ", "å¥å‹è®Šæ›", "ç°¡ç­”é¡Œ"],
    "æ•¸å­¸": ["æ‡‰ç”¨è¨ˆç®—é¡Œ", "åœ–è¡¨åˆ†æé¡Œ", "å¡«å……é¡Œ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ"],
    "è‡ªç„¶ç§‘å­¸": ["å¯¦é©—åˆ¤è®€é¡Œ", "åœ–è¡¨åˆ†æé¡Œ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "é…åˆé¡Œ"],
    "ç¤¾æœƒ": ["åœ°åœ–åˆ¤è®€é¡Œ", "æƒ…å¢ƒæ¡ˆä¾‹åˆ†æ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ", "é…åˆé¡Œ", "ç°¡ç­”é¡Œ"],
    "è‹±èª": ["è‹±èªæœƒè©±é¸æ“‡", "è©å½™æ­é…", "æ–‡æ„é¸å¡«", "å–®é¸é¡Œ", "é–±è®€ç†è§£"],
    "": ["å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "ç°¡ç­”é¡Œ"]
}

# --- 2. æª”æ¡ˆè®€å–å·¥å…· ---
@st.cache_data
def extract_text_from_files(files):
    text_content = ""
    for file in files:
        try:
            file_text = ""
            ext = file.name.split('.')[-1].lower()
            if ext == 'pdf':
                try:
                    pdf_reader = PdfReader(file)
                    for i, page in enumerate(pdf_reader.pages):
                        content = page.extract_text() or ""
                        file_text += f"\n--- Page {i+1} ---\n{content}"
                except:
                    file_text = "(PDF è®€å–å¤±æ•—ï¼Œå¯èƒ½æ˜¯åŠ å¯†æˆ–ç´”åœ–ç‰‡)"
            elif ext == 'docx':
                try:
                    doc = Document(file)
                    file_text = "\n".join([p.text for p in doc.paragraphs])
                except:
                    file_text = "(DOCX è®€å–å¤±æ•—)"
            elif ext == 'doc':
                file_text = "âš ï¸ ç³»çµ±æç¤ºï¼šæœ¬ç³»çµ±ä¸æ”¯æ´èˆŠç‰ˆ Word (.doc)ã€‚è«‹å°‡æª”æ¡ˆã€Œå¦å­˜æ–°æª”ã€ç‚º .docx æˆ– .pdf å¾Œé‡æ–°ä¸Šå‚³ã€‚"
            
            # ç°¡å–®æ¸…æ´—
            file_text = re.sub(r'\n\s*\n', '\n\n', file_text)
            text_content += f"\n\n=== æª”æ¡ˆ: {file.name} ===\n{file_text}"
        except Exception as e:
            text_content += f"\n[è®€å–éŒ¯èª¤: {file.name} - {str(e)}]"
    return text_content

# --- 3. è³‡æ–™è™•ç†å·¥å…· ---

def parse_md_to_df(md_text):
    """å°‡ Markdown è¡¨æ ¼è§£æç‚º Pandas DataFrame"""
    try:
        cleaned_text = md_text.replace("||", "|\n|")
        lines = cleaned_text.strip().split('\n')
        table_lines = []
        is_table_started = False
        
        for line in lines:
            if ("å–®å…ƒ" in line or "ç›®æ¨™" in line or "é…åˆ†" in line) and "|" in line:
                is_table_started = True
                table_lines.append(line)
                continue
            if is_table_started:
                if "---" in line: continue
                if "|" in line: table_lines.append(line)
        
        if not table_lines: return None

        data = []
        for line in table_lines:
            row = [cell.strip() for cell in line.strip('|').split('|')]
            data.append(row)

        if len(data) < 2: return None

        headers = data[0]
        rows = data[1:]
        
        max_cols = len(headers)
        cleaned_rows = []
        for r in rows:
            if len(r) == max_cols: cleaned_rows.append(r)
            elif len(r) < max_cols: cleaned_rows.append(r + [''] * (max_cols - len(r)))
            else: cleaned_rows.append(r[:max_cols])

        df = pd.DataFrame(cleaned_rows, columns=headers)
        
        # --- ğŸ”¥ å¼·åˆ¶æ¸…æ´—è²ªå¿ƒé¡Œå‹ (åªç•™ç¬¬ä¸€å€‹) ---
        type_col = next((col for col in df.columns if "é¡Œå‹" in col), None)
        if type_col:
            def clean_type(x):
                txt = str(x).replace(" ", "")
                if "ã€" in txt: return txt.split("ã€")[0]
                if "," in txt: return txt.split(",")[0]
                if "æˆ–" in txt: return txt.split("æˆ–")[0]
                return txt
            df[type_col] = df[type_col].apply(clean_type)

        # --- ğŸ”¥ é…åˆ†è‡ªå‹•æ ¡æ­£ ---
        score_col = next((col for col in df.columns if "é…åˆ†" in col), None)
        if score_col:
            try:
                def clean_number(x):
                    nums = re.findall(r"[-+]?\d*\.\d+|\d+", str(x))
                    return float(nums[0]) if nums else 0.0

                df[score_col] = df[score_col].apply(clean_number)
                current_total = df[score_col].sum()
                
                if current_total > 0 and current_total != 100:
                    df[score_col] = (df[score_col] / current_total) * 100
                
                df[score_col] = df[score_col].round().astype(int)
                
                diff = 100 - df[score_col].sum()
                if diff != 0:
                    max_idx = df[score_col].idxmax()
                    df.loc[max_idx, score_col] += diff
            except: pass
            
        return df
    except Exception as e: return None

def df_to_excel(df):
    """å°‡ DataFrame è½‰ç‚º Excel bytes"""
    try:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨')
            workbook = writer.book
            worksheet = writer.sheets['å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨']
            
            wrap_format = workbook.add_format({'text_wrap': True, 'valign': 'vcenter'})
            header_format = workbook.add_format({
                'bold': True, 'text_wrap': True, 'valign': 'vcenter', 
                'fg_color': '#D7E4BC', 'border': 1
            })
            num_format = workbook.add_format({'valign': 'vcenter', 'align': 'center'})

            for col_num, value in enumerate(df.columns.values):
                worksheet.write(0, col_num, value, header_format)

            worksheet.set_column(0, 0, 15, wrap_format)
            worksheet.set_column(1, 1, 55, wrap_format) 
            worksheet.set_column(2, 2, 20, wrap_format)
            worksheet.set_column(3, 3, 10, num_format)
                
        return output.getvalue()
    except Exception as e: return None

def df_to_string(df):
    """å°‡ DataFrame è½‰ç‚ºæ–‡å­—å­—ä¸²ï¼Œä¾› Prompt ä½¿ç”¨"""
    if df is None: return ""
    return df.to_markdown(index=False)

# --- 4. Prompt æŒ‡ä»¤é›† ---

GEM_INSTRUCTIONS_PHASE1 = """
ä½ æ˜¯ã€Œåœ‹å°å°ˆæ¥­å®šæœŸè©•é‡å‘½é¡Œ AIã€ã€‚
Phase 1 ä»»å‹™ï¼šé–±è®€æ•™æï¼Œæ•´ç†ã€å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨ã€‘ã€‚

çµ•å°è¦å‰‡ï¼š
1. **é…åˆ†é‚è¼¯**ï¼šæ ¹æ“šç¯‡å¹…èˆ‡é‡è¦æ€§ï¼Œåˆ†é…ç¸½åˆ†å‰›å¥½ 100 åˆ†ã€‚
2. **å–®ä¸€é¡Œå‹**ï¼šã€Œå°æ‡‰é¡Œå‹ã€æ¬„ä½åªèƒ½é¸ã€Œä¸€ç¨®ã€æœ€é©åˆçš„é¡Œå‹ (å¦‚ï¼šå–®é¸é¡Œ)ã€‚
   (âŒéŒ¯èª¤: å–®é¸é¡Œã€é…åˆé¡Œ | âœ…æ­£ç¢º: å–®é¸é¡Œ)
3. **æ•¸å­—æ ¼å¼**ï¼šã€Œé è¨ˆé…åˆ†ã€æ¬„ä½åªèƒ½å¡«é˜¿æ‹‰ä¼¯æ•¸å­—ã€‚
4. **æ ¼å¼è¦æ±‚**ï¼šåƒ…è¼¸å‡º Markdown è¡¨æ ¼ã€‚
"""

GEM_INSTRUCTIONS_PHASE3 = """
ä½ æ˜¯ã€Œåœ‹å°å°ˆæ¥­å®šæœŸè©•é‡å‘½é¡Œ AIã€ï¼Œç²¾é€š 1-6 å¹´ç´šå…¨ç§‘æ•™ææ•™æ³•ã€‚
Phase 3 ä»»å‹™ï¼šä¾æ“šä½¿ç”¨è€…ç¢ºèªçš„ã€è©¦é¡Œå¯©æ ¸è¡¨ã€‘èˆ‡ã€å‘½é¡Œæ¨¡å¼ã€‘é€²è¡Œæ­£å¼å‡ºé¡Œã€‚

### 1. æ ¸å¿ƒåƒæ•¸ï¼šè©¦å·æ¨¡å¼ (Mode)
è«‹ä¾æ“šè¼¸å…¥çš„æ¨¡å¼èª¿æ•´å‘½é¡Œé‚è¼¯ï¼š
* **ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­ (Moderate)**ï¼šåŸºç¤å­¸åŠ›ï¼Œé¡Œå¹¹ç›´æ¥ã€‚
* **ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£ (Hard)**ï¼šé‚è¼¯ç´°ç¯€ï¼Œå¤šæ­¥é©Ÿè§£é¡Œã€‚
* **ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š (Literacy)**ï¼šæƒ…å¢ƒè§£æ±ºå•é¡Œï¼Œæ¥è»Œåœ‹éš›æ¨™æº–ã€‚

### 2. å‘½é¡Œéµå¾‹
* **ç¸½åˆ†**ï¼šå¿…é ˆåš´æ ¼éµå®ˆå¯©æ ¸è¡¨ä¸­çš„é…åˆ†ï¼Œç¸½åˆ† 100ã€‚
* **è¦–è¦ºåŒ–**ï¼šè‹¥é¡Œç›®éœ€è¦åœ–ç‰‡ï¼Œè«‹åœ¨é¡Œå¹¹æ’å…¥  æ¨™ç±¤ã€‚
* **é¸é …å“è³ª**ï¼šå¹²æ“¾é …å¿…é ˆåˆç†ï¼Œç¦æ­¢ã€Œä»¥ä¸Šçš†æ˜¯/éã€ã€‚

### 3. è¼¸å‡ºæ ¼å¼
è«‹ç›´æ¥è¼¸å‡ºè©¦å·å…§å®¹ï¼ŒåŒ…å«é¡Œè™Ÿã€é¡Œç›®ã€é¸é …ã€é…åˆ†ã€‚
"""

# --- 5. æ™ºèƒ½æ¨¡å‹è¨­å®š (è§£æ±º 404 èˆ‡é€£ç·šå•é¡Œ) ---
def get_best_model(api_key, mode="fast"):
    genai.configure(api_key=api_key)
    try:
        # 1. ç²å–æ‰€æœ‰å¯ç”¨æ¨¡å‹æ¸…å–®
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        if not models: return None, "æ‰¾ä¸åˆ°å¯ç”¨æ¨¡å‹ï¼Œè«‹æª¢æŸ¥ API Key æ¬Šé™"
        
        target_model = None
        
        # 2. æœå°‹é‚è¼¯
        if mode == "fast":
            # å„ªå…ˆæ‰¾å«æœ‰ flash çš„æ¨¡å‹
            for m in models:
                if 'flash' in m.lower(): target_model = m; break
            if not target_model: target_model = models[0]
            
        elif mode == "smart":
            # å„ªå…ˆæ‰¾å«æœ‰ pro çš„æ¨¡å‹
            for m in models:
                if 'pro' in m.lower() and '1.5' in m.lower(): target_model = m; break
            if not target_model:
                for m in models:
                    if 'pro' in m.lower(): target_model = m; break
            if not target_model: target_model = models[0]
            
        return target_model, None
    except Exception as e: return None, str(e)

def generate_with_retry(model_or_chat, prompt, stream=True):
    max_retries = 3
    for i in range(max_retries):
        try:
            if hasattr(model_or_chat, 'send_message'):
                return model_or_chat.send_message(prompt, stream=stream)
            else:
                return model_or_chat.generate_content(prompt, stream=stream)
        except Exception as e:
            # å¦‚æœæ˜¯ 429 (Too Many Requests) æˆ–å…¶ä»–ç¶²è·¯å•é¡Œ
            time.sleep((i + 1) * 2)
            if i == max_retries - 1: raise e
    raise Exception("é€£ç·šé€¾æ™‚ï¼Œè«‹æª¢æŸ¥ç¶²è·¯")

# --- 6. ä»‹é¢è¨­å®š ---
st.set_page_config(page_title="å…§æ¹–åœ‹å° AI è¼”åŠ©å‡ºé¡Œç³»çµ±", layout="wide")

st.markdown("""
    <style>
    header[data-testid="stHeader"] { display: none !important; visibility: hidden !important; }
    footer { display: none !important; visibility: hidden !important; }
    .stApp { background-color: #0F172A; }
    .school-header {
        background: linear-gradient(90deg, #1E293B 0%, #334155 100%);
        padding: 25px; border-radius: 18px; text-align: center; margin-bottom: 25px; 
        border: 1px solid #475569;
    }
    .school-name { font-size: 26px; font-weight: 700; color: #F1F5F9; letter-spacing: 3px; }
    .app-title { font-size: 15px; color: #94A3B8; margin-top: 6px; }
    h1, h2, h3, p, span, label, .stMarkdown { color: #E2E8F0 !important; }
    .comfort-box {
        background-color: #1E293B; padding: 15px; border-radius: 10px; 
        margin-bottom: 15px; border-left: 5px solid #3B82F6; 
        font-size: 14px; color: #CBD5E1; line-height: 1.8;
    }
    .comfort-box b { color: #fff; }
    .comfort-box a { color: #60A5FA !important; text-decoration: none; font-weight: bold; }
    [data-testid="stSidebar"] .stMarkdown { margin-bottom: 10px; } 
    .stTextArea textarea { min-height: 80px; }
    .stTextArea { margin-bottom: 15px !important; }
    [data-testid="stSidebar"] .stButton > button { 
        display: block; margin: 15px auto !important; 
        width: 100%; border-radius: 8px; height: 42px;
        background-color: #334155; border: 1px solid #475569; font-size: 15px;
    }
    .custom-footer { 
        position: fixed; left: 0; bottom: 0; width: 100%; 
        background-color: #0F172A; color: #475569; 
        text-align: center; padding: 12px; font-size: 11px; 
        border-top: 1px solid #1E293B; z-index: 100; 
    }
    </style>
    <div class="school-header">
        <div class="school-name">æ–°ç«¹å¸‚é¦™å±±å€å…§æ¹–åœ‹å°</div>
        <div class="app-title">è©•é‡å‘½é¡Œèˆ‡å­¸ç¿’ç›®æ¨™è‡ªå‹•åŒ–ç³»çµ±</div>
    </div>
    """, unsafe_allow_html=True)

if "phase" not in st.session_state: st.session_state.phase = 1 
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "df_preview" not in st.session_state: st.session_state.df_preview = None
if "final_exam_content" not in st.session_state: st.session_state.final_exam_content = ""

# --- Sidebar ---
with st.sidebar:
    st.markdown("### ğŸš€ ç³»çµ±è¨­å®š")
    api_input = st.text_area("åœ¨æ­¤è¼¸å…¥ API Key", height=80, placeholder="è«‹è²¼ä¸Š Google AI Studio é‡‘é‘°...")
    if st.button("ğŸ”„ é‡ç½®ç³»çµ±"):
        st.session_state.clear()
        st.rerun()

    st.markdown("### ğŸ“š è³‡æºé€£çµ")
    st.markdown("""
    <div class="comfort-box">
        <b>æ•™æä¸‹è¼‰ï¼š</b><br>
        â€¢ <a href="https://webetextbook.knsh.com.tw/" target="_blank">åº·è»’é›»å­æ›¸</a><br>
        â€¢ <a href="https://edisc3.hle.com.tw/" target="_blank">ç¿°æ—è¡Œå‹•å¤§å¸«</a><br>
        â€¢ <a href="https://reader.nani.com.tw/" target="_blank">å—ä¸€ OneBox</a>
    </div>
    """, unsafe_allow_html=True)

# --- Phase 1: åƒæ•¸è¨­å®šèˆ‡æ•™æä¸Šå‚³ ---
if st.session_state.phase == 1:
    with st.container(border=True):
        st.markdown("### ğŸ“ ç¬¬ä¸€éšæ®µï¼šåƒæ•¸è¨­å®šèˆ‡æ•™æä¸Šå‚³")
        
        c1, c2, c3 = st.columns(3)
        with c1: grade = st.selectbox("1. é¸æ“‡å¹´ç´š", ["", "ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"], index=0)
        with c2: subject = st.selectbox("2. é¸æ“‡ç§‘ç›®", ["", "åœ‹èª", "æ•¸å­¸", "è‡ªç„¶ç§‘å­¸", "ç¤¾æœƒ", "è‹±èª"], index=0)
        with c3: mode = st.selectbox("3. å‘½é¡Œæ¨¡å¼", ["ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­", "ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£", "ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š"], index=0)
        
        st.divider()
        st.markdown("**4. å‹¾é¸æ¬²ç”¢å‡ºçš„é¡Œå‹**")
        available_types = SUBJECT_Q_TYPES.get(subject, SUBJECT_Q_TYPES[""])
        cols = st.columns(min(len(available_types), 4))
        selected_types = []
        for i, t in enumerate(available_types):
            if cols[i % len(cols)].checkbox(t, value=True): selected_types.append(t)
        
        st.divider()
        uploaded_files = st.file_uploader("5. ä¸Šå‚³æ•™ææª”æ¡ˆ (Word/PDF)", type=["pdf", "docx", "doc"], accept_multiple_files=True)
        
        if st.button("ğŸš€ ç”¢å‡ºå­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨", type="primary", use_container_width=True):
            if not api_input: st.error("âŒ è«‹è¼¸å…¥ API Key")
            elif not grade or not subject or not uploaded_files or not selected_types:
                st.warning("âš ï¸ è«‹ç¢ºèªæ‰€æœ‰æ¬„ä½å·²å¡«å¯«")
            else:
                with st.spinner("âš¡ AI æ­£åœ¨åˆ†ææ•™æ..."):
                    keys = [k.strip() for k in api_input.replace('\n', ',').split(',') if k.strip()]
                    target_key = random.choice(keys)
                    
                    # å‹•æ…‹æœå°‹æ¨¡å‹ï¼Œé¿å… 404
                    model_name, error_msg = get_best_model(target_key, mode="fast")
                    
                    if error_msg: st.error(f"âŒ API éŒ¯èª¤ï¼š{error_msg}")
                    else:
                        content = extract_text_from_files(uploaded_files)
                        try:
                            st.toast(f"âš¡ å•Ÿå‹• AI å¼•æ“ ({model_name})...", icon="ğŸ¤–")
                            model_fast = genai.GenerativeModel(
                                model_name=model_name,
                                system_instruction=GEM_INSTRUCTIONS_PHASE1, 
                                generation_config={"temperature": 0.0}
                            )
                            chat = model_fast.start_chat(history=[])
                            t_str = "ã€".join(selected_types)
                            prompt_content = f"""
                            ä»»å‹™ï¼šåˆ†æä»¥ä¸‹æ•™æä¸¦ç”¢å‡ºå¯©æ ¸è¡¨ã€‚
                            ã€åƒæ•¸ã€‘å¹´ç´šï¼š{grade}, ç§‘ç›®ï¼š{subject}, å¯ç”¨é¡Œå‹ï¼š{t_str}
                            ã€æ•™æã€‘{content}
                            ã€æ­¥é©Ÿã€‘
                            1. è­˜åˆ¥å–®å…ƒçµæ§‹èˆ‡å­¸ç¿’ç›®æ¨™ã€‚
                            2. ä¾é‡è¦æ€§èˆ‡ç¯‡å¹…åˆ†é… 100 åˆ†ã€‚
                            3. è¼¸å‡º Markdown è¡¨æ ¼ã€‚
                            """
                            response = generate_with_retry(chat, prompt_content, stream=False)
                            
                            if "|" in response.text and "å–®å…ƒ" in response.text:
                                st.session_state.chat_history.append({"role": "model", "content": response.text})
                                st.session_state.df_preview = parse_md_to_df(response.text)
                                st.session_state.phase = 2
                                st.session_state.subject = subject 
                                st.session_state.grade = grade
                                st.session_state.mode = mode
                                st.rerun()
                            else: st.error("âŒ æ ¼å¼ç•°å¸¸ï¼Œè«‹é‡è©¦")
                        except Exception as e: st.error(f"é€£ç·šå¤±æ•—ï¼š{e}")

# --- Phase 2: ç·šä¸Šç·¨è¼¯èˆ‡ä¸‹è¼‰ ---
elif st.session_state.phase == 2:
    with st.container(border=True):
        st.markdown("### ğŸ“ ç¬¬äºŒéšæ®µï¼šå¯©æ ¸èˆ‡ç·¨è¼¯")
        st.info("è«‹åœ¨ä¸‹æ–¹è¡¨æ ¼ç›´æ¥ä¿®æ”¹ã€Œå°æ‡‰é¡Œå‹ã€æˆ–ã€Œå­¸ç¿’ç›®æ¨™ã€ã€‚ç¢ºèªç„¡èª¤å¾Œï¼Œå¯å…ˆä¸‹è¼‰ Excel å­˜æª”ï¼Œæˆ–ç›´æ¥é»æ“Šä¸‹æ–¹æŒ‰éˆ•å‡ºé¡Œã€‚")
        
        current_subject = st.session_state.get("subject", "")
        valid_types = SUBJECT_Q_TYPES.get(current_subject, SUBJECT_Q_TYPES[""])

        if st.session_state.df_preview is not None:
            edited_df = st.data_editor(
                st.session_state.df_preview,
                column_config={
                    "å°æ‡‰é¡Œå‹": st.column_config.SelectboxColumn(
                        "å°æ‡‰é¡Œå‹",
                        width="medium",
                        options=valid_types,
                        required=True,
                    ),
                    "é è¨ˆé…åˆ†": st.column_config.NumberColumn(
                        "é è¨ˆé…åˆ†",
                        min_value=0,
                        max_value=100,
                        format="%d åˆ†"
                    )
                },
                use_container_width=True,
                num_rows="dynamic",
                hide_index=True
            )
            
            st.session_state.df_preview = edited_df

            total_score = edited_df["é è¨ˆé…åˆ†"].sum()
            if total_score != 100:
                st.warning(f"âš ï¸ ç›®å‰ç¸½åˆ†ï¼š{total_score} åˆ† (å»ºè­°èª¿æ•´ç‚º 100 åˆ†)")
            else:
                st.success(f"âœ… ç›®å‰ç¸½åˆ†ï¼š{total_score} åˆ†")

            excel_data = df_to_excel(edited_df)
            
            col1, col2 = st.columns([1, 1])
            with col1:
                if excel_data:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ Excel å¯©æ ¸è¡¨",
                        data=excel_data,
                        file_name=f"å…§æ¹–åœ‹å°_{current_subject}_å¯©æ ¸è¡¨.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
            with col2:
                if st.button("â¬…ï¸ è¿”å›é‡ä¾†", use_container_width=True):
                    st.session_state.phase = 1
                    st.session_state.chat_history = []
                    st.session_state.df_preview = None
                    st.rerun()
        else:
            st.error("âš ï¸ è³‡æ–™éºå¤±ï¼Œè«‹é‡æ–°ç”Ÿæˆã€‚")

    st.divider()
    
    # --- Phase 3 å…¥å£ ---
    if st.button("âœ… å¯©æ ¸ç„¡èª¤ï¼Œé–‹å§‹æ­£å¼å‘½é¡Œ (Phase 3)", type="primary", use_container_width=True):
        if st.session_state.df_preview is None:
            st.error("âŒ ç„¡æ³•è®€å–å¯©æ ¸è¡¨è³‡æ–™")
        else:
            st.session_state.phase = 3
            st.rerun()

# --- Phase 3: æ­£å¼å‡ºé¡Œ ---
elif st.session_state.phase == 3:
    with st.container(border=True):
        st.markdown("### ğŸ“ ç¬¬ä¸‰éšæ®µï¼šè©¦é¡Œç”Ÿæˆçµæœ")
        
        mode_str = st.session_state.get('mode', 'æœªå®š')
        subject_str = st.session_state.get('subject', 'æœªå®š')
        st.caption(f"ğŸ“ ç›®å‰æ¨¡å¼ï¼š{mode_str} | ç§‘ç›®ï¼š{subject_str}")
        
        if not st.session_state.final_exam_content:
            with st.spinner("ğŸ§  æ­£åœ¨æ ¹æ“šæ‚¨çš„å¯©æ ¸è¡¨èˆ‡å‘½é¡Œæ¨¡å¼é€²è¡Œæ¨ç†... (Pro æ¨¡å‹å•Ÿå‹•ä¸­)"):
                try:
                    keys = [k.strip() for k in api_input.replace('\n', ',').split(',') if k.strip()]
                    target_key = random.choice(keys)
                    
                    # Phase 3 ä¹Ÿç”¨å‹•æ…‹æœå°‹ï¼Œä¸ç¡¬æ€§æŒ‡å®š
                    model_smart_name, error_msg = get_best_model(target_key, mode="smart")
                    
                    if error_msg: st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š{error_msg}")
                    else:
                        st.toast(f"åˆ‡æ›è‡³æ·±åº¦æ€è€ƒæ¨¡å¼ ({model_smart_name})...", icon="ğŸ’¡")
                        model_smart = genai.GenerativeModel(
                            model_name=model_smart_name,
                            system_instruction=GEM_INSTRUCTIONS_PHASE3
                        )
                        
                        df_str = df_to_string(st.session_state.df_preview)
                        
                        final_prompt = f"""
                        è«‹æ ¹æ“šä»¥ä¸‹ã€å¯©æ ¸é€šéçš„æ¶æ§‹è¡¨ã€‘é€²è¡Œå‘½é¡Œã€‚
                        
                        ã€åŸºæœ¬è³‡è¨Šã€‘
                        å¹´ç´šï¼š{st.session_state.get('grade')}
                        ç§‘ç›®ï¼š{st.session_state.get('subject')}
                        å‘½é¡Œæ¨¡å¼ï¼š{st.session_state.get('mode')}
                        
                        ã€å¯©æ ¸è¡¨ (è«‹ä¾æ­¤æ¶æ§‹å‡ºé¡Œ)ã€‘
                        {df_str}
                        
                        ã€åŸ·è¡Œè¦æ±‚ã€‘
                        1. é¡Œç›®æ•¸é‡èˆ‡é…åˆ†éœ€èˆ‡è¡¨æ ¼å®Œå…¨ä¸€è‡´ã€‚
                        2. è‹¥ç‚ºç´ é¤Šæ¨¡å¼ï¼Œè«‹å‹™å¿…è¨­è¨ˆæƒ…å¢ƒé¡Œã€‚
                        3. è«‹åŒ…å«  æ¨™ç±¤ä»¥æ¨™ç¤ºåœ–ç‰‡éœ€æ±‚ã€‚
                        """
                        
                        response = generate_with_retry(model_smart, final_prompt, stream=True)
                        full_text = ""
                        msg_placeholder = st.empty()
                        
                        for chunk in response:
                            if chunk.text:
                                full_text += chunk.text
                                msg_placeholder.markdown(full_text + "â–Œ")
                        
                        msg_placeholder.markdown(full_text)
                        st.session_state.final_exam_content = full_text
                        
                except Exception as e:
                    st.error(f"å‘½é¡Œå¤±æ•—ï¼š{e}")
                    if st.button("é‡è©¦"): st.rerun()
        else:
            st.markdown(st.session_state.final_exam_content)

        st.divider()
        c1, c2 = st.columns([1, 1])
        with c1:
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰è©¦å· (.txt)",
                data=st.session_state.final_exam_content,
                file_name=f"å…§æ¹–åœ‹å°_{st.session_state.get('subject')}_è©¦å·åˆç¨¿.txt",
                mime="text/plain",
                use_container_width=True
            )
        with c2:
            if st.button("ğŸ”„ å›åˆ°ç·¨è¼¯å° (é‡æ–°å¯©æ ¸)", use_container_width=True):
                st.session_state.phase = 2
                st.session_state.final_exam_content = ""
                st.rerun()

st.markdown('<div class="custom-footer">Â© 2026 æ–°ç«¹å¸‚é¦™å±±å€å…§æ¹–åœ‹å°. All Rights Reserved.</div>', unsafe_allow_html=True)
