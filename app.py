import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from docx import Document
import pandas as pd
import subprocess
import os

# --- 1. æª”æ¡ˆè®€å–å·¥å…· (æ”¯æ´ .doc, .docx, .pdf) ---
def read_pdf(file):
    pdf_reader = PdfReader(file)
    return "".join([p.extract_text() or "" for p in pdf_reader.pages])

def read_docx(file):
    doc = Document(file)
    return "\n".join([p.text for p in doc.paragraphs])

def read_doc(file):
    with open("temp.doc", "wb") as f: f.write(file.getbuffer())
    try:
        result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
        return result.stdout if result.returncode == 0 else "[è®€å–éŒ¯èª¤]"
    except: return "[çµ„ä»¶æœªå°±ç·’]"
    finally:
        if os.path.exists("temp.doc"): os.remove("temp.doc")

# --- 2. æ ¸å¿ƒå‘½é¡Œé€£å‹•é‚è¼¯ (æ·±åº¦æ•´åˆæ‚¨çš„ Gem è¨­å®š) ---
GEM_INSTRUCTIONS = """
ä½ æ˜¯ã€Œåœ‹å°å°ˆæ¥­å®šæœŸè©•é‡å‘½é¡Œ AIã€ã€‚ä½ å¿…é ˆåš´æ ¼åŸ·è¡Œã€Œç›®æ¨™å°æ‡‰é¡Œè™Ÿã€çš„å‘½é¡Œéµå¾‹ï¼š

### æ ¸å¿ƒéµå¾‹ (Core Principle)ï¼š
1. **åŸæ–‡ç…§éŒ„**ï¼šå­¸ç¿’ç›®æ¨™å¿…é ˆå¾æ•™æä¸­åŸæ–‡æå–ã€‚ [cite: 2026-02-13]
2. **ç›®æ¨™å…¨è¦†è“‹**ï¼šæ¯æ¢ç›®æ¨™è‡³å°‘å…¥é¡Œ 1 æ¬¡ï¼Œä¸¦åœ¨å¯©æ ¸è¡¨ä¸­æ˜ç¢ºæ¨™è¨»ã€Œå°æ‡‰é¡Œè™Ÿã€ã€‚ [cite: 2026-02-13]
3. **å…©æ®µå¼è¼¸å‡º**ï¼šPhase 1 ç”¢å‡ºå«é¡Œè™Ÿçš„å¯©æ ¸è¡¨ï¼ŒPhase 2 åš´æ ¼ä¾ç…§è©²è¡¨å‡ºé¡Œã€‚ [cite: 2026-02-13]

### Phase 1 è¼¸å‡ºæ ¼å¼ (å…§æ¹–åœ‹å°å¯©æ ¸è¡¨)ï¼š
è«‹ç‚ºæ¯å€‹å–®å…ƒç”¢å‡ºè¡¨æ ¼ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

#### **[å–®å…ƒåç¨±]**
| å­¸ç¿’ç›®æ¨™ (åŸæ–‡æå–) | æˆèª²ç¯€æ•¸ | å°æ‡‰é¡Œè™Ÿ | é¸æ“‡é¡Œ (ä½”åˆ†) | é–±è®€/å…¶å®ƒ (ä½”åˆ†) |
| :--- | :---: | :---: | :---: | :---: |
| 1. [æ•™æç›®æ¨™ 1] | [ç¯€æ•¸] | ç¬¬ 1, 2 é¡Œ | [å¾—åˆ†] | [å¾—åˆ†] |
| 2. [æ•™æç›®æ¨™ 2] | | ç¬¬ 3 é¡Œ | | |

---
**åŸºæœ¬æª¢æŸ¥ (ä¾æ“šæ¨¡å¼)ï¼š**
* **æ¨¡å¼**ï¼š{mode} (A:60/40, B:30/70, C:20/80)
* **ç¸½åˆ†**ï¼š100 åˆ† | **ç¸½æ ¼æ•¸**ï¼š34-45 æ ¼
* **åœ–è¡¨éœ€æ±‚**ï¼šåˆ—å‡º [Image of...] æ¨™ç±¤ã€‚
"""

# --- 3. ç¶²é ä»‹é¢é…ç½® ---
st.set_page_config(page_title="QuestWiz å…§æ¹–åœ‹å°å°ˆå±¬ç‰ˆ", layout="wide")
st.title("ğŸ« QuestWiz è©¦é¡Œè¡Œæ”¿è‡ªå‹•åŒ–ç³»çµ±")

with st.sidebar:
    st.header("ğŸ”‘ ç³»çµ±è¨­å®š")
    st.markdown("[ğŸ‘‰ ç”³è«‹é‡‘é‘°](https://aistudio.google.com/app/apikey)")
    api_key = st.text_input("è²¼ä¸Šæ‚¨çš„ API Key", type="password")
    st.divider()
    st.info("ğŸ’¡ æ ¸å¿ƒï¼šå­¸ç¿’ç›®æ¨™å…¨è¦†è“‹èˆ‡é¡Œè™Ÿé€£å‹•")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if not st.session_state.chat_history:
    with st.container(border=True):
        col1, col2, col3 = st.columns(3)
        with col1:
            grade = st.selectbox("å¹´ç´š", ["ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"], index=4)
        with col2:
            subject = st.selectbox("ç§‘ç›®", ["è‡ªç„¶ç§‘å­¸", "åœ‹èª", "æ•¸å­¸", "ç¤¾æœƒ", "è‹±èª"], index=0)
        with col3:
            mode = st.selectbox("å‘½é¡Œæ¨¡å¼", ["ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­", "ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£", "ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š"], index=0)
        
        uploaded_files = st.file_uploader("ä¸Šå‚³æ•™æ", type=["pdf", "docx", "doc", "csv"], accept_multiple_files=True)
        start_btn = st.button("ğŸš€ ç”¢å‡ºã€Œå«é¡Œè™Ÿå°æ‡‰ã€ä¹‹å¯©æ ¸è¡¨", type="primary", use_container_width=True)

    if start_btn and api_key and uploaded_files:
        all_content = ""
        for f in uploaded_files:
            ext = f.name.split('.')[-1].lower()
            if ext == 'pdf': all_content += read_pdf(f)
            elif ext == 'docx': all_content += read_docx(f)
            elif ext == 'doc': all_content += read_doc(f)
            elif ext == 'csv': all_content += pd.read_csv(f, encoding_errors='ignore').to_string()
        
        try:
            genai.configure(api_key=api_key)
            available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            target = "models/gemini-2.5-flash" if "models/gemini-2.5-flash" in available else available[0]
            
            # å°‡é¸æ“‡çš„æ¨¡å¼æ³¨å…¥æŒ‡ä»¤
            final_instr = GEM_INSTRUCTIONS.format(mode=mode, subject=subject)
            
            model = genai.GenerativeModel(model_name=target, system_instruction=final_instr, generation_config={"temperature": 0.0})
            chat = model.start_chat(history=[])
            
            with st.spinner("âš¡ æ­£åœ¨åˆ†æç›®æ¨™è¦†è“‹ä¸¦è¦åŠƒé¡Œè™Ÿå°æ‡‰..."):
                response = chat.send_message(f"å…§å®¹ï¼š\n{all_content}")
                st.session_state.chat_session = chat
                st.session_state.chat_history.append({"role": "model", "content": response.text})
                st.rerun()
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—ï¼š{e}")
else:
    for msg in st.session_state.chat_history:
        with st.chat_message("ai" if msg["role"] == "model" else "user"):
            st.markdown(msg["content"])
    
    if prompt := st.chat_input("ç¢ºèªå°æ‡‰é¡Œè™Ÿç„¡èª¤å¾Œï¼Œè«‹è¼¸å…¥ã€é–‹å§‹å‡ºé¡Œã€..."):
        res = st.session_state.chat_session.send_message(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        st.session_state.chat_history.append({"role": "model", "content": res.text})
        st.rerun()

    if st.button("ğŸ”„ é‡æ–°è¨­å®š"):
        st.session_state.chat_history = []
        st.session_state.chat_session = None
        st.rerun()
