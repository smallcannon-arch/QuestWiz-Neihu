import streamlit as st
import google.generativeai as genai
import random
import io
import time
import re
from pypdf import PdfReader
from docx import Document
import pandas as pd
import subprocess
import os

# --- 1. å®šç¾©å­¸ç§‘èˆ‡é¡Œå‹æ˜ å°„ ---
SUBJECT_Q_TYPES = {
    "åœ‹èª": ["åœ‹å­—æ³¨éŸ³", "é€ å¥", "å–®é¸é¡Œ", "é–±è®€ç´ é¤Šé¡Œ", "å¥å‹è®Šæ›", "ç°¡ç­”é¡Œ"],
    "æ•¸å­¸": ["æ‡‰ç”¨è¨ˆç®—é¡Œ", "åœ–è¡¨åˆ†æé¡Œ", "å¡«å……é¡Œ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ"],
    "è‡ªç„¶ç§‘å­¸": ["å¯¦é©—åˆ¤è®€é¡Œ", "åœ–è¡¨åˆ†æé¡Œ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "é…åˆé¡Œ"],
    "ç¤¾æœƒ": ["åœ°åœ–åˆ¤è®€é¡Œ", "æƒ…å¢ƒæ¡ˆä¾‹åˆ†æ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ", "é…åˆé¡Œ", "ç°¡ç­”é¡Œ"],
    "è‹±èª": ["è‹±èªæœƒè©±é¸æ“‡", "è©å½™æ­é…", "æ–‡æ„é¸å¡«", "å–®é¸é¡Œ", "é–±è®€ç†è§£"],
    "": ["å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "ç°¡ç­”é¡Œ"]
}

# --- 2. æª”æ¡ˆè®€å–èˆ‡å·¥å…· (å¿«å–å„ªåŒ–) ---
@st.cache_data
def extract_text_from_files(files):
    text_content = ""
    for file in files:
        try:
            ext = file.name.split('.')[-1].lower()
            if ext == 'pdf':
                pdf_reader = PdfReader(file)
                text_content += "".join([p.extract_text() or "" for p in pdf_reader.pages])
            elif ext == 'docx':
                doc = Document(file)
                text_content += "\n".join([p.text for p in doc.paragraphs])
            elif ext == 'doc':
                with open("temp.doc", "wb") as f: f.write(file.getbuffer())
                result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
                if result.returncode == 0: text_content += result.stdout
                if os.path.exists("temp.doc"): os.remove("temp.doc")
        except: text_content += f"\n[è®€å–éŒ¯èª¤: {file.name}]"
    return text_content

def process_table_data(md_text):
    """å¼·åŠ›è§£æ Markdown è¡¨æ ¼ä¸¦è½‰ç‚º DataFrame"""
    try:
        cleaned = md_text.replace("ï½œ", "|").replace("**", "").replace("||", "|\n|")
        # å°‹æ‰¾æ¨™é¡ŒéŒ¨é»
        header_match = re.search(r'\|\s*å–®å…ƒåç¨±\s*\|\s*å­¸ç¿’ç›®æ¨™.*\|\s*å°æ‡‰é¡Œå‹\s*\|\s*é è¨ˆé…åˆ†\s*\|', cleaned)
        if not header_match: return None
        # æ™ºæ…§åˆ‡åˆ†
        raw_cells = [c.strip() for c in cleaned[header_match.start():].split('|') if c.strip() and '---' not in c]
        num_cols = 4 
        if len(raw_cells) < num_cols: return None
        headers = raw_cells[:num_cols]
        data_cells = raw_cells[num_cols:]
        rows = [data_cells[i:i+num_cols] for i in range(0, len(data_cells), num_cols)]
        for r in rows:
            if len(r) < num_cols: r += [''] * (num_cols - len(r))
        return pd.DataFrame(rows, columns=headers)
    except: return None

def generate_with_retry(model_or_chat, prompt, stream=True):
    """å°æ‡‰ 429 éŒ¯èª¤çš„è‡ªå‹•é‡è©¦æ©Ÿåˆ¶"""
    max_retries = 3
    for i in range(max_retries):
        try:
            if hasattr(model_or_chat, 'send_message'): return model_or_chat.send_message(prompt, stream=stream)
            else: return model_or_chat.generate_content(prompt, stream=stream)
        except Exception as e:
            if "429" in str(e):
                wait = (i + 1) * 5
                st.toast(f"â³ ä¼ºæœå™¨å¿™ç¢Œï¼Œ{wait}ç§’å¾Œé‡è©¦...", icon="âš ï¸")
                time.sleep(wait)
            else: raise e
    raise Exception("é‡è©¦æ¬¡æ•¸éå¤š")

# --- 3. ä»‹é¢è¨­è¨ˆ ---
st.set_page_config(page_title="å…§æ¹–åœ‹å° AI è¼”åŠ©å‡ºé¡Œç³»çµ±", layout="wide")

st.markdown("""
    <style>
    header[data-testid="stHeader"], footer { display: none !important; }
    .stApp { background-color: #0F172A; }
    .block-container { max-width: 1200px; padding-top: 1.5rem !important; }
    .school-header { background: linear-gradient(90deg, #1E293B 0%, #334155 100%); padding: 25px; border-radius: 15px; text-align: center; margin-bottom: 25px; border: 1px solid #475569; }
    .school-name { font-size: 24px; font-weight: 700; color: #F1F5F9; letter-spacing: 3px; }
    .app-title { font-size: 14px; color: #94A3B8; }
    .comfort-box { background-color: #1E293B; padding: 12px; border-radius: 10px; margin-bottom: 12px; border-left: 5px solid #3B82F6; font-size: 13px; color: #CBD5E1; line-height: 1.6; }
    .comfort-box a { color: #60A5FA !important; text-decoration: none; font-weight: bold; }
    [data-testid="stSidebar"] .stButton > button { width: 100%; height: 40px; }
    .custom-footer { position: fixed; left: 0; bottom: 0; width: 100%; background-color: #0F172A; color: #475569; text-align: center; padding: 10px; font-size: 11px; z-index: 100; }
    </style>
    <div class="school-header">
        <div class="school-name">æ–°ç«¹å¸‚é¦™å±±å€å…§æ¹–åœ‹å°</div>
        <div class="app-title">è©•é‡å‘½é¡Œèˆ‡å­¸ç¿’ç›®æ¨™è‡ªå‹•åŒ–ç³»çµ±</div>
    </div>
    """, unsafe_allow_html=True)

# ç‹€æ…‹
if "phase" not in st.session_state: st.session_state.phase = 1 
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "last_prompt_content" not in st.session_state: st.session_state.last_prompt_content = ""

# --- Sidebar ---
with st.sidebar:
    st.markdown("### ğŸš€ å¿«é€ŸæŒ‡å—")
    st.markdown("""<div class="comfort-box"><ol style="margin:0; padding-left:1.2rem;">
        <li>å‰å¾€ <a href="https://aistudio.google.com/" target="_blank">AI Studio (é»æˆ‘)</a></li>
        <li>ç™»å…¥<b>å€‹äºº Google å¸³è™Ÿ</b></li>
        <li>é»æ“Š <b>Get API key</b> ä¸¦è¤‡è£½è²¼å…¥ä¸‹æ–¹</li></ol></div>""", unsafe_allow_html=True)
    api_input = st.text_area("åœ¨æ­¤è¼¸å…¥ API Key", height=70)
    if st.button("ğŸ”„ é‡ç½®ç³»çµ±"):
        for k in ["phase", "chat_history", "last_prompt_content"]: st.session_state[k] = (1 if k=="phase" else [] if k=="chat_history" else "")
        st.rerun()
    st.markdown("### ğŸ“š è³‡æºé€£çµ")
    st.markdown("""<div class="comfort-box"><b>æ•™æï¼š</b><a href="https://webetextbook.knsh.com.tw/" target="_blank">åº·è»’</a> | <a href="https://edisc3.hle.com.tw/" target="_blank">ç¿°æ—</a> | <a href="https://reader.nani.com.tw/" target="_blank">å—ä¸€</a><br><b>åƒè€ƒï¼š</b><a href="https://cirn.moe.edu.tw/Syllabus/index.aspx?sid=1108" target="_blank">108èª²ç¶±</a> | <a href="https://www.nhps.hc.edu.tw/" target="_blank">æ ¡ç¶²</a></div>""", unsafe_allow_html=True)

# --- Phase 1: åƒæ•¸è¨­å®šèˆ‡æ•™æä¸Šå‚³ ---
if st.session_state.phase == 1:
    with st.container(border=True):
        st.markdown("### ğŸ“ ç¬¬ä¸€éšæ®µï¼šåƒæ•¸è¨­å®šèˆ‡æ•™æä¸Šå‚³")
        c1, c2, c3 = st.columns(3)
        with c1: grade = st.selectbox("1. å¹´ç´š", ["", "ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"])
        with c2: subject = st.selectbox("2. ç§‘ç›®", ["", "åœ‹èª", "æ•¸å­¸", "è‡ªç„¶ç§‘å­¸", "ç¤¾æœƒ", "è‹±èª"])
        with c3: mode = st.selectbox("3. æ¨¡å¼", ["ğŸŸ¢ é©ä¸­", "ğŸ”´ å›°é›£", "ğŸŒŸ ç´ é¤Š"])
        
        st.markdown("**4. å‹¾é¸æ¬²ç”¢å‡ºçš„é¡Œå‹**")
        available_types = SUBJECT_Q_TYPES.get(subject, SUBJECT_Q_TYPES[""])
        cols = st.columns(min(len(available_types), 4))
        selected_types = [t for i, t in enumerate(available_types) if cols[i % len(cols)].checkbox(t, value=True)]
        
        uploaded_files = st.file_uploader("5. ä¸Šå‚³æ•™æ (Word/PDF)", type=["pdf", "docx", "doc"], accept_multiple_files=True)
        
        if st.button("ğŸš€ ç”¢å‡ºå­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨", type="primary", use_container_width=True):
            if not api_input or not grade or not subject or not uploaded_files:
                st.warning("âš ï¸ è«‹è£œé½Š API Keyã€åƒæ•¸æˆ–æ•™æã€‚")
            else:
                with st.spinner("âš¡ æ­£åœ¨æ¥µé€Ÿæƒææ•™æä¸¦åŸæ–‡æå–å­¸ç¿’ç›®æ¨™..."):
                    genai.configure(api_key=api_input.strip())
                    content = extract_text_from_files(uploaded_files)
                    try:
                        model = genai.GenerativeModel("gemini-1.5-flash", system_instruction="ä½ åƒ…ç”¢å‡ºè¡¨æ ¼ï¼Œæ¬„ä½ï¼š| å–®å…ƒåç¨± | å­¸ç¿’ç›®æ¨™(åŸæ–‡) | å°æ‡‰é¡Œå‹ | é è¨ˆé…åˆ† |ã€‚çµ•å°ç¦æ­¢å‡ºé¡Œï¼")
                        st.session_state.last_prompt_content = f"å¹´ç´šï¼š{grade}, ç§‘ç›®ï¼š{subject}\né¡Œå‹ï¼š{'ã€'.join(selected_types)}\nå‘½é¡Œæ¨¡å¼ï¼š{mode}\næ•™æï¼š{content}"
                        
                        with st.chat_message("ai"):
                            placeholder = st.empty()
                            full_res = ""
                            res = generate_with_retry(model, st.session_state.last_prompt_content)
                            for chunk in res:
                                full_res += chunk.text
                                placeholder.markdown(full_res + "â–Œ")
                            placeholder.markdown(full_res)
                        
                        st.session_state.chat_history.append({"role": "model", "content": full_res})
                        st.session_state.phase = 2
                        st.rerun()
                    except Exception as e: st.error(f"é€£ç·šå¤±æ•—ï¼š{e}")

# --- Phase 2: ç¢ºèªèˆ‡å‡ºé¡Œ ---
elif st.session_state.phase == 2:
    current_md = st.session_state.chat_history[0]["content"]
    with st.chat_message("ai"): st.markdown(current_md)
    
    # ä¸‹è¼‰æŒ‰éˆ•å€
    df = process_table_data(current_md)
    if df is not None:
        c_d1, c_d2 = st.columns(2)
        with c_d1:
            try:
                buf = io.BytesIO()
                with pd.ExcelWriter(buf, engine='openpyxl') as writer: df.to_excel(writer, index=False)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel å¯©æ ¸è¡¨", data=buf.getvalue(), file_name="å¯©æ ¸è¡¨.xlsx", use_container_width=True)
            except: st.caption("ç’°å¢ƒä¸æ”¯æ´ Excelï¼Œè«‹ç”¨ CSVã€‚")
        with c_d2:
            st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV å¯©æ ¸è¡¨ (ä¿éšªç”¨)", data=df.to_csv(index=False).encode('utf-8-sig'), file_name="å¯©æ ¸è¡¨.csv", use_container_width=True)

    st.divider()
    with st.container(border=True):
        st.markdown("### ğŸ“ ç¬¬äºŒéšæ®µï¼šæ­£å¼å‡ºé¡Œ")
        st.caption("ğŸ§  ç³»çµ±å°‡æ›æª”è‡³ **Gemini 1.5 Pro** ä»¥ç¢ºä¿é¡Œç›®å“è³ª")
        
        if st.button("âœ… ç¢ºèªç„¡èª¤ï¼Œé–‹å§‹å‡ºé¡Œ", type="primary", use_container_width=True):
            with st.spinner("ğŸ§  æ·±åº¦å‘½é¡Œä¸­ï¼Œè«‹ç¨å€™..."):
                genai.configure(api_key=api_input.strip())
                model_pro = genai.GenerativeModel("gemini-1.5-pro", system_instruction="è«‹æ ¹æ“šå¯©æ ¸è¡¨ç”¢å‡ºæ­£å¼è©¦å·èˆ‡åƒè€ƒç­”æ¡ˆã€‚")
                
                with st.chat_message("ai"):
                    placeholder = st.empty()
                    full_res = ""
                    res = generate_with_retry(model_pro, f"{st.session_state.last_prompt_content}\n---\nåƒè€ƒå¯©æ ¸è¡¨ï¼š\n{current_md}\n\nè«‹æ­£å¼å‡ºé¡Œã€‚")
                    for chunk in res:
                        full_res += chunk.text
                        placeholder.markdown(full_res + "â–Œ")
                    placeholder.markdown(full_res)
                st.session_state.chat_history.append({"role": "model", "content": full_res})

        if st.button("â¬…ï¸ è¿”å›ä¿®æ”¹åƒæ•¸", use_container_width=True):
            st.session_state.phase = 1
            st.rerun()
    
    # é¡¯ç¤ºå‡ºé¡Œå¾Œçš„æ­·å²èˆ‡å¾®èª¿
    if len(st.session_state.chat_history) > 1:
        for msg in st.session_state.chat_history[1:]:
             with st.chat_message("ai"): st.markdown(msg["content"])
        if prompt := st.chat_input("å¾®èª¿é¡Œç›®ï¼Ÿ"):
            with st.chat_message("user"): st.markdown(prompt)
            with st.spinner("ğŸ”§ ä¿®æ”¹ä¸­..."):
                res = generate_with_retry(genai.GenerativeModel("gemini-1.5-pro").start_chat(history=[]), prompt)
                st.session_state.chat_history.append({"role": "model", "content": res.text})
                st.rerun()

st.markdown('<div class="custom-footer">Â© 2026 æ–°ç«¹å¸‚é¦™å±±å€å…§æ¹–åœ‹å°. All Rights Reserved.</div>', unsafe_allow_html=True)
