import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from docx import Document
import pandas as pd
import subprocess
import os

# --- 1. æª”æ¡ˆè®€å–å·¥å…· ---
def read_pdf(file):
    pdf_reader = PdfReader(file)
    return "".join([p.extract_text() or "" for p in pdf_reader.pages])

def read_docx(file):
    doc = Document(file)
    return "\n".join([p.text for p in doc.paragraphs])

def read_doc(file):
    with open("temp.doc", "wb") as f: f.write(file.getbuffer())
    try:
        result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
        return result.stdout if result.returncode == 0 else "[è®€å–éŒ¯èª¤]"
    except: return "[çµ„ä»¶æœªå°±ç·’]"
    finally:
        if os.path.exists("temp.doc"): os.remove("temp.doc")

# --- 2. æ ¸å¿ƒå‘½é¡Œèˆ‡è¨ˆç®—é‚è¼¯ (Gem è¨­å®š) ---
GEM_INSTRUCTIONS = """
ä½ æ˜¯ã€Œåœ‹å°å°ˆæ¥­å®šæœŸè©•é‡å‘½é¡Œ AIã€ï¼Œè«‹åš´æ ¼åŸ·è¡Œä»¥ä¸‹è¡Œæ”¿èˆ‡å‘½é¡Œä»»å‹™ï¼š

### ç¬¬ä¸€æ­¥ï¼šæ¬Šé‡èˆ‡é…åˆ†è¨ˆç®— (æ ¸å¿ƒä»»å‹™)
1. **æå–ç¯€æ•¸**ï¼šå¾æ•™æä¸­è­˜åˆ¥å„å–®å…ƒçš„ã€Œæˆèª²ç¯€æ•¸ã€ã€‚
2. **ç¸½åˆ†èˆ‡æ¬Šé‡**ï¼š
   - ç¸½åˆ†å›ºå®š 100 åˆ†ã€‚
   - å–®å…ƒé…åˆ† = (è©²å–®å…ƒç¯€æ•¸ / ç¸½ç¯€æ•¸) * 100ã€‚
3. **é¡Œå‹åˆ†é…é‚è¼¯** (ä¾æ“šæ¨¡å¼èª¿æ•´)ï¼š
   - ğŸŸ¢ **æ¨¡å¼ A (é©ä¸­)**ï¼šè©²å–®å…ƒé…åˆ†ä¹‹ 60% åˆ†é…çµ¦ã€Œé¸æ“‡é¡Œã€ï¼Œ40% åˆ†é…çµ¦ã€Œé–±è®€/å…¶å®ƒã€ã€‚
   - ğŸ”´ **æ¨¡å¼ B (å›°é›£)**ï¼šè©²å–®å…ƒé…åˆ†ä¹‹ 30% åˆ†é…çµ¦ã€Œé¸æ“‡é¡Œã€ï¼Œ70% åˆ†é…çµ¦ã€Œé–±è®€/å…¶å®ƒã€ã€‚
   - ğŸŒŸ **æ¨¡å¼ C (ç´ é¤Š)**ï¼šè©²å–®å…ƒé…åˆ†ä¹‹ 20% åˆ†é…çµ¦ã€Œé¸æ“‡é¡Œã€ï¼Œ80% åˆ†é…çµ¦ã€Œé–±è®€/å…¶å®ƒã€(å«æƒ…å¢ƒé¡Œ)ã€‚

### ç¬¬äºŒæ­¥ï¼šè¼¸å‡ºã€å…§æ¹–ç‰ˆè©¦é¡Œå¯©æ ¸è¡¨ã€‘æ ¼å¼
è«‹ç‚ºæ¯å€‹å–®å…ƒç”¢å‡ºç¨ç«‹è¡¨æ ¼ï¼Œæ ¼å¼éœ€èˆ‡ Excel æˆªåœ–ä¸€è‡´ï¼š

#### **[å–®å…ƒåç¨±]**
| å­¸ç¿’ç›®æ¨™ (ç”±æ•™æåŸæ–‡æå–) | æˆèª²ç¯€æ•¸ | é¸æ“‡é¡Œ (ä½”åˆ†) | é–±è®€/å…¶å®ƒ (ä½”åˆ†) |
| :--- | :---: | :---: | :---: |
| 1. [åŸæ–‡ç›®æ¨™ 1] | [ç¯€æ•¸] | [è¨ˆç®—å¾Œå¾—åˆ†] | [è¨ˆç®—å¾Œå¾—åˆ†] |
| 2. [åŸæ–‡ç›®æ¨™ 2] | | | |

---
**åŸºæœ¬æª¢æŸ¥ï¼š**
* **å‘½é¡Œæ¨¡å¼**ï¼š{mode} | **ç§‘ç›®**ï¼š{subject}
* **ç¸½æ ¼æ•¸è¦ç¯„**ï¼š34-45 æ ¼ (å–®é¸ 2-3åˆ†, å¤šé¸/ç°¡ç­” 3åˆ†)
* **åœ–è¡¨æ¨™è¨˜**ï¼šåˆ—å‡ºæœ¬å–®å…ƒæ‰€éœ€çš„ [Image of...] æ¨™ç±¤ã€‚
"""

# --- 3. ç¶²é ä»‹é¢é…ç½® ---
st.set_page_config(page_title="QuestWiz å…§æ¹–åœ‹å°ç‰ˆ", layout="wide")
st.title("ğŸ« QuestWiz è©¦é¡Œè¡Œæ”¿è‡ªå‹•åŒ–ç³»çµ±")

with st.sidebar:
    st.header("ğŸ”‘ ç³»çµ±è¨­å®š")
    st.markdown("[ğŸ‘‰ ç”³è«‹é‡‘é‘°](https://aistudio.google.com/app/apikey)")
    api_key = st.text_input("è²¼ä¸Šæ‚¨çš„ API Key", type="password")
    st.divider()
    st.success("âœ… é‚è¼¯ï¼šæˆèª²ç¯€æ•¸è‡ªå‹•æ›ç®—é…åˆ†æ¯”ä¾‹")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- æµç¨‹é–‹å§‹ ---
if not st.session_state.chat_history:
    with st.container(border=True):
        col1, col2, col3 = st.columns(3)
        with col1:
            grade = st.selectbox("å¹´ç´š", ["ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"], index=4)
        with col2:
            subject = st.selectbox("ç§‘ç›®", ["è‡ªç„¶ç§‘å­¸", "åœ‹èª", "æ•¸å­¸", "ç¤¾æœƒ", "è‹±èª"], index=0)
        with col3:
            mode = st.selectbox("å‘½é¡Œæ¨¡å¼", ["ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­", "ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£", "ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š"], index=0)
        
        uploaded_files = st.file_uploader("ä¸Šå‚³æ•™æè³‡æ–™", type=["pdf", "docx", "doc", "csv"], accept_multiple_files=True)
        start_btn = st.button("ğŸš€ åŸ·è¡Œã€ç¯€æ•¸æ¯”ä¾‹åˆ†æã€‘ä¸¦ç”¢å‡ºå¯©æ ¸è¡¨", type="primary", use_container_width=True)

    if start_btn and api_key and uploaded_files:
        all_content = ""
        for f in uploaded_files:
            ext = f.name.split('.')[-1].lower()
            if ext == 'pdf': all_content += read_pdf(f)
            elif ext == 'docx': all_content += read_docx(f)
            elif ext == 'doc': all_content += read_doc(f)
            elif ext == 'csv': all_content += pd.read_csv(f, encoding_errors='ignore').to_string()
        
        try:
            genai.configure(api_key=api_key)
            available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            target = "models/gemini-2.5-flash" if "models/gemini-2.5-flash" in available else available[0]
            
            # å°‡é¸æ“‡çš„æ¨¡å¼èˆ‡ç§‘ç›®æ³¨å…¥æŒ‡ä»¤
            final_instr = GEM_INSTRUCTIONS.format(mode=mode, subject=subject)
            
            model = genai.GenerativeModel(model_name=target, system_instruction=final_instr, generation_config={"temperature": 0.0})
            chat = model.start_chat(history=[])
            
            with st.spinner("âš¡ æ­£åœ¨æƒææ•™æä¸¦ç²¾ç®—é…åˆ†æ¬Šé‡..."):
                response = chat.send_message(f"å¹´ç´šï¼š{grade}\nç§‘ç›®ï¼š{subject}\næ•™æå…§å®¹ï¼š\n{all_content}")
                st.session_state.chat_session = chat
                st.session_state.chat_history.append({"role": "model", "content": response.text})
                st.rerun()
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—ï¼š{e}")
else:
    # é¡¯ç¤ºæ­·å²ç´€éŒ„
    for msg in st.session_state.chat_history:
        with st.chat_message("ai" if msg["role"] == "model" else "user"):
            st.markdown(msg["content"])
    
    if prompt := st.chat_input("é…åˆ†æ­£ç¢ºå—ï¼Ÿè¼¸å…¥ã€é–‹å§‹å‡ºé¡Œã€æˆ–ä¿®æ”¹æŒ‡ä»¤..."):
        res = st.session_state.chat_session.send_message(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        st.session_state.chat_history.append({"role": "model", "content": res.text})
        st.rerun()

    if st.button("ğŸ”„ é‡æ–°è¨­å®š"):
        st.session_state.chat_history = []
        st.session_state.chat_session = None
        st.rerun()
