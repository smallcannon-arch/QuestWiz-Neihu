import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
from docx import Document
import pandas as pd
import subprocess
import os

# --- 1. æª”æ¡ˆè®€å–å·¥å…· ---
def read_pdf(file):
    pdf_reader = PdfReader(file)
    return "".join([p.extract_text() or "" for p in pdf_reader.pages])

def read_docx(file):
    doc = Document(file)
    return "\n".join([p.text for p in doc.paragraphs])

def read_doc(file):
    with open("temp.doc", "wb") as f:
        f.write(file.getbuffer())
    try:
        result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
        return result.stdout if result.returncode == 0 else "[DOC è®€å–å¤±æ•—]"
    except: return "[ç³»çµ±æœªå°±ç·’]"
    finally:
        if os.path.exists("temp.doc"): os.remove("temp.doc")

# --- 2. æ•´åˆæ‚¨çš„å°ˆæ¥­ Gem å‘½é¡ŒæŒ‡ä»¤ ---
GEM_INSTRUCTIONS = """
ä½ æ˜¯ã€Œåœ‹å°å°ˆæ¥­å®šæœŸè©•é‡å‘½é¡Œ AIã€ï¼Œç²¾é€š 1-6 å¹´ç´šå…¨ç§‘æ•™ææ•™æ³•ã€‚
åš´æ ¼éµå®ˆã€Œå…©æ®µå¼è¼¸å‡ºã€ï¼š
1. Phase 1ï¼šåƒ…è¼¸å‡ºã€è©¦é¡Œå¯©æ ¸è¡¨ã€‘ï¼ˆå«é…åˆ†ã€åœ–è¡¨æ¸…å–®ã€ç›®æ¨™è¦†è“‹ï¼‰ã€‚
2. Phase 2ï¼šä½¿ç”¨è€…ç¢ºèªå¾Œï¼Œæ‰è¼¸å‡ºã€è©¦é¡Œã€‘ã€‚

### æ ¸å¿ƒåƒæ•¸ï¼š
* ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­ (Moderate) - 60% è¨˜æ†¶ç†è§£ + 40% åŸºç¤æ‡‰ç”¨ã€‚
* ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£ (Hard) - 30% æ‡‰ç”¨ + 70% åˆ†æè©•é‘‘ã€‚
* ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š (Literacy) - 100% æƒ…å¢ƒè§£æ±ºå•é¡Œï¼Œæ¥è»Œ PISA/PIRLS æ¨™æº–ã€‚

### éµå¾‹ï¼š
* ç¸½åˆ†ï¼šå›ºå®š 100 åˆ†ã€‚æ ¼æ•¸ï¼š34ï½45 æ ¼ã€‚
* åš´ç¦å‡ºç¾ã€Œä»¥ä¸Šçš†æ˜¯ã€ã€ã€Œä»¥ä¸Šçš†éã€ã€‚
* é¸é …éœ€å…·å‚™é¡åˆ¥ä¸€è‡´æ€§ (OptionClass)ã€‚
"""

# --- 3. ç¶²é ä»‹é¢ ---
st.set_page_config(page_title="QuestWiz å…§æ¹–åœ‹å°å°ˆå±¬ç‰ˆ", layout="wide")
st.title("ğŸ« QuestWiz è©¦é¡Œè¡Œæ”¿è‡ªå‹•åŒ–ç³»çµ±")

with st.sidebar:
    st.header("ğŸ”‘ ç³»çµ±è¨­å®š")
    st.markdown("[ğŸ‘‰ ç”³è«‹é‡‘é‘°](https://aistudio.google.com/app/apikey)")
    api_key = st.text_input("è²¼ä¸Šæ‚¨çš„ Gemini API Key", type="password")
    st.divider()
    st.success("âœ… æ ¸å¿ƒå·²è¼‰å…¥ï¼šåœ‹å°å°ˆæ¥­å‘½é¡Œ Gem é‚è¼¯")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- ç¬¬ä¸€éšæ®µï¼šåˆ†æèˆ‡è¨ºæ–· ---
if not st.session_state.chat_history:
    with st.container(border=True):
        col1, col2, col3 = st.columns(3)
        with col1:
            grade = st.selectbox("å¹´ç´š", ["ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"], index=4)
        with col2:
            subject = st.selectbox("ç§‘ç›®", ["è‡ªç„¶ç§‘å­¸", "åœ‹èª", "æ•¸å­¸", "ç¤¾æœƒ", "è‹±èª"], index=0)
        with col3:
            mode = st.selectbox("å‘½é¡Œæ¨¡å¼", ["ğŸŸ¢ æ¨¡å¼ Aï¼šé©ä¸­", "ğŸ”´ æ¨¡å¼ Bï¼šå›°é›£", "ğŸŒŸ æ¨¡å¼ Cï¼šç´ é¤Š"], index=0)
        
        uploaded_files = st.file_uploader("ä¸Šå‚³æ•™æè³‡æ–™", type=["pdf", "docx", "doc", "csv"], accept_multiple_files=True)
        start_btn = st.button("ğŸš€ ä¾ç…§ Gem æŒ‡ä»¤ç”¢å‡ºå¯©æ ¸è¡¨", type="primary", use_container_width=True)

    if start_btn and api_key and uploaded_files:
        all_content = ""
        for f in uploaded_files:
            ext = f.name.split('.')[-1].lower()
            if ext == 'pdf': all_content += read_pdf(f)
            elif ext == 'docx': all_content += read_docx(f)
            elif ext == 'doc': all_content += read_doc(f)
            elif ext == 'csv': all_content += pd.read_csv(f, encoding_errors='ignore').to_string()
        
        try:
            genai.configure(api_key=api_key)
            
            # --- æ ¸å¿ƒé™¤éŒ¯é‚è¼¯ï¼šè‡ªå‹•å°‹æ‰¾æ‚¨é‡‘é‘°æ”¯æ´çš„æ¨¡å‹ ---
            available = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            # å„ªå…ˆæ¬Šï¼š2.5-flash > 1.5-flash > å…¶å®ƒ
            target_model = ""
            for m in ["models/gemini-2.5-flash", "models/gemini-1.5-flash", "models/gemini-1.5-pro"]:
                if m in available:
                    target_model = m
                    break
            if not target_model: target_model = available[0]
            
            st.info(f"ğŸ“¡ ç³»çµ±é€£ç·šæˆåŠŸï¼šå·²è‡ªå‹•å°é½Šæœ€ä½³è·¯å¾‘ {target_model}")
            
            model = genai.GenerativeModel(
                model_name=target_model,
                system_instruction=GEM_INSTRUCTIONS,
                generation_config={"temperature": 0.0}
            )
            chat = model.start_chat(history=[])
            
            with st.spinner("AI æ­£åœ¨å·¥ä½œä¸­..."):
                prompt = f"å¹´ç´šï¼š{grade}\nç§‘ç›®ï¼š{subject}\næ¨¡å¼ï¼š{mode}\næ•™æå…§å®¹ï¼š\n{all_content}\n--- è«‹è¼¸å‡ºã€è©¦é¡Œå¯©æ ¸è¡¨ã€‘è¡¨æ ¼ã€‚"
                response = chat.send_message(prompt)
                st.session_state.chat_session = chat
                st.session_state.chat_history.append({"role": "model", "content": response.text})
                st.rerun()
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—ï¼š{e}")

else:
    # é€™è£¡é¡¯ç¤ºå°è©±ç´€éŒ„èˆ‡å¾ŒçºŒæŒ‡ä»¤
    for msg in st.session_state.chat_history:
        with st.chat_message("ai" if msg["role"] == "model" else "user"):
            st.markdown(msg["content"])
    
    if prompt := st.chat_input("ç¢ºèªå¯©æ ¸è¡¨å¾Œï¼Œè«‹è¼¸å…¥ã€é–‹å§‹å‡ºé¡Œã€..."):
        with st.chat_message("user"): st.markdown(prompt)
        res = st.session_state.chat_session.send_message(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        st.session_state.chat_history.append({"role": "model", "content": res.text})
        st.rerun()

    if st.button("ğŸ”„ é‡æ–°è¨­å®š"):
        st.session_state.chat_history = []
        st.session_state.chat_session = None
        st.rerun()
