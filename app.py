import streamlit as st
import google.generativeai as genai
import io
import pandas as pd
import math
from pypdf import PdfReader
from docx import Document
from pptx import Presentation  # éœ€å®‰è£: pip install python-pptx

# --- 1. æ ¸å¿ƒè¨­å®šèˆ‡å·¥å…· ---
SUBJECT_Q_TYPES = {
    "åœ‹èª": ["åœ‹å­—æ³¨éŸ³", "æ”¹éŒ¯å­—", "å­—è©ç¾©æ¸¬é©—", "èª²æ–‡ç†è§£", "é–±è®€æ¸¬é©—", "æˆèªé‹ç”¨"],
    "æ•¸å­¸": ["é¸æ“‡é¡Œ", "å¡«å……é¡Œ", "è¨ˆç®—é¡Œ", "æ‡‰ç”¨é¡Œ", "ç•«åœ–é¡Œ"],
    "è‡ªç„¶ç§‘å­¸": ["æ˜¯éé¡Œ", "é¸æ“‡é¡Œ", "åšåšçœ‹", "ç§‘å­¸é–±è®€", "å¯¦é©—é¡Œ"],
    "ç¤¾æœƒ": ["æ˜¯éé¡Œ", "é¸æ“‡é¡Œ", "å‹¾é¸é¡Œ", "é€£é€£çœ‹", "ç°¡ç­”é¡Œ", "åœ–è¡¨é¡Œ"],
    "è‹±èª": ["Listen & Check", "Listen & Choose", "Read & Choose", "Look & Write", "Reading Comprehension"],
    "": ["å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "ç°¡ç­”é¡Œ"]
}

# --- 2. æª”æ¡ˆè®€å–å·¥å…· (å…¨èƒ½å¢å¼·ç‰ˆ) ---
@st.cache_data
def extract_text_from_files(files):
    text_content = ""
    for file in files:
        try:
            filename = file.name.lower()
            file_header = f"\n\n=== æª”æ¡ˆä¾†æºï¼š{file.name} ===\n"
            extracted_text = ""

            # === PDF è™•ç† ===
            if filename.endswith('.pdf'):
                pdf_reader = PdfReader(file)
                for page in pdf_reader.pages:
                    extracted_text += (page.extract_text() or "") + "\n"
                
                # é˜²å‘†ï¼šå¦‚æœè®€å‡ºä¾†å®Œå…¨æ²’å­— (å¯èƒ½æ˜¯æƒææª”)
                if len(extracted_text.strip()) < 10:
                    text_content += file_header + "[è­¦ç¤º] æª”æ¡ˆå…§å®¹éå°‘ï¼Œä¼¼ä¹æ˜¯åœ–ç‰‡æƒææª”ã€‚è«‹ä½¿ç”¨å´é‚Šæ¬„å·¥å…·è½‰æª”å¾Œå†è©¦ã€‚\n"
                else:
                    text_content += file_header + extracted_text

            # === Word (.docx) è™•ç† ===
            elif filename.endswith('.docx'):
                doc = Document(file)
                extracted_text = "\n".join([p.text for p in doc.paragraphs])
                text_content += file_header + extracted_text

            # === PowerPoint (.pptx) è™•ç† ===
            elif filename.endswith('.pptx'):
                try:
                    prs = Presentation(file)
                    for slide_idx, slide in enumerate(prs.slides):
                        slide_text = []
                        for shape in slide.shapes:
                            if hasattr(shape, "text") and shape.text.strip():
                                slide_text.append(shape.text)
                        if slide_text:
                            extracted_text += f"[Slide {slide_idx+1}]\n" + "\n".join(slide_text) + "\n"
                    text_content += file_header + extracted_text
                except Exception as e:
                    text_content += file_header + f"[PPTX è®€å–éŒ¯èª¤] {str(e)}"

            # === èˆŠç‰ˆæ ¼å¼ (.doc, .ppt) ===
            elif filename.endswith('.doc') or filename.endswith('.ppt'):
                text_content += file_header + "[ç³»çµ±é™åˆ¶] è«‹å°‡ .doc/.ppt èˆŠç‰ˆæª”æ¡ˆå¦å­˜ç‚º .docx/.pptx å¾Œå†ä¸Šå‚³ï¼Œä»¥ç¢ºä¿ AI åˆ¤è®€æ­£ç¢ºã€‚"

            # === ç´”æ–‡å­— (.txt) ===
            elif filename.endswith('.txt'):
                text_content += file_header + str(file.read(), "utf-8")

        except Exception as e:
            text_content += f"\n[è®€å–éŒ¯èª¤: {file.name}] åŸå› ï¼š{str(e)}\n"
            
    return text_content

# --- 3. æ•¸å­¸é…åˆ†é‚è¼¯ (ç¸½åˆ† 100 é–å®šæ¼”ç®—æ³•) ---
def calculate_scores(df):
    """
    è¼¸å…¥åŒ…å« 'æˆèª²ç¯€æ•¸' çš„ DataFrameï¼Œè¼¸å‡ºåŒ…å« 'é è¨ˆé…åˆ†' çš„ DataFrameã€‚
    ä½¿ç”¨æœ€å¤§é¤˜æ•¸æ³•ç¢ºä¿ç¸½åˆ†å‰›å¥½ 100 åˆ†ã€‚
    """
    try:
        # 1. æ¸…ç†æ•¸æ“šï¼šè½‰ç‚ºæ•¸å­—ï¼Œç„¡æ•ˆå€¼è¨­ç‚º 1 ç¯€
        df['æˆèª²ç¯€æ•¸'] = pd.to_numeric(df['æˆèª²ç¯€æ•¸'], errors='coerce').fillna(1)
        
        # 2. è¨ˆç®—ç¸½ç¯€æ•¸
        total_hours = df['æˆèª²ç¯€æ•¸'].sum()
        if total_hours == 0: total_hours = 1
        
        # 3. åˆæ­¥åˆ†é… (ç„¡æ¢ä»¶æ¨å»)
        df['åŸå§‹é…åˆ†'] = (df['æˆèª²ç¯€æ•¸'] / total_hours) * 100
        df['é è¨ˆé…åˆ†'] = df['åŸå§‹é…åˆ†'].apply(math.floor)
        
        # 4. é¤˜æ•¸è™•ç† (è£œè¶³åˆ° 100 åˆ†)
        current_total = df['é è¨ˆé…åˆ†'].sum()
        remainder = 100 - current_total
        
        if remainder > 0:
            # æ‰¾å‡ºè¢«æ¨å»æœ€å¤šåˆ†æ•¸çš„å–®å…ƒï¼Œä¾åºè£œåˆ†
            df['é¤˜æ•¸æ¬Šé‡'] = df['åŸå§‹é…åˆ†'] - df['é è¨ˆé…åˆ†']
            indices_to_add = df.nlargest(int(remainder), 'é¤˜æ•¸æ¬Šé‡').index
            df.loc[indices_to_add, 'é è¨ˆé…åˆ†'] += 1
        elif remainder < 0:
            # ç†è«–ä¸Š floor ä¸æœƒç™¼ç”Ÿé€™ç¨®æƒ…æ³ï¼Œä½†ä»¥é˜²è¬ä¸€
             df.iloc[0, df.columns.get_loc('é è¨ˆé…åˆ†')] += remainder

        # ç§»é™¤æš«å­˜æ¬„ä½
        if 'åŸå§‹é…åˆ†' in df.columns: df = df.drop(columns=['åŸå§‹é…åˆ†'])
        if 'é¤˜æ•¸æ¬Šé‡' in df.columns: df = df.drop(columns=['é¤˜æ•¸æ¬Šé‡'])
        
        return df
    except Exception as e:
        st.error(f"é…åˆ†è¨ˆç®—éŒ¯èª¤: {e}")
        return df

# --- 4. Excel ä¸‹è¼‰å·¥å…· (ç¬¦åˆå¯©æ ¸è¡¨æ ¼å¼) ---
def df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        # ç‚ºäº†ç¬¦åˆå¯©æ ¸è¡¨æ ¼å¼ï¼Œæˆ‘å€‘åŠ å…¥ç©ºç™½æ¬„ä½è®“è€å¸«å¡«å¯«é¡Œå‹é…åˆ†
        export_df = df.copy()
        export_df["é¸æ“‡é¡Œé…åˆ†"] = "" 
        export_df["éé¸é¡Œé…åˆ†"] = ""
        
        export_df.to_excel(writer, index=False, sheet_name='å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨')
        workbook = writer.book
        worksheet = writer.sheets['å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨']
        
        # æ ¼å¼è¨­å®š
        header_fmt = workbook.add_format({'bold': True, 'align': 'center', 'bg_color': '#DCE6F1', 'border': 1})
        
        # è¨­å®šæ¬„å¯¬
        worksheet.set_column('A:A', 20) # å–®å…ƒåç¨±
        worksheet.set_column('B:B', 50) # å­¸ç¿’ç›®æ¨™
        worksheet.set_column('C:C', 10) # ç¯€æ•¸
        worksheet.set_column('D:D', 12) # é è¨ˆé…åˆ†
        worksheet.set_column('E:F', 15) # é¡Œå‹é…åˆ†æ¬„ä½
        
        # å¯«å…¥æ ¼å¼
        for col_num, value in enumerate(export_df.columns.values):
            worksheet.write(0, col_num, value, header_fmt)
            
    return output.getvalue()

# --- 5. è‡ªå‹•æœå°‹å¯ç”¨æ¨¡å‹ (ä¿®å¾© 404 éŒ¯èª¤) ---
def get_available_flash_model(api_key):
    """è‡ªå‹•å°‹æ‰¾å¸³è™Ÿå¯ç”¨çš„ Flash æ¨¡å‹"""
    try:
        genai.configure(api_key=api_key)
        valid_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # å„ªå…ˆé †åºï¼šFlash -> Pro -> ä»»ä½•å¯ç”¨
        for m in valid_models:
            if 'flash' in m.lower() and '1.5' in m.lower(): return m
        for m in valid_models:
            if 'flash' in m.lower(): return m
        for m in valid_models:
            if 'pro' in m.lower(): return m
            
        return "models/gemini-1.5-flash" # æœ€å¾Œå˜—è©¦
    except Exception:
        return "models/gemini-1.5-flash"

# --- 6. AI æç¤ºè© (æ¥µç°¡åŒ–ï¼šåªåšæ‘˜å–) ---
GEM_EXTRACT_PROMPT = """
ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„æ•™æåˆ†æå¸«ã€‚è«‹åˆ†æä»¥ä¸‹æ•™æå…§å®¹ï¼Œä¸¦æå–ã€Œå–®å…ƒåç¨±ã€ã€ã€Œå­¸ç¿’ç›®æ¨™ã€èˆ‡ã€Œæˆèª²ç¯€æ•¸ã€ã€‚

**è¼¸å‡ºè¦å‰‡ (åš´æ ¼éµå®ˆ)ï¼š**
1. åƒ…è¼¸å‡ºä¸€å€‹ Markdown è¡¨æ ¼ã€‚
2. æ¬„ä½å¿…é ˆåŒ…å«ï¼š| å–®å…ƒåç¨± | å­¸ç¿’ç›®æ¨™ | æˆèª²ç¯€æ•¸ |
3. ã€Œæˆèª²ç¯€æ•¸ã€æ¬„ä½**åªèƒ½å¡«å…¥æ•¸å­—** (ä¾‹å¦‚: 4, 3, 5)ã€‚è‹¥æ•™ææœªæåŠï¼Œè«‹æ ¹æ“šå…§å®¹é•·åº¦æ¨ä¼°ä¸€å€‹æ•´æ•¸ (1~5)ã€‚
4. å­¸ç¿’ç›®æ¨™è«‹ç²¾ç°¡æ‘˜éŒ„é‡é» (ä¸è¦è¶…é 50 å­—)ã€‚
5. **ä¸è¦**è¨ˆç®—åˆ†æ•¸ï¼Œ**ä¸è¦**è¼¸å‡ºå…¶ä»–å»¢è©±ã€‚

æ•™æå…§å®¹ï¼š
{content}
"""

# --- 7. ä¸»ç¨‹å¼ä»‹é¢ ---
st.set_page_config(page_title="å…§æ¹–åœ‹å°å‡ºé¡Œç³»çµ± (Pro)", layout="wide")

st.markdown("""
    <style>
    .school-header { background: linear-gradient(90deg, #1E293B 0%, #334155 100%); padding: 20px; border-radius: 12px; text-align: center; color: white; margin-bottom: 20px; }
    </style>
    <div class="school-header">
        <h2 style="margin:0;">å…§æ¹–åœ‹å° AI å‘½é¡Œèˆ‡å¯©æ ¸ç³»çµ±</h2>
        <p style="opacity:0.8; margin-top:5px;">å­¸ç¿’ç›®æ¨™è‡ªå‹•æ‘˜å– â€¢ æ™ºæ…§é…åˆ† â€¢ é›™å‘ç´°ç›®è¡¨ç”Ÿæˆ</p>
    </div>
""", unsafe_allow_html=True)

# ç‹€æ…‹åˆå§‹åŒ–
if "extracted_data" not in st.session_state: st.session_state.extracted_data = None
if "step" not in st.session_state: st.session_state.step = 1

# --- å´é‚Šæ¬„ï¼šè¨­å®šèˆ‡å·¥å…· ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šèˆ‡é‡‘é‘°")
    api_key = st.text_input("Google API Key", type="password", placeholder="åœ¨æ­¤è²¼ä¸Šæ‚¨çš„ Key")
    
    if st.button("ğŸ”„ é‡ç½®ç³»çµ±"):
        st.session_state.extracted_data = None
        st.session_state.step = 1
        st.rerun()

    st.divider()
    st.markdown("### ğŸ› ï¸ è¬ç”¨è½‰æª”å·¥å…·ç®±")
    st.info("é‡åˆ°èˆŠç‰ˆæª”æ¡ˆ (.doc, .ppt) æˆ– åœ–ç‰‡å‹ PDF è®€ä¸åˆ°å­—ï¼Ÿè«‹å…ˆç”¨ä¸‹æ–¹å·¥å…·è½‰æª”ã€‚")
    
    with st.expander("ğŸ“‚ èˆŠæª”æ•‘æ˜Ÿ (è½‰æˆ .docx/.pptx)"):
        st.markdown("""
        æ‚¨çš„æª”æ¡ˆæ˜¯ 2003 å¹´ä»¥å‰çš„èˆŠæ ¼å¼å—ï¼Ÿ
        1. **Word è½‰æª”**ï¼š[CloudConvert (Doc to Docx)](https://cloudconvert.com/doc-to-docx)
        2. **PPT è½‰æª”**ï¼š[CloudConvert (Ppt to Pptx)](https://cloudconvert.com/ppt-to-pptx)
        """)

    with st.expander("ğŸ“¸ åœ–ç‰‡/æƒææª”æ•‘æ˜Ÿ (OCR)"):
        st.markdown("""
        æ‚¨çš„ PDF æ˜¯æƒæçš„åœ–ç‰‡å—ï¼ŸAI è®€ä¸åˆ°å­—ï¼Ÿ
        1. **PDF è½‰ Word (å« OCR)**ï¼š[iLovePDF](https://www.ilovepdf.com/zh-tw/pdf_to_word)
        2. **åœ–ç‰‡ è½‰ æ–‡å­—**ï¼š[Google Drive](https://drive.google.com)  
           *(å°æ’‡æ­¥ï¼šä¸Šå‚³åœ–ç‰‡ -> å³éµ -> é¸æ“‡ã€ŒGoogle æ–‡ä»¶ã€é–‹å•Ÿ)*
        """)

# --- Step 1: ä¸Šå‚³èˆ‡åƒæ•¸ ---
if st.session_state.step == 1:
    col1, col2 = st.columns([1, 2])
    with col1:
        st.subheader("1. åƒæ•¸è¨­å®š")
        grade = st.selectbox("å¹´ç´š", ["ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"])
        subject = st.selectbox("ç§‘ç›®", list(SUBJECT_Q_TYPES.keys()))
    with col2:
        st.subheader("2. ä¸Šå‚³æ•™æ")
        st.markdown("æ”¯æ´æ ¼å¼ï¼š**PDF, DOCX, PPTX** (å»ºè­°) / TXT")
        uploaded_files = st.file_uploader("è«‹é¸æ“‡æª”æ¡ˆ", type=["pdf", "docx", "pptx", "txt", "doc", "ppt"], accept_multiple_files=True)

    if st.button("ğŸš€ é–‹å§‹åˆ†ææ•™æ (ç”Ÿæˆå¯©æ ¸è¡¨)", type="primary", use_container_width=True):
        if not api_key:
            st.error("âŒ è«‹åœ¨å·¦å´è¼¸å…¥ Google API Key")
        elif not uploaded_files:
            st.warning("âš ï¸ è«‹ä¸Šå‚³è‡³å°‘ä¸€å€‹æ•™ææª”æ¡ˆ")
        else:
            with st.spinner("ğŸ¤– AI æ­£åœ¨é–±è®€æ•™æä¸¦æ‘˜å–çµæ§‹ (ä½¿ç”¨ Flash æ¨¡å‹)..."):
                try:
                    # 1. è®€æª”
                    text_content = extract_text_from_files(uploaded_files)
                    
                    # 2. è‡ªå‹•é¸æ¨¡å‹
                    best_model_name = get_available_flash_model(api_key)
                    st.toast(f"å·²å•Ÿç”¨çœéŒ¢æ¨¡å¼ï¼š{best_model_name}", icon="âœ…")
                    
                    model = genai.GenerativeModel(best_model_name)
                    
                    # 3. ç™¼é€è«‹æ±‚
                    response = model.generate_content(GEM_EXTRACT_PROMPT.format(content=text_content[:40000]))
                    raw_text = response.text
                    
                    # 4. è§£æè¡¨æ ¼
                    lines = [line.strip() for line in raw_text.split('\n') if "|" in line and "---" not in line]
                    data = []
                    for line in lines:
                        row = [cell.strip() for cell in line.split('|') if cell.strip()]
                        if len(row) >= 3:
                            data.append(row[:3])
                    
                    if len(data) > 0:
                        # è™•ç†æ¨™é¡Œåˆ—
                        headers = ["å–®å…ƒåç¨±", "å­¸ç¿’ç›®æ¨™", "æˆèª²ç¯€æ•¸"]
                        start_idx = 1 if "å–®å…ƒ" in data[0][0] else 0
                        
                        df = pd.DataFrame(data[start_idx:], columns=headers)
                        
                        # 5. å‘¼å« Python é€²è¡Œé…åˆ†è¨ˆç®—
                        df_calculated = calculate_scores(df)
                        
                        st.session_state.extracted_data = df_calculated
                        st.session_state.step = 2
                        st.rerun()
                    else:
                        st.error("âŒ AI ç„¡æ³•è­˜åˆ¥æ•™æçµæ§‹ï¼Œè«‹ç¢ºèªæª”æ¡ˆå…§å®¹æ˜¯å¦æ¸…æ™°ï¼Œæˆ–ä½¿ç”¨å´é‚Šæ¬„è½‰æª”å·¥å…·ã€‚")
                        with st.expander("æŸ¥çœ‹ AI åŸå§‹å›æ‡‰"):
                            st.text(raw_text)
                            
                except Exception as e:
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- Step 2: ç¢ºèªèˆ‡ä¸‹è¼‰ ---
elif st.session_state.step == 2:
    st.subheader("âœ… å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨ (è‡ªå‹•é…åˆ†å®Œç•¢)")
    
    st.info("ğŸ’¡ æ‚¨å¯ä»¥ç›´æ¥ä¿®æ”¹ã€Œæˆèª²ç¯€æ•¸ã€ï¼Œå³å´çš„ã€Œé è¨ˆé…åˆ†ã€æœƒè‡ªå‹•é‡æ–°è¨ˆç®—ï¼Œä¿æŒç¸½åˆ† 100ã€‚")
    
    # ä½¿ç”¨ data_editor è®“ä½¿ç”¨è€…ä¿®æ”¹
    df_current = st.session_state.extracted_data
    
    edited_df = st.data_editor(
        df_current,
        column_config={
            "é è¨ˆé…åˆ†": st.column_config.NumberColumn("é è¨ˆé…åˆ† (%)", help="ç”±ç³»çµ±ä¾ç¯€æ•¸æ¯”ä¾‹è‡ªå‹•è¨ˆç®—", disabled=True), # è¨­ç‚ºå”¯è®€ï¼Œå¼·åˆ¶ç”±ç¯€æ•¸é©…å‹•
            "æˆèª²ç¯€æ•¸": st.column_config.NumberColumn("æˆèª²ç¯€æ•¸", help="å¯ä¿®æ”¹ï¼Œä¿®æ”¹å¾Œè‡ªå‹•æ›´æ–°é…åˆ†", min_value=1, max_value=50)
        },
        use_container_width=True,
        num_rows="dynamic"
    )
    
    # å³æ™‚é‡ç®—ï¼šå¦‚æœä½¿ç”¨è€…ä¿®æ”¹äº†ç¯€æ•¸ï¼Œç«‹åˆ»é‡æ–°è¨ˆç®—é…åˆ†ä¸¦åˆ·æ–°ä»‹é¢
    # æ³¨æ„ï¼šé€™è£¡åˆ©ç”¨ session_state æ¯”è¼ƒä¾†è§¸ç™¼é‡ç®—
    if not edited_df.equals(df_current):
         recalculated_df = calculate_scores(edited_df)
         st.session_state.extracted_data = recalculated_df
         st.rerun()

    # é¡¯ç¤ºç¸½åˆ†ç‹€æ…‹
    current_total = edited_df['é è¨ˆé…åˆ†'].sum()
    st.caption(f"ç›®å‰ç¸½åˆ†ï¼š{current_total} åˆ†")

    col_d1, col_d2 = st.columns(2)
    with col_d1:
        # ä¸‹è¼‰ Excel
        excel_data = df_to_excel(edited_df)
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel å¯©æ ¸è¡¨",
            data=excel_data,
            file_name="å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
    with col_d2:
        if st.button("â¬…ï¸ é‡æ–°ä¸Šå‚³æ•™æ", use_container_width=True):
            st.session_state.step = 1
            st.rerun()
