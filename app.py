import streamlit as st
import google.generativeai as genai
import random
import io
import time
import re
from pypdf import PdfReader
from docx import Document
import pandas as pd
import subprocess
import os

# --- 1. å®šç¾©å­¸ç§‘èˆ‡é¡Œå‹æ˜ å°„ ---
SUBJECT_Q_TYPES = {
    "åœ‹èª": ["åœ‹å­—æ³¨éŸ³", "é€ å¥", "å–®é¸é¡Œ", "é–±è®€ç´ é¤Šé¡Œ", "å¥å‹è®Šæ›", "ç°¡ç­”é¡Œ"],
    "æ•¸å­¸": ["æ‡‰ç”¨è¨ˆç®—é¡Œ", "åœ–è¡¨åˆ†æé¡Œ", "å¡«å……é¡Œ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ"],
    "è‡ªç„¶ç§‘å­¸": ["å¯¦é©—åˆ¤è®€é¡Œ", "åœ–è¡¨åˆ†æé¡Œ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "é…åˆé¡Œ"],
    "ç¤¾æœƒ": ["åœ°åœ–åˆ¤è®€é¡Œ", "æƒ…å¢ƒæ¡ˆä¾‹åˆ†æ", "å–®é¸é¡Œ", "æ˜¯éé¡Œ", "é…åˆé¡Œ", "ç°¡ç­”é¡Œ"],
    "è‹±èª": ["è‹±èªæœƒè©±é¸æ“‡", "è©å½™æ­é…", "æ–‡æ„é¸å¡«", "å–®é¸é¡Œ", "é–±è®€ç†è§£"],
    "": ["å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "ç°¡ç­”é¡Œ"]
}

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ (å¼·åŒ–é˜²è­·ç‰ˆ) ---
@st.cache_data
def extract_text_from_files(files):
    text_content = ""
    if not files: return ""
    for file in files:
        try:
            ext = file.name.split('.')[-1].lower()
            if ext == 'pdf':
                pdf_reader = PdfReader(file)
                text_content += "".join([p.extract_text() or "" for p in pdf_reader.pages])
            elif ext == 'docx':
                doc = Document(file)
                text_content += "\n".join([p.text for p in doc.paragraphs])
            elif ext == 'doc':
                with open("temp.doc", "wb") as f: f.write(file.getbuffer())
                result = subprocess.run(['antiword', 'temp.doc'], capture_output=True, text=True)
                if result.returncode == 0: text_content += result.stdout
                if os.path.exists("temp.doc"): os.remove("temp.doc")
        except: text_content += f"\n[è®€å–éŒ¯èª¤: {file.name}]"
    return text_content

def find_available_model(api_key, keyword="flash"):
    """é˜²å‘†ç‰ˆæ¨¡å‹æœå°‹ [cite: 2026-02-13]"""
    if not api_key: return None, "å°šæœªè¼¸å…¥ API Key"
    genai.configure(api_key=api_key.strip())
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        if not models: return None, "æ­¤ Key ç„¡æ³•è®€å–æ¨¡å‹æ¸…å–®"
        target = next((m for m in models if keyword in m.lower()), models[0])
        return target, None
    except Exception as e: return None, str(e)

def process_table_data(md_text):
    """æ™ºæ…§åˆ‡åˆ†è¡¨æ ¼ï¼šè§£æ±ºæ²¾é»ä¸¦ç¢ºä¿åŒ¯å‡ºæ ¼å¼æ­£ç¢º [cite: 2026-02-13]"""
    try:
        cleaned = md_text.replace("ï½œ", "|").replace("**", "").replace("||", "|\n|")
        header_match = re.search(r'\|\s*å–®å…ƒåç¨±\s*\|\s*å­¸ç¿’ç›®æ¨™.*\|\s*å°æ‡‰é¡Œå‹\s*\|\s*é è¨ˆé…åˆ†\s*\|', cleaned)
        if not header_match: return None
        raw_cells = [c.strip() for c in cleaned[header_match.start():].split('|') if c.strip() and '---' not in c]
        num_cols = 4 
        if len(raw_cells) < num_cols: return None
        headers = raw_cells[:num_cols]
        data_cells = raw_cells[num_cols:]
        rows = [data_cells[i:i+num_cols] for i in range(0, len(data_cells), num_cols)]
        for r in rows:
            if len(r) < num_cols: r += [''] * (num_cols - len(r))
        return pd.DataFrame(rows, columns=headers)
    except: return None

def generate_with_retry(model_or_chat, prompt, stream=True):
    """é…é¡éè¼‰(ResourceExhausted) è‡ªå‹•é‡è©¦æ©Ÿåˆ¶ [cite: 2026-02-13]"""
    max_retries = 3
    for i in range(max_retries):
        try:
            if hasattr(model_or_chat, 'send_message'): return model_or_chat.send_message(prompt, stream=stream)
            else: return model_or_chat.generate_content(prompt, stream=stream)
        except Exception as e:
            err = str(e).lower()
            if "429" in err or "exhausted" in err:
                wait = (i + 1) * 10
                st.toast(f"â³ ç³»çµ±å¿™ç¢Œï¼Œ{wait}ç§’å¾Œè‡ªå‹•é‡è©¦...", icon="âš ï¸")
                time.sleep(wait)
            else: raise e
    raise Exception("API é…é¡å·²æ»¿ï¼Œè«‹ç¨å€™å†è©¦ã€‚")

# --- 3. ä»‹é¢è¦–è¦ºè¨­è¨ˆ (å¤§å­—é«”ã€å¹³å‡åˆ†æ•£ã€å°ˆæ¥­è—) ---
st.set_page_config(page_title="å…§æ¹–åœ‹å° AI è¼”åŠ©å‡ºé¡Œç³»çµ±", layout="wide")

st.markdown("""
    <style>
    header[data-testid="stHeader"], footer { display: none !important; }
    .stApp { background-color: #0F172A; }
    .block-container { max-width: 1200px; padding-top: 1.5rem !important; }
    .school-header { background: linear-gradient(90deg, #1E293B 0%, #334155 100%); padding: 25px; border-radius: 15px; text-align: center; margin-bottom: 25px; border: 1px solid #475569; }
    .school-name { font-size: 26px; font-weight: 700; color: #F1F5F9; letter-spacing: 3px; }
    .app-title { font-size: 15px; color: #94A3B8; }

    /* å´é‚Šæ¬„å¹³å‡åˆ†æ•£æ’ç‰ˆ [cite: 2026-02-13] */
    [data-testid="stSidebar"] > div:first-child { display: flex; flex-direction: column; height: 96vh; justify-content: space-between; }
    .sb-section { padding: 10px 0; }
    [data-testid="stSidebar"] h3 { font-size: 22px !important; margin-bottom: 15px !important; }

    .comfort-box { 
        background-color: #1E293B; padding: 20px; border-radius: 12px; border-left: 6px solid #3B82F6; 
        font-size: 16px; color: #CBD5E1; line-height: 2.2; 
    }
    .comfort-box a { color: #60A5FA !important; text-decoration: underline; font-weight: bold; }
    
    .stTextArea label { font-size: 18px !important; font-weight: bold; }
    [data-testid="stSidebar"] .stButton > button { width: 100%; height: 50px; border-radius: 10px; font-size: 18px; font-weight: bold; }
    
    .custom-footer { position: fixed; left: 0; bottom: 0; width: 100%; background-color: #0F172A; color: #475569; text-align: center; padding: 10px; font-size: 11px; z-index: 100; }
    </style>
    <div class="school-header">
        <div class="school-name">æ–°ç«¹å¸‚é¦™å±±å€å…§æ¹–åœ‹å°</div>
        <div class="app-title">è©•é‡å‘½é¡Œèˆ‡å­¸ç¿’ç›®æ¨™è‡ªå‹•åŒ–ç³»çµ±</div>
    </div>
    """, unsafe_allow_html=True)

# ç‹€æ…‹æŒä¹…åŒ–
if "phase" not in st.session_state: st.session_state.phase = 1 
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "last_prompt_content" not in st.session_state: st.session_state.last_prompt_content = ""
if "subject" not in st.session_state: st.session_state.subject = ""

# --- Sidebar --- [cite: 2026-02-13]
with st.sidebar:
    st.write('<div class="sb-section">', unsafe_allow_html=True)
    st.markdown("### ğŸš€ ä¸€ã€å–å¾—é‡‘é‘°")
    st.markdown("""<div class="comfort-box">
        1ï¸âƒ£ å‰å¾€ <a href="https://aistudio.google.com/" target="_blank">AI Studio (é»æˆ‘)</a><br>
        2ï¸âƒ£ ç™»å…¥<b>å€‹äººå¸³è™Ÿ</b> (é¿é–‹æ•™è‚²ç‰ˆ)<br>
        3ï¸âƒ£ é»æ“Šä¸‹æ–¹ <b>Get API key</b> ä¸¦è²¼å…¥ä¸‹æ–¹
    </div>""", unsafe_allow_html=True)
    st.write('</div>', unsafe_allow_html=True)

    st.write('<div class="sb-section">', unsafe_allow_html=True)
    st.markdown("### ğŸ”‘ é‡‘é‘°è¨­å®š")
    api_input = st.text_area("åœ¨æ­¤è¼¸å…¥ API Key", height=100, placeholder="è«‹è²¼ä¸Šé‡‘é‘°ä»¥å•Ÿç”¨ç³»çµ±...")
    if st.button("ğŸ”„ é‡ç½®ç³»çµ±é€²åº¦"):
        for k in ["phase", "chat_history", "last_prompt_content", "subject"]: st.session_state[k] = (1 if k=="phase" else [] if k=="chat_history" else "")
        st.rerun()
    st.write('</div>', unsafe_allow_html=True)

    st.write('<div class="sb-section">', unsafe_allow_html=True)
    st.markdown("### ğŸ“š è³‡æºé€£çµ")
    st.markdown("""<div class="comfort-box">
        <b>ğŸ“– æ•™æä¸‹è¼‰ï¼š</b><br>
        â€¢ <a href="https://webetextbook.knsh.com.tw/" target="_blank">åº·è»’</a> | <a href="https://edisc3.hle.com.tw/" target="_blank">ç¿°æ—</a> | <a href="https://reader.nani.com.tw/" target="_blank">å—ä¸€</a><br><br>
        <b>ğŸ›ï¸ å®˜æ–¹é€£çµï¼š</b><br>
        â€¢ <a href="https://cirn.moe.edu.tw/Syllabus/index.aspx?sid=1108" target="_blank">108 èª²ç¶±è³‡æºç¶²</a><br>
        â€¢ <a href="https://www.nhps.hc.edu.tw/" target="_blank">å…§æ¹–åœ‹å°æ ¡ç¶²é¦–é </a>
    </div>""", unsafe_allow_html=True)
    st.write('</div>', unsafe_allow_html=True)

# --- Phase 1: åƒæ•¸è¨­å®š ---
if st.session_state.phase == 1:
    with st.container(border=True):
        st.markdown("### ğŸ“ ç¬¬ä¸€éšæ®µï¼šåƒæ•¸è¨­å®šèˆ‡æ•™æä¸Šå‚³")
        c1, c2, c3 = st.columns(3)
        with c1: grade = st.selectbox("1. å¹´ç´š", ["", "ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"])
        with c2: subject = st.selectbox("2. ç§‘ç›®", ["", "åœ‹èª", "æ•¸å­¸", "è‡ªç„¶ç§‘å­¸", "ç¤¾æœƒ", "è‹±èª"])
        with c3: mode = st.selectbox("3. å‘½é¡Œæ¨¡å¼", ["ğŸŸ¢ é©ä¸­", "ğŸ”´ å›°é›£", "ğŸŒŸ ç´ é¤Š"])
        st.session_state.subject = subject

        st.markdown("**4. å‹¾é¸æ¬²ç”¢å‡ºçš„é¡Œå‹**")
        available_types = SUBJECT_Q_TYPES.get(subject, SUBJECT_Q_TYPES[""])
        cols = st.columns(min(len(available_types), 4))
        selected_types = [t for i, t in enumerate(available_types) if cols[i % len(cols)].checkbox(t, value=True)]
        uploaded_files = st.file_uploader("5. ä¸Šå‚³æ•™ææª”æ¡ˆ", type=["pdf", "docx", "doc"], accept_multiple_files=True)
        
        if st.button("ğŸš€ ç”¢å‡ºå­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨", type="primary", use_container_width=True):
            if not api_input or not grade or not subject or not uploaded_files:
                st.warning("âš ï¸ è«‹ç¢ºèª API Keyã€å¹´ç´šã€ç§‘ç›®èˆ‡æ•™ææª”æ¡ˆå‡å·²å‚™å¦¥ã€‚")
            else:
                with st.spinner("âš¡ æ­£åœ¨åˆ†ææ•™æä¸¦ç²¾æº–ç”¢å‡ºé…åˆ†å¯©æ ¸è¡¨..."):
                    model_name, error = find_available_model(api_input, "flash")
                    if error: st.error(f"âŒ æ¨¡å‹åµæ¸¬å¤±æ•—ï¼š{error}")
                    else:
                        content = extract_text_from_files(uploaded_files)
                        sys_inst = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­æ•™å‹™ä¸»ä»»ã€‚è«‹åŸæ–‡æå–å­¸ç¿’ç›®æ¨™ã€‚
                        æ¬„ä½ï¼š| å–®å…ƒåç¨± | å­¸ç¿’ç›®æ¨™(åŸæ–‡) | å°æ‡‰é¡Œå‹ | é è¨ˆé…åˆ† |
                        é‚è¼¯ï¼šæ ¹æ“šè¤‡é›œåº¦åˆ†é… 2-8 åˆ†ã€‚ç¦æ­¢å‡ºé¡Œï¼"""
                        try:
                            model = genai.GenerativeModel(model_name, system_instruction=sys_inst)
                            st.session_state.last_prompt_content = f"å¹´ç´šï¼š{grade}, ç§‘ç›®ï¼š{subject}\né¡Œå‹ï¼š{'ã€'.join(selected_types)}\næ•™æï¼š{content}"
                            res = generate_with_retry(model, st.session_state.last_prompt_content)
                            st.session_state.chat_history.append({"role": "model", "content": res.text})
                            st.session_state.phase = 2
                            st.rerun()
                        except Exception as e: st.error(f"åˆ†æå¤±æ•—ï¼š{e}")

# --- Phase 2: ç¢ºèªèˆ‡å‡ºé¡Œ ---
elif st.session_state.phase == 2:
    current_md = st.session_state.chat_history[0]["content"]
    with st.chat_message("ai"): st.markdown(current_md)
    
    df = process_table_data(current_md)
    if df is not None:
        c_d1, c_d2 = st.columns(2)
        subj_name = st.session_state.subject
        with c_d1:
            try:
                buf = io.BytesIO()
                with pd.ExcelWriter(buf, engine='openpyxl') as writer: df.to_excel(writer, index=False)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel å¯©æ ¸è¡¨", data=buf.getvalue(), file_name=f"å…§æ¹–åœ‹å°_{subj_name}.xlsx", use_container_width=True)
            except: st.caption("å„ªå…ˆä½¿ç”¨ CSV ä¸‹è¼‰ã€‚")
        with c_d2:
            st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV å¯©æ ¸è¡¨ (ä¿éšªç”¨)", data=df.to_csv(index=False).encode('utf-8-sig'), file_name=f"å…§æ¹–åœ‹å°_{subj_name}.csv", use_container_width=True)

    st.divider()
    if st.button("âœ… ç¢ºèªç„¡èª¤ï¼Œé–‹å§‹å‡ºé¡Œ", type="primary", use_container_width=True):
        with st.spinner("ğŸ§  æ­£æ›æª”è‡³ Pro æ¨¡å‹å‘½é¡Œä¸­ (è‹¥é…é¡æ»¿è¼‰å°‡è‡ªå‹•æ’éšŠ)..."):
            model_name_pro, _ = find_available_model(api_input, "pro")
            if not model_name_pro: st.error("âŒ æ‰¾ä¸åˆ°å¯ç”¨æ–¼å‘½é¡Œçš„ Pro æ¨¡å‹ã€‚")
            else:
                model_pro = genai.GenerativeModel(model_name_pro)
                try:
                    with st.chat_message("ai"):
                        placeholder = st.empty()
                        full_res = ""
                        res = generate_with_retry(model_pro, f"{st.session_state.last_prompt_content}\n---\nåƒè€ƒå¯©æ ¸è¡¨ï¼š\n{current_md}\n\nè«‹æ­£å¼å‡ºé¡Œã€‚", stream=True)
                        for chunk in res:
                            full_res += chunk.text
                            placeholder.markdown(full_res + "â–Œ")
                        placeholder.markdown(full_res)
                    st.session_state.chat_history.append({"role": "model", "content": full_res})
                except Exception as e: st.error(f"å‡ºé¡Œå¤±æ•—ï¼š{e}")

st.markdown('<div class="custom-footer">Â© 2026 æ–°ç«¹å¸‚é¦™å±±å€å…§æ¹–åœ‹å°. All Rights Reserved.</div>', unsafe_allow_html=True)
