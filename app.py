import streamlit as st
import google.generativeai as genai
import io
import pandas as pd
import math
from pypdf import PdfReader
from docx import Document
from pptx import Presentation

# --- 1. æ ¸å¿ƒè¨­å®šèˆ‡å·¥å…· ---
SUBJECT_Q_TYPES = {
    "åœ‹èª": ["åœ‹å­—æ³¨éŸ³", "æ”¹éŒ¯å­—", "å­—è©ç¾©æ¸¬é©—", "èª²æ–‡ç†è§£", "é–±è®€æ¸¬é©—", "æˆèªé‹ç”¨"],
    "æ•¸å­¸": ["é¸æ“‡é¡Œ", "å¡«å……é¡Œ", "è¨ˆç®—é¡Œ", "æ‡‰ç”¨é¡Œ", "ç•«åœ–é¡Œ"],
    "è‡ªç„¶ç§‘å­¸": ["æ˜¯éé¡Œ", "é¸æ“‡é¡Œ", "åšåšçœ‹", "ç§‘å­¸é–±è®€", "å¯¦é©—é¡Œ"],
    "ç¤¾æœƒ": ["æ˜¯éé¡Œ", "é¸æ“‡é¡Œ", "å‹¾é¸é¡Œ", "é€£é€£çœ‹", "ç°¡ç­”é¡Œ", "åœ–è¡¨é¡Œ"],
    "è‹±èª": ["Listen & Check", "Listen & Choose", "Read & Choose", "Look & Write", "Reading Comprehension"],
    "": ["å–®é¸é¡Œ", "æ˜¯éé¡Œ", "å¡«å……é¡Œ", "ç°¡ç­”é¡Œ"]
}

# --- 2. æª”æ¡ˆè®€å–å·¥å…· ---
@st.cache_data
def extract_text_from_files(files):
    text_content = ""
    for file in files:
        try:
            filename = file.name.lower()
            file_header = f"\n\n=== æª”æ¡ˆä¾†æºï¼š{file.name} ===\n"
            extracted_text = ""

            if filename.endswith('.pdf'):
                pdf_reader = PdfReader(file)
                for page in pdf_reader.pages:
                    extracted_text += (page.extract_text() or "") + "\n"
                if len(extracted_text.strip()) < 10:
                    text_content += file_header + "[è­¦ç¤º] æª”æ¡ˆå…§å®¹éå°‘ï¼Œä¼¼ä¹æ˜¯åœ–ç‰‡æƒææª”ã€‚è«‹ä½¿ç”¨å´é‚Šæ¬„å·¥å…·è½‰æª”å¾Œå†è©¦ã€‚\n"
                else:
                    text_content += file_header + extracted_text

            elif filename.endswith('.docx'):
                doc = Document(file)
                extracted_text = "\n".join([p.text for p in doc.paragraphs])
                text_content += file_header + extracted_text

            elif filename.endswith('.pptx'):
                try:
                    prs = Presentation(file)
                    for slide_idx, slide in enumerate(prs.slides):
                        slide_text = []
                        for shape in slide.shapes:
                            if hasattr(shape, "text") and shape.text.strip():
                                slide_text.append(shape.text)
                        if slide_text:
                            extracted_text += f"[Slide {slide_idx+1}]\n" + "\n".join(slide_text) + "\n"
                    text_content += file_header + extracted_text
                except Exception as e:
                    text_content += file_header + f"[PPTX è®€å–éŒ¯èª¤] {str(e)}"

            elif filename.endswith('.doc') or filename.endswith('.ppt'):
                text_content += file_header + "[ç³»çµ±é™åˆ¶] è«‹å°‡ .doc/.ppt èˆŠç‰ˆæª”æ¡ˆå¦å­˜ç‚º .docx/.pptx å¾Œå†ä¸Šå‚³ï¼Œä»¥ç¢ºä¿ AI åˆ¤è®€æ­£ç¢ºã€‚"

            elif filename.endswith('.txt'):
                text_content += file_header + str(file.read(), "utf-8")

        except Exception as e:
            text_content += f"\n[è®€å–éŒ¯èª¤: {file.name}] åŸå› ï¼š{str(e)}\n"
            
    return text_content

# --- 3. æ•¸å­¸é…åˆ†é‚è¼¯ ---
def calculate_scores(df):
    try:
        # è½‰ç‚ºæ•¸å€¼ï¼Œè‹¥ AI ç•™ç©ºå‰‡é è¨­ç‚º 1 ç¯€
        df['æˆèª²ç¯€æ•¸'] = pd.to_numeric(df['æˆèª²ç¯€æ•¸'], errors='coerce').fillna(1)
        
        # è¨ˆç®—ç¸½ç¯€æ•¸
        total_hours = df['æˆèª²ç¯€æ•¸'].sum()
        if total_hours == 0: total_hours = 1
        
        # è¨ˆç®—é…åˆ† (æœ€å¤§é¤˜æ•¸æ³•)
        df['åŸå§‹é…åˆ†'] = (df['æˆèª²ç¯€æ•¸'] / total_hours) * 100
        df['é è¨ˆé…åˆ†'] = df['åŸå§‹é…åˆ†'].apply(math.floor)
        
        current_total = df['é è¨ˆé…åˆ†'].sum()
        remainder = 100 - current_total
        
        if remainder > 0:
            df['é¤˜æ•¸æ¬Šé‡'] = df['åŸå§‹é…åˆ†'] - df['é è¨ˆé…åˆ†']
            indices_to_add = df.nlargest(int(remainder), 'é¤˜æ•¸æ¬Šé‡').index
            df.loc[indices_to_add, 'é è¨ˆé…åˆ†'] += 1
        elif remainder < 0:
             df.iloc[0, df.columns.get_loc('é è¨ˆé…åˆ†')] += remainder

        if 'åŸå§‹é…åˆ†' in df.columns: df = df.drop(columns=['åŸå§‹é…åˆ†'])
        if 'é¤˜æ•¸æ¬Šé‡' in df.columns: df = df.drop(columns=['é¤˜æ•¸æ¬Šé‡'])
        
        return df
    except Exception as e:
        st.error(f"é…åˆ†è¨ˆç®—éŒ¯èª¤: {e}")
        return df

# --- 4. Excel ä¸‹è¼‰å·¥å…· (å„ªåŒ–ç‰ˆï¼šæ”¯æ´å¤šåˆ—ç›®æ¨™) ---
def df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        export_df = df.copy()
        export_df["é¸æ“‡é¡Œé…åˆ†"] = "" 
        export_df["éé¸é¡Œé…åˆ†"] = ""
        
        export_df.to_excel(writer, index=False, sheet_name='å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨')
        workbook = writer.book
        worksheet = writer.sheets['å­¸ç¿’ç›®æ¨™å¯©æ ¸è¡¨']
        
        # æ ¼å¼è¨­å®š
        header_fmt = workbook.add_format({'bold': True, 'align': 'center', 'bg_color': '#DCE6F1', 'border': 1})
        cell_fmt = workbook.add_format({'text_wrap': True, 'valign': 'top', 'border': 1})
        
        # è¨­å®šæ¬„å¯¬
        worksheet.set_column('A:A', 20, cell_fmt) # å–®å…ƒ
        worksheet.set_column('B:B', 60, cell_fmt) # ç›®æ¨™ (æœ€å¯¬)
        worksheet.set_column('C:C', 10, cell_fmt) # ç¯€æ•¸
        worksheet.set_column('D:D', 12, cell_fmt) # é…åˆ†
        worksheet.set_column('E:F', 15, cell_fmt) # ç©ºç™½æ¬„ä½
        
        for col_num, value in enumerate(export_df.columns.values):
            worksheet.write(0, col_num, value, header_fmt)
            
    return output.getvalue()

# --- 5. è‡ªå‹•æœå°‹å¯ç”¨æ¨¡å‹ ---
def get_available_flash_model(api_key):
    try:
        genai.configure(api_key=api_key)
        valid_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        for m in valid_models:
            if 'flash' in m.lower() and '1.5' in m.lower(): return m
        for m in valid_models:
            if 'flash' in m.lower(): return m
        for m in valid_models:
            if 'pro' in m.lower(): return m
            
        return "models/gemini-1.5-flash"
    except Exception:
        return "models/gemini-1.5-flash"

# --- 6. AI æç¤ºè© (é—œéµä¿®æ”¹ï¼šä¸€ç›®æ¨™ä¸€åˆ—) ---
GEM_EXTRACT_PROMPT = """
ä½ æ˜¯ä¸€å€‹ç²¾æº–çš„æ•™æåˆ†æå¸«ã€‚è«‹åˆ†æä»¥ä¸‹æ•™æå…§å®¹ï¼Œæå–ã€Œå–®å…ƒåç¨±ã€ã€ã€Œå­¸ç¿’ç›®æ¨™ã€èˆ‡ã€Œæˆèª²ç¯€æ•¸ã€ã€‚

**è¼¸å‡ºè¦å‰‡ (åš´æ ¼éµå®ˆ)ï¼š**
1. åƒ…è¼¸å‡ºä¸€å€‹ Markdown è¡¨æ ¼ã€‚
2. æ¬„ä½å¿…é ˆåŒ…å«ï¼š| å–®å…ƒåç¨± | å­¸ç¿’ç›®æ¨™ | æˆèª²ç¯€æ•¸ |
3. **æ‹†è§£è¦å‰‡ï¼š** - **è«‹å°‡æ¯å€‹å­¸ç¿’ç›®æ¨™ç¨ç«‹æ‹†æˆä¸åŒåˆ— (Row)**ï¼Œä¸è¦åˆä½µåœ¨åŒä¸€æ ¼ã€‚
   - è‹¥ä¸€å€‹å–®å…ƒæœ‰å¤šå€‹ç›®æ¨™ï¼Œè«‹é‡è¤‡å¡«å¯«ã€Œå–®å…ƒåç¨±ã€ã€‚
   - ä¾‹å¦‚ï¼šå–®å…ƒä¸€æœ‰ç›®æ¨™ A å’Œ ç›®æ¨™ Bï¼Œè«‹è¼¸å‡ºå…©åˆ—ï¼š
     | å–®å…ƒä¸€ | ç›®æ¨™ A | ... |
     | å–®å…ƒä¸€ | ç›®æ¨™ B | ... |
4. **æˆèª²ç¯€æ•¸ (é…åˆ†æ¬Šé‡)ï¼š** - è«‹æ ¹æ“šè©²å­¸ç¿’ç›®æ¨™çš„é‡è¦æ€§æˆ–å…§å®¹ä»½é‡ï¼Œä¼°ç®—å…¶æ‰€éœ€çš„ç¯€æ•¸ (æ•´æ•¸)ã€‚
   - **è«‹å°‡è©²å–®å…ƒçš„ç¸½ç¯€æ•¸ï¼Œåˆç†åˆ†é…çµ¦æ——ä¸‹çš„å„å€‹ç›®æ¨™ã€‚** (ä¾‹å¦‚å–®å…ƒç¸½å…± 4 ç¯€ï¼Œæœ‰ 2 å€‹ç›®æ¨™ï¼Œå‰‡å„å¡« 2)ã€‚
   - è‹¥ç„¡æ³•åˆ¤æ–·ï¼Œè«‹é è¨­å¡«å…¥ 1ã€‚
5. å­¸ç¿’ç›®æ¨™è«‹å®Œæ•´ä¿ç•™ï¼Œä¸è¦éåº¦ç¸®æ¸›ã€‚

æ•™æå…§å®¹ï¼š
{content}
"""

# --- 7. ä¸»ç¨‹å¼ä»‹é¢ ---
st.set_page_config(page_title="å…§æ¹–åœ‹å°å‡ºé¡Œç³»çµ± (Pro)", layout="wide")

st.markdown("""
    <style>
    .school-header { background: linear-gradient(90deg, #1E293B 0%, #334155 100%); padding: 20px; border-radius: 12px; text-align: center; color: white; margin-bottom: 20px; }
    </style>
    <div class="school-header">
        <h2 style="margin:0;">å…§æ¹–åœ‹å° AI å‘½é¡Œèˆ‡å¯©æ ¸ç³»çµ±</h2>
        <p style="opacity:0.8; margin-top:5px;">å­¸ç¿’ç›®æ¨™è‡ªå‹•æ‹†è§£ â€¢ æ¬Šé‡ç¨ç«‹é…åˆ† â€¢ é›™å‘ç´°ç›®è¡¨ç”Ÿæˆ</p>
    </div>
""", unsafe_allow_html=True)

if "extracted_data" not in st.session_state: st.session_state.extracted_data = None
if "step" not in st.session_state: st.session_state.step = 1

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šèˆ‡é‡‘é‘°")
    api_key = st.text_input("Google API Key", type="password", placeholder="åœ¨æ­¤è²¼ä¸Šæ‚¨çš„ Key")
    
    if api_key and st.button("ğŸ” æ¸¬è©¦ API é€£ç·šèˆ‡æ¨¡å‹", use_container_width=True):
        try:
            genai.configure(api_key=api_key)
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            st.success(f"âœ… é€£ç·šæˆåŠŸï¼å…±æ‰¾åˆ° {len(models)} å€‹å¯ç”¨æ¨¡å‹")
        except Exception as e:
            st.error(f"âŒ é€£ç·šå¤±æ•—ï¼š{e}")

    if st.button("ğŸ”„ é‡ç½®ç³»çµ±", use_container_width=True):
        st.session_state.extracted_data = None
        st.session_state.step = 1
        st.rerun()

    st.divider()
    st.markdown("### ğŸ› ï¸ è¬ç”¨è½‰æª”å·¥å…·ç®±")
    st.info("é‡åˆ°èˆŠç‰ˆæª”æ¡ˆ (.doc, .ppt) æˆ– åœ–ç‰‡å‹ PDF è®€ä¸åˆ°å­—ï¼Ÿè«‹å…ˆç”¨ä¸‹æ–¹å·¥å…·è½‰æª”ã€‚")
    with st.expander("ğŸ“‚ èˆŠæª”æ•‘æ˜Ÿ (è½‰æˆ .docx/.pptx)"):
        st.markdown("[Word è½‰æª” (CloudConvert)](https://cloudconvert.com/doc-to-docx)")
        st.markdown("[PPT è½‰æª” (CloudConvert)](https://cloudconvert.com/ppt-to-pptx)")
    with st.expander("ğŸ“¸ åœ–ç‰‡/æƒææª”æ•‘æ˜Ÿ (OCR)"):
        st.markdown("[PDF è½‰ Word (iLovePDF)](https://www.ilovepdf.com/zh-tw/pdf_to_word)")

# --- Step 1: ä¸Šå‚³èˆ‡åƒæ•¸ ---
if st.session_state.step == 1:
    col1, col2 = st.columns([1, 2])
    with col1:
        st.subheader("1. åƒæ•¸è¨­å®š")
        grade = st.selectbox("å¹´ç´š", ["ä¸€å¹´ç´š", "äºŒå¹´ç´š", "ä¸‰å¹´ç´š", "å››å¹´ç´š", "äº”å¹´ç´š", "å…­å¹´ç´š"])
        subject = st.selectbox("ç§‘ç›®", list(SUBJECT_Q_TYPES.keys()))
    with col2:
        st.subheader("2. ä¸Šå‚³æ•™æ")
        st.markdown("æ”¯æ´æ ¼å¼ï¼š**PDF, DOCX, PPTX** (å»ºè­°) / TXT")
        uploaded_files = st.file_uploader("è«‹é¸æ“‡æª”æ¡ˆ", type=["pdf", "docx", "pptx", "txt", "doc", "ppt"], accept_multiple_files=True)

    if st.button("ğŸš€ é–‹å§‹åˆ†ææ•™æ (ç”Ÿæˆç²¾ç´°å¯©æ ¸è¡¨)", type="primary", use_container_width=True):
        if not api_key:
            st.error("âŒ è«‹åœ¨å·¦å´è¼¸å…¥ Google API Key")
        elif not uploaded_files:
            st.warning("âš ï¸ è«‹ä¸Šå‚³è‡³å°‘ä¸€å€‹æ•™ææª”æ¡ˆ")
        else:
            with st.spinner("ğŸ¤– AI æ­£åœ¨ç²¾ç´°æ‹†è§£å­¸ç¿’ç›®æ¨™èˆ‡åˆ†é…æ¬Šé‡..."):
                try:
                    text_content = extract_text_from_files(uploaded_files)
                    best_model_name = get_available_flash_model(api_key)
                    model = genai.GenerativeModel(best_model_name)
                    
                    response = model.generate_content(GEM_EXTRACT_PROMPT.format(content=text_content[:40000]))
                    raw_text = response.text
                    
                    # è§£æ Markdown è¡¨æ ¼
                    lines = [line.strip() for line in raw_text.split('\n') if "|" in line and "---" not in line]
                    data = []
                    for line in lines:
                        row = [cell.strip() for cell in line.split('|') if cell.strip()]
                        if len(row) >= 3:
                            data.append(row[:3])
                    
                    if len(data) > 0:
                        headers = ["å–®å…ƒåç¨±", "å­¸ç¿’ç›®æ¨™", "æˆèª²ç¯€æ•¸"]
                        start_idx = 1 if "å–®å…ƒ" in data[0][0] else 0
                        df = pd.DataFrame(data[start_idx:], columns=headers)
                        
                        df_calculated = calculate_scores(df)
                        
                        st.session_state.extracted_data = df_calculated
                        st.session_state.step = 2
                        st.rerun()
                    else:
                        st.error("âŒ AI ç„¡æ³•è­˜åˆ¥æ•™æçµæ§‹ã€‚")
                except Exception as e:
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- Step 2: ç¢ºèªèˆ‡ä¸‹è¼‰ ---
elif st.session_state.step == 2:
    st.subheader("âœ… å­¸ç¿’ç›®æ¨™ç´°ç›®å¯©æ ¸è¡¨")
    
    st.info("ğŸ’¡ æ¯ä¸€åˆ—ä»£è¡¨ä¸€å€‹å…·é«”çš„å­¸ç¿’ç›®æ¨™ã€‚æ‚¨å¯ä»¥èª¿æ•´ã€Œæˆèª²ç¯€æ•¸ã€ä¾†æ”¹è®Šè©²ç›®æ¨™çš„é…åˆ†æ¯”é‡ã€‚")
    
    df_current = st.session_state.extracted_data
    
    edited_df = st.data_editor(
        df_current,
        column_config={
            "å–®å…ƒåç¨±": st.column_config.TextColumn("å–®å…ƒåç¨±", width="medium"),
            "å­¸ç¿’ç›®æ¨™": st.column_config.TextColumn("å­¸ç¿’ç›®æ¨™", width="large", help="AI æ‹†è§£çš„è©³ç´°ç›®æ¨™"),
            "æˆèª²ç¯€æ•¸": st.column_config.NumberColumn("æ¬Šé‡(ç¯€æ•¸)", help="èª¿æ•´æ­¤æ•¸å€¼ä»¥æ”¹è®Šé…åˆ†", min_value=1, max_value=20),
            "é è¨ˆé…åˆ†": st.column_config.NumberColumn("é è¨ˆé…åˆ† (%)", help="ç³»çµ±è‡ªå‹•è¨ˆç®—", disabled=True), 
        },
        use_container_width=True,
        num_rows="dynamic"
    )
    
    if not edited_df.equals(df_current):
         recalculated_df = calculate_scores(edited_df)
         st.session_state.extracted_data = recalculated_df
         st.rerun()

    current_total = edited_df['é è¨ˆé…åˆ†'].sum()
    st.caption(f"ç›®å‰ç¸½åˆ†ï¼š{current_total} åˆ†")

    col_d1, col_d2 = st.columns(2)
    with col_d1:
        excel_data = df_to_excel(edited_df)
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel ç´°ç›®è¡¨",
            data=excel_data,
            file_name="å­¸ç¿’ç›®æ¨™ç´°ç›®å¯©æ ¸è¡¨.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
    with col_d2:
        if st.button("â¬…ï¸ é‡æ–°ä¸Šå‚³æ•™æ", use_container_width=True):
            st.session_state.step = 1
            st.rerun()
